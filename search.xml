<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[tomcat 安全加固]]></title>
    <url>%2F2019%2F08%2F05%2Ftomcat-%E5%AE%89%E5%85%A8%E5%8A%A0%E5%9B%BA%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>Linux</category>
        <category>Apache</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Apache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[什么是wifi探针??]]></title>
    <url>%2F2019%2F07%2F17%2F%E4%BB%80%E4%B9%88%E6%98%AFwifi%E6%8E%A2%E9%92%88%2F</url>
    <content type="text"><![CDATA[1、什么是WIFI探针？？WIFI 探针是一种能够主动识别 Android 和 IOS 设备，感知用户行为轨迹的精准数据收集前端，基于 WIFI探测技术、移动互联网和云计算等先进技术自动识别探针附近的智能移动终端。、当一个设备给另外一个设备通过无线传输技术发送信息时，周围的其他同类设备都是能够收到无线信息，WiFi探针技术基于此原理。具体说，当WiFi设备在WiFi探针的侦听范围内，WiFi设备（无论是终端、路由器或者其他WiFi设备）发送任何一帧（Frame）时，不管是发给谁，探针都能截获，并分析出此帧MAC层与物理层的一些信息，比如发送与接收设备的MAC地址、帧类型、信号强度等。WiFi探针不需要与周围的设备有任何交互，其本身不发出任何WiFi信号，即实现了无感知获取MAC信息。2、WIFI 探针原理wifi探针实际上指的是probe帧。我们一般接入无线网络的时候，首先要选择对应的无线网路，即根据无线网络的名字进行选择（SSID）。那么知道这个名字有两种方式，主动扫描和被动扫描，其中probe帧即是用在主动扫描这种技术中。具体原理：节点会主动的发送probe request请求帧给AP（路由），AP然后反馈响应probe response，该probe response帧和Beacon的内容几乎是一致的，之后利用该帧中的一些信息，节点才会继续发起接入过程。所以狭义上而言，探针技术是一个帧，也是一种节点收集AP信息的方法。AP实际上也可以用来收集节点的信息，该信息并不是指节点（即用户的终端，比如手机）内部的一些信息，而是一些移动的痕迹。3、WIFI探针特点●用户无需连接，无需安装APP；●手机已经连接WiFi也可以探测；●自动实时探测区域内的WiFi终端标识MAC地址；●自动记录每个WiFi终端进入区域时间log_TIme、场强SNR；●兼容iOS苹果和Android系统，开启WiFi的智能手机、笔记本电脑、Pad等移动设备都能探测。4、WIFI 探针技术所使用的网络协议WIFI探针所采用的网络协议是IEEE802.11协议集，此协议集包含许多子协议。其中按照时间顺序发展，主要有：（1）802.11a（2）802.11b（3）802.11g（4）802.11n在网络通信中，数据被封装成了帧（通信中的一个数据块）。帧在数据链路层传输的时候是有固定格式的，不是随便的封装和打包就可以传输。大小有限制，最小46字节，最大1500字节。]]></content>
      <categories>
        <category>物联网</category>
      </categories>
      <tags>
        <tag>物联网</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo博客使用Next主题建立标签云]]></title>
    <url>%2F2019%2F07%2F10%2FHexo%E5%8D%9A%E5%AE%A2%E4%BD%BF%E7%94%A8Next%E4%B8%BB%E9%A2%98%E5%BB%BA%E7%AB%8B%E6%A0%87%E7%AD%BE%E4%BA%91%2F</url>
    <content type="text"><![CDATA[使用hexo-tag-cloud插件:github地址1、安装插件:进入到hexo的根目录，在在 package.json 中添加依赖: “hexo-tag-cloud”: “2.0.*” 操作如下：npm install hexo-tag-cloud@^2.0.* --save Git clone 下载使用命令行安装插件包的过程中可能会出现问题，安装失败，安装不完全。可以直接克隆插件到博客的插件文件夹blog/node_modules里。或者克隆到桌面然后复制到博客的插件目录blog\node_modules文件夹里git clone https://github.com/MikeCoder/hexo-tag-cloud 2、配置插件插件的配置需要对应的环境，可以在主题文件夹里找一下，有没有对应的渲染文件，然后根据渲染文件的类型，选择对应的插件配置方法。我这里使用的next主题，所以使用的是swig 配置方式（不仅next，还有其他主题的配置文件也是.swig格式）在主题文件夹找到文件 theme/next/layout/_macro/sidebar.swig, 然后写入如下代码跳转官网复制代码添加到合适的位置即可博客根目录找到 _config.yml配置文件,在最后添加以下的配置项# hexo-tag-cloud tag_cloud: textFont: Trebuchet MS, Helvetica textColor: &apos;#333&apos; textHeight: 25 outlineColor: &apos;#E2E1D1&apos; maxSpeed: 0.1 定义标签云的字体和颜色textColor: ‘#333’ 字体颜色 textHeight: 25 字体高度，根据部署的效果调整 maxSpeed: 0.1 文字滚动速度，根据自己喜好调整 重启博客，部署到线上hexo clean 清除缓存 hexo g 生成博客 hexo s 本地预览 hexo d 部署到线上 一定要注意清除缓存，不然的话容易出现功能效果不展示的问题，清除缓存即执行:hexo clean 实现效果]]></content>
      <categories>
        <category>hexo博客建站</category>
      </categories>
      <tags>
        <tag>HEXO博客建站</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux常用网络工具:fping主机扫描]]></title>
    <url>%2F2019%2F07%2F10%2FLinux%E5%B8%B8%E7%94%A8%E7%BD%91%E7%BB%9C%E5%B7%A5%E5%85%B7-fping%E4%B8%BB%E6%9C%BA%E6%89%AB%E6%8F%8F%2F</url>
    <content type="text"><![CDATA[fping 介绍Linux下有很多强大网络扫描工具，网络扫描工具可以分为：主机扫描、主机服务扫描、路由扫描等。fping是一个主机扫描工具，相比于ping工具它可以批量扫描主机。fping完全不同于ping，因为您可以在命令行上定义任意数量的主机，或者指定包含要ping的IP地址或主机列表的文件。例如，使用fping，我们可以指定完整的网络范围（ 192.168.0.1/24 ）。它会向主机发送Fping请求，并以循环方式移动到另一个目标主机。 与ping不同，Fping基本上用于编写脚本。访问fping 官方网站：http://fping.org下载最新版安装程序一、编译及安装安装可以使用yum安装或者源码安装yum 安装命令:yum install fping 非root用户可使用sudo或者切换到root用户安装 sudo yum install fping 源码安装[root@node1 ~]# wget http://fping.org/dist/fping-4.2.tar.gz [root@node1 ~]# ll fping-4.2.tar.gz -rw-r--r--. 1 root root 171409 2月 20 05:05 fping-4.2.tar.gz [root@node1 ~]# tar xf fping-4.2.tar.gz &amp;&amp; cd fping-4.2 [root@node1 fping-4.2]# ./configure &amp;&amp; make &amp;&amp; make install 查看安装版本fping -v 二、使用示例2.1 ping多个主机[root@node1 fping-4.2]# fping 172.31.8.13 172.31.8.107 172.31.8.75 172.31.8.3 172.31.8.13 is alive ---主机活动 172.31.8.107 is alive 172.31.8.75 is alive 172.31.8.75 is unreachable --- 主机不可用 [root@node1 fping-4.2]# 2.2 ping IP地址范围以下命令将接收ping的IP范围并输出以下内容，我们将响应请求发送到该范围内的IP并获得我们想要信息。结束后还显示累积结果[root@node1 fping-4.2]# fping -s -g 172.31.8.1 172.31.8.10 172.31.8.1 is alive 172.31.8.3 is alive 172.31.8.5 is alive 172.31.8.8 is alive ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.2 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.2 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.2 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.2 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.4 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.4 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.4 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.4 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.6 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.6 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.6 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.6 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.7 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.7 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.7 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.7 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.9 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.9 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.9 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.9 172.31.8.2 is unreachable 172.31.8.4 is unreachable 172.31.8.6 is unreachable 172.31.8.7 is unreachable 172.31.8.9 is unreachable 172.31.8.10 is unreachable 10 targets 4 alive 6 unreachable 0 unknown addresses 6 timeouts (waiting for response) 28 ICMP Echos sent 4 ICMP Echo Replies received 20 other ICMP received 0.04 ms (min round trip time) 0.73 ms (avg round trip time) 1.15 ms (max round trip time) 4.164 sec (elapsed real time) [root@node1 fping-4.2]# 2.3 ping整个IP段，并重复一次2.4 从文件中读取IP信息，执行ping三、查看帮助信息[root@node1 fping-4.2]# fping -help Usage: fping [options] [targets...] 用法：fping [选项] [ping的目标] -a show targets that are alive 显示可ping通的目标 -A show targets by address 将目标以ip地址的形式显示 -b n amount of ping data to send, in bytes (default 56) ping 数据包的大小。（默认为56） -B f set exponential backoff factor to f 设置指数反馈因子到f -c n count of pings to send to each target (default 1) ping每个目标的次数 (默认为1) -C n same as -c, report results in verbose format 同-c, 返回的结果为冗长格式 -e show elapsed time on return packets 显示返回数据包所费时间 -f file read list of targets from a file ( - means stdin) (only if no -g specified) 从文件获取目标列表( - 表示从标准输入)(不能与 -g 同时使用) -g generate target list (only if no -f specified) 生成目标列表(不能与 -f 同时使用) (specify the start and end IP in the target list, or supply a IP netmask) (ex. fping -g 192.168.1.0 192.168.1.255 or fping -g 192.168.1.0/24) (可指定目标的开始和结束IP， 或者提供ip的子网掩码) (例：fping -g 192.168.1.0 192.168.1.255 或 fping -g 192.168.1.0/24) -H n Set the IP TTL value (Time To Live hops) 设置ip的TTL值 (生存时间) -i n interval between sending ping packets (in millisec) (default 25) ping包之间的间隔(单位：毫秒)(默认25) -l loop sending pings forever 循环发送ping -m ping multiple interfaces on target host ping目标主机的多个网口 -n show targets by name (-d is equivalent) 将目标以主机名或域名显示(等价于 -d ) -p n interval between ping packets to one target (in millisec) 对同一个目标的ping包间隔(毫秒) (in looping and counting modes, default 1000) (在循环和统计模式中，默认为1000) -q quiet (don&apos;t show per-target/per-ping results) 安静模式(不显示每个目标或每个ping的结果) -Q n same as -q, but show summary every n seconds 同-q, 但是每n秒显示信息概要 -r n number of retries (default 3) 当ping失败时，最大重试次数(默认为3次) -s print final stats 打印最后的统计数据 -I if bind to a particular interface 绑定到特定的网卡 -S addr set source address 设置源ip地址 -t n individual target initial timeout (in millisec) (default 500) 单个目标的超时时间(毫秒)(默认500) -T n ignored (for compatibility with fping 2.4) 请忽略(为兼容fping 2.4) -u show targets that are unreachable 显示不可到达的目标 -O n set the type of service (tos) flag on the ICMP packets 在icmp包中设置tos（服务类型） -v show version 显示版本号 targets list of targets to check (if no -f specified) 需要ping的目标列表(不能和 -f 同时使用) -h show this page 显示本帮助页]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Rabbitmq 入门(集群安装篇)]]></title>
    <url>%2F2019%2F07%2F02%2FRabbitmq-%E5%85%A5%E9%97%A8(%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85%E7%AF%87)%2F</url>
    <content type="text"><![CDATA[简介:RabbitMQ是采用Erlang语言实现AMQP（Advanced Message Queuing Protocol，高级消息队列协议）的消息中间件，它最初起源于金融系统，用于在分布式系统中存储转发消息。MQ全称为Message Queue, 消息队列（MQ）是一种应用程序对应用程序的通信方法。应用程序通过读写出入队列的消息（针对应用程序的数据）来通信，而无需专用连接来链接它们。消息传递指的是程序之间通过在消息中发送数据进行通信，而不是通过直接调用彼此来通信，直接调用通常是用于诸如远程过程调用的技术。排队指的是应用程序通过 队列来通信。队列的使用除去了接收和发送应用程序同时执行的要求。其中较为成熟的MQ产品有IBM WEBSPHERE MQ等等。RabbitMQ是目前非常热门的一款消息中间件，很多行业都在使用这个消息中间件，RabbitMQ凭借其高可靠、易扩展、高可用及丰富的功能特性收到很多人的青睐。一、软件下载：下载Erlang 百度云提取码: 864m下载Rabbitmq 源码包 百度云提取码: qwih点击此处跳转到官方网站下载最新版本二、安装环境:node1 172.31.8.8 system Centos 7 —- node3 172.31.8.107 system Centos 7node2 172.31.8.13 system Centos 7 —- node4 172.31.8.75 system Centos 7软件版本：Erlang 21.3rabbitmq 3.7.7三、单点安装(以下操作需要在其他四个节点重复执行)1、分别编辑四台机器的/etc/hosts 文件，增加以下内容172.31.8.8 node1172.31.8.13 node2172.31.8.107 node3172.31.8.75 node42、安装依赖包yum install -y *epel* gcc-c++ unixODBC unixODBC-devel openssl-devel ncurses-devel 3、编译安装 Erlang[root@node1 ~]# tar xf otp_src_21.3.tar.gz [root@node1 ~]# cd otp_src_21.3 [root@node1 otp_src_21.3]# ./configure --prefix=/usr/local/bin/erlang --without-javac [root@node1 otp_src_21.3]# make &amp;&amp; make install [root@node1 otp_src_21.3]# echo &quot;export PATH=$PATH:/usr/local/bin/erlang/bin:/usr/local/bin/rabbitmq_server-3.6.5/sbin&quot; &gt;&gt; /etc/profile [root@node1 otp_src_21.3]# source /etc/profile 查看erlang 是否安装成功，出现以下输出即证明erlang已经安装成功4、安装Rabbitmq[root@node1 ~]# tar xf rabbitmq-server-generic-unix-3.7.7.tar [root@node2 ~]# mv rabbitmq_server-3.7.7 /usr/local/rabbitmq-3.7.7 [root@node2 ~]# cd /usr/local/rabbitmq-3.7.7/ [root@node1 ~]# echo &quot;export PATH=$PATH:/usr/local/rabbitmq-3.7.7/sbin&quot; &gt;&gt; /etc/profile [root@node1 ~]# source /etc/profile [root@node1 ~]# rabbitmq-plugins enable rabbitmq_management ---打开管理页面插件 [root@node1 ~]# rabbitmq-server -detached --后台启动服务 [root@node1 ~]# rabbitmqctl add_user admin 123456 --增加用户名admin，密码123456 [root@node1 ~]# rabbitmqctl set_permissions -p &quot;/&quot; admin &quot;.*&quot; &quot;.*&quot; &quot;.*&quot; [root@node1 ~]# rabbitmqctl set_user_tags admin administrator --设置用户admin为管理员 打开web页面，出现以下页面即安装成功node1node2四、部署集群:1、 修改 .erlang.cookie文件，node1、node4节点内容改为一致[root@node1 ~]# chmod 400 .erlang.cookie --设置.erlang.cookie文件权限,为了防止添加集群失败四个节点均需要调整为一致 [root@node1 ~]# scp .erlang.cookie root@172.31.8.13:/root/ [root@node1 ~]# scp .erlang.cookie root@172.31.8.107:/root/ [root@node1 ~]# scp .erlang.cookie root@172.31.8.75:/root/ 添加集群失败报错示例: 出现此信息可根据提示进行排查2、 替换完.erlang.cookie文件，需要重启各个节点的rabbitmq服务node1 [root@node1 ~]# kill -9 PID [root@node1 ~]# rabbitmq-server -detached node2 [root@node2 ~]# kill -9 PID [root@node2 ~]# rabbitmq-server -detached node3 [root@node3 ~]# kill -9 PID [root@node3 ~]# rabbitmq-server -detached node4 [root@node4 ~]# kill -9 PID [root@node5 ~]# rabbitmq-server -detached 3、添加节点到集群，将node1节点作为主节点在 node2 节点执行以下命令：[root@node2 ~]# rabbitmqctl stop_app [root@node4 ~]# rabbitmqctl join_cluster rabbit@node1 --默认为disc节点，如果需要指定节点角色，可以添加--ram/--disc参数 [root@node4 ~]# rabbitmqctl start_app [root@node4 ~]# rabbitmqctl cluster_status 以上命令在node3、4节点重复执行执行结果:打开web管理页面查看状态到此Rabbitmq集群已经安装完毕，四个节点均已正常运行五、集群管理1、假设Rabbitmq-node2节点需要退出集群在node2节点执行：rabbitmqctl stop_app --停止rabbitmq服务 rabbitmqctl reset --将RabbitMQ node还原到最初状态.包括从所在群集中删除此node,从管理数据库中删除所有配置数据，如已配置的用户和虚拟主机，以及删除所有持久化消息. rabbitmqctl start_app 在主节点（node1）执行rabbitmqctl forget_cluster_node rabbit@node2 --此命令会从集群中删除rabbit@node2节点. 2、修改node2、node4节点为内存节点，在node2、4节点执行:[root@node2 ~]# rabbitmqctl stop_app --停止rabbitmq服务 [root@node2 ~]# rabbitmqctl change_cluster_node_type ram --修改节点为内存节点 [root@node2 ~]# rabbitmqctl start_app --启动服务 [root@node2 ~]# rabbitmqctl cluster_status --查看集群状态 执行结果可以看到node2节点已经修改为RAM节点，disc节点为node1、3、4再修改node4节点：node2、node4节点已经成功修改为内存节点，现在集群就是双内存、双硬盘节点，从控制台查看更为直观:更多管理命令可参考文档:https://blog.csdn.net/wulex/article/details/64127224点击此处查看官方文档]]></content>
      <categories>
        <category>Linux</category>
        <category>Rabbitmq</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Rabbitmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DDOS网络攻击测试工具LOIC]]></title>
    <url>%2F2019%2F06%2F10%2FDDOS%E7%BD%91%E7%BB%9C%E6%94%BB%E5%87%BB%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7LOIC%2F</url>
    <content type="text"><![CDATA[1、简介DoS(Denial Of Service)攻击是指故意的攻击网络协议实现的缺陷或直接通过野蛮手段残忍地耗尽被攻击对象的资源，目的是让目标计算机或网络无法提供正常的服务或资源访问，使目标系统服务系统停止响应甚至崩溃。然而随着网络上免费的可用DDOS工具增多，Dos攻击也日益增长，下面介绍一款Hacker常用的Dos攻击工具LOIC（卢卡）特别提示: 此款工具仅限于教学测试、攻防演练用途，禁止用于非法途径LOIC（卢卡）（Low Orbit Ion Canon）LOTC是一个最受欢迎的DOS攻击工具。 这个工具被去年流行的黑客集团“匿名者”用于对许多大公司的网络攻击。它可以通过使用单个用户执行DOS攻击小型服务器，工具非常易于使用，即便你是一个初学者。 这个工具执行DOS攻击通过发送UDP,TCP或HTTP请求到受害者服务器。 你只需要知道服务器的IP地址或URL.还有其他类似的工具如：XOIC、HULK等等下载地址2、使用方法LOIC 可用于内外网压力测试，下载打开即可直接使用LOIC 应用界面:温馨提示：珍爱生命，远离网络攻击。]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>网络</tag>
        <tag>安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ELK日志监控系统部署]]></title>
    <url>%2F2019%2F05%2F25%2FELK%E6%97%A5%E5%BF%97%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[一、安装软件1.1 集群所需软件列表OS：Centos 7.2 host: 172.31.8.8、172.31.8.13、172.31.8.107、172.31.8.75、172.31.8.11(五台) Elasticsearch：elasticsearch-6.2.2.tar.gz Kibana: kibana-6.2.2-linux-x86_64.tar.gz Logstash:logstash-6.2.2.tar.xz redis：redis-5.0.5.tar.gz JDK:jdk-8u51-linux-x64.tar.gz Nginx: 安装目录:/software/ 1.2 架构图(草图)该图仅供参考，如果要求高可用的话logstash-server、redis需要分别安装在多台服务器上且logstash-server、redis都需要至少两台服务器（后端监控的web应用不一定都是nginx，也可能是jboss、tomcat等其他web应用）如果方案没有改动的话我会按照架构图上设计的方案去部署，否则我可能会把Elasticsearch、kibana、redis部署在一台服务器上目前elasticsearch、logstash、kibana最高版本已经达到7.2.*，安装7版本需要jdk1.9支持，否则程序无法启动并会报错：OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release. 二、安装2.1 安装Elasticsearch2.1.1 修改环境参数：配置线程个数。修改配置文件/etc/security/limits.conf，增加配置* hard nofile 65536 * soft nofile 65536 * soft nproc 2048 * hard nproc 4096 修改/etc/sysctl.conf文件，增加配置：vim /etc/sysctl.conf vm.max_map_count=262144 执行 sysctl -p 命令，是配置生效2.1.2 添加普通用户groupadd elsearch --- 添加elsearch组 useradd elsearch -g elsearch ---添加elsearch用户，并加入elsearch组 2.1.3 修改Elasticsearch配置文件：vim /software/elasticsearch-6.2.2/config/elasticsearch.yml --- 修改以下参数 cluster.name: es-cluster --- 集群名称 node.name: master --- Elasticsearch主节点写为master，备节点写为slave path.data: /software/elasticsearch-6.2.2/data --- 数据存储目录 path.logs: /software/elasticsearch-6.2.2/logs --- 程序日志存储目录 network.host: 172.31.8.8 --- 可写为本机IP或者0.0.0.0 http.port: 9200 --- 默认端口9200，打开注释即可 discovery.zen.ping.unicast.hosts: [&quot;172.31.8.8&quot;, &quot;172.31.8.13&quot;] --- 集群主机IP 2.1.4 修改java环境变量vim /software/elasticsearch-6.2.2/bin/elasticsearch-env --- 在头部添加java环境变量 #!/bin/bash JAVA_HOME=/software/jdk1.8.0_51 JRE_HOME=/software/jdk1.8.0_51/jre PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib export JAVA_HOME JRE_HOME PATH CLASSPATH 2.1.5 修改程序权限（Elasticsearch不能使用root权限启动，只能使用普通用户）chown -R elsearch.elsearch elasticsearch-6.2.2/ 2.1.6 启动服务su - elsearch /software/elasticsearch-6.2.2/bin/elasticsearch -d --- -d参数指定程序在后台运行 访问： http://IPaddr:9200 masterslave查看集群状态http://172.31.8.8:9200/_cat/health?v2.1.7 集群状态相关参数说明URL中_cat表示查看信息，health表明返回的信息为集群健康信息，?v表示返回的信息加上头信息，跟返回JSON信息加上?pretty同理，就是为了获得更直观的信息，当然，你也可以不加，不要头信息，特别是通过代码获取返回信息进行解释，头信息有时候不需要，写shell脚本也一样，经常要去除一些多余的信息。 通过这个链接会返回下面的信息，下面的信息包括： 集群的状态（status）：red红表示集群不可用，有故障。yellow黄表示集群不可靠但可用，一般单节点时就是此状态。green正常状态，表示集群一切正常。 节点数（node.total）：节点数，这里是2，表示该集群有两个节点。 数据节点数（node.data）：存储数据的节点数，这里是2。数据节点在Elasticsearch概念介绍有。 分片数（shards）：这是 0，表示我们把数据分成多少块存储。 主分片数（pri）：primary shards，这里是6，实际上是分片数的两倍，因为有一个副本，如果有两个副本，这里的数量应该是分片数的三倍，这个会跟后面的索引分片数对应起来，这里只是个总数。 激活的分片百分比（active_shards_percent）：这里可以理解为加载的数据分片数，只有加载所有的分片数，集群才算正常启动，在启动的过程中，如果我们不断刷新这个页面，我们会发现这个百分比会不断加大。 2.1.8 安装elasticsearch-head 插件因为head是一个用于管理Elasticsearch的web前端插件，该插件在es5版本以后采用独立服务的形式进行安装使用（之前的版本可以直接在es安装目录中直接安装），因此需要安装nodejs、npmyum -y install nodejs npm 如果没有安装git，还需要先安装git：yum -y install git 然后安装elasticsearch-head插件：git clone https://github.com/mobz/elasticsearch-head.git git下载完成后，进入目录，进行操作：cd elasticsearch-head/ 执行npm install 命令， 执行该命名可能会出现以下错误： npm ERR! phantomjs-prebuilt@2.1.16 install: `node install.js` npm ERR! Exit status 1 npm ERR! npm ERR! Failed at the phantomjs-prebuilt@2.1.16 install script &apos;node install.js&apos;. npm ERR! Make sure you have the latest version of node.js and npm installed. npm ERR! If you do, this is most likely a problem with the phantomjs-prebuilt package, npm ERR! not with npm itself. npm ERR! Tell the author that this fails on your system: npm ERR! node install.js npm ERR! You can get information on how to open an issue for this project with: npm ERR! npm bugs phantomjs-prebuilt npm ERR! Or if that isn&apos;t available, you can get their info via: npm ERR! npm owner ls phantomjs-prebuilt npm ERR! There is likely additional logging output above. npm ERR! Please include the following file with any support request: npm ERR! /software/elasticsearch-6.2.2/elasticsearch-head/npm-debug.log 此时忽略phantomjs-prebuilt@2.1.16，执行命令如下 npm install phantomjs-prebuilt@2.1.16 --ignore-scripts 然后执行： npm install npm WARN deprecated coffee-script@1.10.0: CoffeeScript on NPM has moved to &quot;coffeescript&quot; (no hyphen) npm WARN deprecated http2@3.3.7: Use the built-in module in node 9.0.0 or newer, instead npm WARN deprecated phantomjs-prebuilt@2.1.16: this package is now deprecated npm WARN deprecated json3@3.2.6: Please use the native JSON object instead of JSON 3 npm WARN deprecated json3@3.3.2: Please use the native JSON object instead of JSON 3 npm WARN prefer global coffee-script@1.10.0 should be installed with -g &gt; phantomjs-prebuilt@2.1.16 install /software/elasticsearch-6.2.2/elasticsearch-head/node_modules/phantomjs-prebuilt &gt; node install.js PhantomJS not found on PATH Downloading https://github.com/Medium/phantomjs/releases/download/v2.1.1/phantomjs-2.1.1-linux-x86_64.tar.bz2 Saving to /tmp/phantomjs/phantomjs-2.1.1-linux-x86_64.tar.bz2 Receiving... [=======---------------------------------] 19% 插件安装相对会慢一些。。。配置插件：停止elasticsearchps -ef | grep java | grep elsearch kill -9 PID 修改：vim /software/elasticsearch-6.2.2/config/elasticsearch.yml 添加以下参数： http.cors.enabled: true http.cors.allow-origin: &quot;*&quot; 启动elasticsearch/software/elasticsearch-6.2.2/bin/elasticsearch -d 启动elasticsearch-head 插件（后台运行）nohup npm run start &amp; [1] 11047 nohup: 忽略输入并把输出追加到&quot;/home/elsearch/nohup.out&quot; netstat -anlp | grep 9100 tcp 0 0 0.0.0.0:9100 0.0.0.0:* LISTEN 11058/grunt 使用浏览器访问插件并与ES进行交互masterslave2.2 安装kibana2.2.1 修改配置文件tar xf kibana-6.2.2-linux-x86_64.tar.gz cd kibana-6.2.2-linux-x86_64 vim /software/kibana-6.2.2-linux-x86_64/config/kibana.yml server.port: 5601 server.host: &quot;172.31.8.8&quot; elasticsearch.url: &quot;http://172.31.8.8:9200&quot; --- 这个写的就是本机安装的Elasticsearch，只能写一个地址，目前还不支持写多个节点。如果想要对接Elasticsearch集群就需要搭建一个只能用来进行协调的Elasticsearch节点，这个节点不参与主节点选举、不存储数据。 只是用来处理传入的HTTP请求，并将操作重定向到集群中的其他Elasticsearch节点，然后收集并返回结果。这个“协调”节点本质上也起了一个负载均衡的作用。 2.2.2 Kibana启动脚本配置#/bin/sh RETVAL= PID=`ps -ef | grep &quot;kibana.yml&quot; | awk -F &apos; &apos; &apos;{print $2}&apos;` echo $PID KIBANA_DIR=/software/kibana-6.2.2-linux-x86_64 KIBANA=$KIBANA_DIR/bin/kibana PROG=$(basename $KIBANA) CONF=$KIBANA_DIR/config/kibana.yml if [ ! -x $KIBANA ]; then echo -n $&quot;$KIBANA not exist.&quot;;warning;echo exit 0 fi start(){ echo -n $&quot;Starting $PROG: &quot; nohup $KIBANA &gt;/dev/null 2&gt;&amp;1 &amp; RETVAL=$? if [ $RETVAL -eq 0 ]; then echo &quot;start OK&quot; else echo &quot;start failure&quot; fi return $RETVAL } stop(){ echo -n $&quot;Stopping $PROG: &quot; kill -TERM $PID &gt;/dev/null 2&gt;&amp;1 RETVAL=$? echo &quot;stop OK&quot; return $RETVAL } restart(){ stop sleep 2 start } case &quot;$1&quot; in start) start ;; stop) stop ;; restart) restart ;; status) ps -ef|grep $PID|grep kibana RETVAL=$? ;; *) echo $&quot;Usage: $0 {start|stop|status|restart}&quot; RETVAL=1 esac exit $RETVAL 2.2.3 启动Kibana ./kibana.sh start Starting kibana: start OK 访问：http://172.31.8.8:56012.3 redis 安装 wget http://45.252.224.74/files/503000000DD76BB8/download.redis.io/releases/redis-5.0.5.tar.gz cd /software/ &amp;&amp; tar xf redis-5.0.5.tar.gz &amp;&amp; mkdir redis cd redis-5.0.5 make &amp;&amp; cd src/ make install PREFIX=/software/redis/ -- 指定redis安装目录为/software/redis/ cd ../ &amp;&amp; mkdir /software/conf &amp;&amp; cp redis.conf /software/redis/conf/ vim /software/redis/conf/redis.conf 修改以下参数: bind 172.31.8.107 --- 将这里的127.0.0.1改为172.31.8.107,否则只能连接127.0.0.1本地回环地址，无法远程连接 protected-mode yes 改为 protected-mode no --- yes改为no,目的是为了解决安全模式引起的报错 port 6379 --- 打开注释 daemonize no 改为 daemonize yes --- no改为yes,目的是为了设置后台运行 pidfile /software/redis/redis.pid --- 设置redis.pid 文件存储目录 logfile &quot;/software/redis/logs/redis.log&quot; --- 设置redis.log 文件存储目录 安装测试：/software/redis/bin/redis-cli -h 172.31.8.107 -p 6379 如果出现如下，则表明连接成功 172.31.8.107:6379&gt; 2.4 logstash-server 安装2.4.1 编辑配置文件：vim /software/logstash-6.2.2/config/logstash.yml 修改参数： node.name: logstash-server -- 设置节点名称，一般为主机名 path.data: /software/logstash-6.2.2/data --- 设置logstash 和插件使用的持久化目录 config.reload.automatic: true --- 开启配置文件自动加载 config.reload.interval: 10s --- 定义配置文件重载时间周期 http.host: &quot;172.31.8.107&quot; --- 定义访问主机名，一般为域名或IP http.port: 9600-9700 --- 打开logstash 端口注释 vim /software/logstash-6.2.2/config/logstash_server.conf input { redis { port =&gt; &quot;6379&quot; host =&gt; &quot;127.0.0.1&quot; data_type =&gt; &quot;list&quot; batch_count =&gt; &quot;1&quot; key =&gt; &quot;nginx-accesslog&quot; } } filter { grok { match =&gt; { &quot;message&quot; =&gt; &quot;%{COMBINEDAPACHELOG}&quot; } } } output { elasticsearch { hosts =&gt; [&quot;172.31.8.8:9200&quot;] index =&gt; &quot;nginx-accesslog-%{+YYYY.MM.dd}&quot; } } 2.4.2 编写logstash 启动脚本#/bin/sh RETVAL= PID=`ps -ef | grep java | grep &quot;logstash_server\.conf&quot; | awk -F &apos; &apos; &apos;{print $2}&apos;` LOGSTASH_DIR=/software/logstash-6.2.2 LOGSTASH=$LOGSTASH_DIR/bin/logstash PROG=$(basename $LOGSTASH) CONF=$LOGSTASH_DIR/config/logstash_server.conf LOG=$LOGSTASH_DIR/logs/logstash.log if [ ! -x $LOGSTASH ]; then echo -n $&quot;$LOGSTASH not exist.&quot;;warning;echo exit 0 fi start(){ echo -n $&quot;Starting $PROG: &quot; nohup $LOGSTASH --config $CONF --log $LOG &gt;/dev/null 2&gt;&amp;1 &amp; RETVAL=$? if [ $RETVAL -eq 0 ]; then echo &quot;start OK&quot; else echo &quot;start failure&quot; fi return $RETVAL } stop(){ echo -n $&quot;Stopping $PROG: &quot; kill -TERM $PID &gt;/dev/null 2&gt;&amp;1 RETVAL=$? echo &quot;stop OK&quot; return $RETVAL } restart(){ stop sleep 2 start } case &quot;$1&quot; in start) start ;; stop) stop ;; restart) restart ;; status) ps -ef|grep $PID|grep logstash_server\.conf RETVAL=$? ;; *) echo $&quot;Usage: $0 {start|stop|status|restart}&quot; RETVAL=1 esac exit $RETVAL 2.4.3 测试启动脚本2.4.4 logstash-server 调试停止logstash-server/software/logstash-6.2.2/logstash.sh stop 编辑配置文件vim /software/logstash-6.2.2/config/logstash_server.conf 修改为以下参数： input { redis { port =&gt; &quot;6379&quot; host =&gt; &quot;127.0.0.1&quot; data_type =&gt; &quot;list&quot; key =&gt; &quot;nginx-access&quot; db =&gt; &quot;0&quot; codec =&gt; &quot;json&quot; } } output { elasticsearch { hosts =&gt; [&quot;172.31.8.8:9200&quot;,&quot;172.31.8.13:9200&quot;] index =&gt; &quot;nginx-access-%{+YYYY.MM.dd}&quot; } } 修改logstash-server JVMvim /software/logstash-6.2.2/config/jvm.options -Xms1g 改为 -Xms500m -- 根据自己的实际情况 -Xmx1g 改为 -Xmx500m -- 根据自己的实际情况 目前我这个日志数据比较少，使用500M内存足够验证配置是否正确/software/logstash-6.2.2/bin/logstash -f /software/logstash-6.2.2/config/logstash_server.conf -t Sending Logstash&apos;s logs to /software/logstash-6.2.2/logs which is now configured via log4j2.properties [INFO ][logstash.modules.scaffold] Initializing module {:module_name=&gt;&quot;fb_apache&quot;, :directory=&gt;&quot;/software/logstash-6.2.2/modules/fb_apache/configuration&quot;} [INFO ][logstash.modules.scaffold] Initializing module {:module_name=&gt;&quot;netflow&quot;, :directory=&gt;&quot;/software/logstash-6.2.2/modules/netflow/configuration&quot;} [WARN ][logstash.config.source.multilocal] Ignoring the &apos;pipelines.yml&apos; file because modules or command line options are specified [INFO ][logstash.config.source.local.configpathloader] No config files found in path {:path=&gt;&quot;/software/logstash-6.2.2/config/logstash&quot;} [ERROR][logstash.config.sourceloader] No configuration found in the configured sources. Configuration OK [INFO ][logstash.runner ] Using config.test_and_exit mode. Config Validation Result: OK. Exiting Logstash 启动logstash程序已经正常运行2.5 安装nginxnginx 安装过程参考,点击传送2.6 安装logstash-agent2.6.1 修改配置文件vim /software/logstash-6.2.2/config/logstash.yml 修改参数： node.name: logstash-server -- 设置节点名称，一般为主机名 path.data: /software/logstash-6.2.2/data --- 设置logstash 和插件使用的持久化目录 config.reload.automatic: true --- 开启配置文件自动加载 config.reload.interval: 10s --- 定义配置文件重载时间周期 http.host: &quot;172.31.8.75&quot; --- 定义访问主机名，一般为域名或IP http.port: 9600-9700 --- 打开logstash 端口注释 2.6.2 新建程序启动文件：vim /software/logstash-6.2.2/config/logstash-nginx.conf 写入以下内容： input { file { type =&gt; &quot;nginx-access&quot; path =&gt; [&quot;/software/nginx/logs/172.31.8.75_json_access*&quot;] } file { type =&gt; &quot;nginx-error&quot; path =&gt; &quot;/software/nginx/logs/nginx_error.log&quot; } } # output to redis output { if [type] == &quot;nginx-access&quot; { redis { host =&gt; &quot;172.31.8.107&quot; port =&gt; &quot;6379&quot; db =&gt; &quot;0&quot; data_type =&gt; &quot;list&quot; key =&gt; &quot;nginx-access&quot; } } } 2.6.3 编辑 修改logstash-agent JVM-Xms1g 改为 -Xms256m -- 根据自己的实际情况 -Xmx1g 改为 -Xmx256m -- 根据自己的实际情况 2.6.4 配置logstash-agent java环境变量vim /software/logstash-6.2.2/bin/logstash 插入以下内容： JAVA_HOME=/software/jdk1.8.0_51 JRE_HOME=/software/jdk1.8.0_51/jre PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib export JAVA_HOME JRE_HOME PATH CLASSPATH 2.6.5 同样使用以下命令验证配置文件/software/logstash-6.2.2/bin/logstash -f /software/logstash-6.2.2/config/logstash-nginx.conf -t 2.6.6 验证正常后启动logstash服务 （另一个节点操作同样）nohup /software/logstash-6.2.2/bin/logstash -f /software/logstash-6.2.2/config/logstash-nginx.conf &amp; 三、配置ELK监控3.1 登陆redis，验证/software/redis/bin/redis-cli -h 172.31.8.107 -p 6379 172.31.8.107:6379&gt; keys * 1) &quot;nginx-access&quot; --- 数据已经传输到redis 3.2 打开elasticsearch-headhttp://172.31.8.8:9100 索引已经可以在elasticsearch上展示3.3 打开kibana创建索引http://172.31.8.8:5601 点击Discover数据已经可以正常展示3.4 使用ab 压测工具，生成日志3.4.1 安装yum -y install httpd-tools 3.4.2 测试安装是否成功ab -V This is ApacheBench, Version 2.3 &lt;$Revision: 1430300 $&gt; Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ 3.4.2 ab 参数说明ab --help ab: wrong number of arguments Usage: ab [options] [http[s]://]hostname[:port]/path Options are: -n requests Number of requests to perform -c concurrency Number of multiple requests to make at a time -t timelimit Seconds to max. to spend on benchmarking This implies -n 50000 -s timeout Seconds to max. wait for each response Default is 30 seconds -b windowsize Size of TCP send/receive buffer, in bytes -B address Address to bind to when making outgoing connections -p postfile File containing data to POST. Remember also to set -T -u putfile File containing data to PUT. Remember also to set -T -T content-type Content-type header to use for POST/PUT data, eg. &apos;application/x-www-form-urlencoded&apos; Default is &apos;text/plain&apos; -v verbosity How much troubleshooting info to print -w Print out results in HTML tables -i Use HEAD instead of GET -x attributes String to insert as table attributes -y attributes String to insert as tr attributes -z attributes String to insert as td or th attributes -C attribute Add cookie, eg. &apos;Apache=1234&apos;. (repeatable) -H attribute Add Arbitrary header line, eg. &apos;Accept-Encoding: gzip&apos; Inserted after all normal header lines. (repeatable) -A attribute Add Basic WWW Authentication, the attributes are a colon separated username and password. -P attribute Add Basic Proxy Authentication, the attributes are a colon separated username and password. -X proxy:port Proxyserver and port number to use -V Print version number and exit -k Use HTTP KeepAlive feature -d Do not show percentiles served table. -S Do not show confidence estimators and warnings. -q Do not show progress when doing more than 150 requests -g filename Output collected data to gnuplot format file. -e filename Output CSV file with percentages served -r Don&apos;t exit on socket receive errors. -h Display usage information (this message) -Z ciphersuite Specify SSL/TLS cipher suite (See openssl ciphers) -f protocol Specify SSL/TLS protocol (SSL3, TLS1, TLS1.1, TLS1.2 or ALL) ab的命令参数比较多，我们经常使用的是-c和-n参数。ab -c 10 -n 100 http://172.31.8.75/ This is ApacheBench, Version 2.3 &lt;$Revision: 1430300 $&gt; Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking 172.31.8.75 (be patient).....done Server Software: nginx/1.8.1 Server Hostname: 172.31.8.75 Server Port: 80 Document Path: / Document Length: 612 bytes Concurrency Level: 10 Time taken for tests: 0.013 seconds Complete requests: 100 Failed requests: 0 Write errors: 0 Total transferred: 84400 bytes HTML transferred: 61200 bytes Requests per second: 7569.45 [#/sec] (mean) Time per request: 1.321 [ms] (mean) Time per request: 0.132 [ms] (mean, across all concurrent requests) Transfer rate: 6238.88 [Kbytes/sec] received Connection Times (ms) min mean[+/-sd] median max Connect: 0 0 0.1 0 0 Processing: 0 1 0.2 1 1 Waiting: 0 1 0.2 1 1 Total: 1 1 0.1 1 1 Percentage of the requests served within a certain time (ms) 50% 1 66% 1 75% 1 80% 1 90% 1 95% 1 98% 1 99% 1 100% 1 (longest request)]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jira(安装篇)]]></title>
    <url>%2F2019%2F05%2F21%2Fjira(%E5%AE%89%E8%A3%85%E7%AF%87)%2F</url>
    <content type="text"><![CDATA[一、jira环境需求system： Linuxmemory： 2GBMysql数据库Jdk jdk-8u92-linux-x64.rpmJira atlassian-jira-6.4.12-x64Jira + 数据库连接插件mysql-connector-java-5.1.36-bin部署前机器的内存至少为2GB.否则会出现如下错误：二、安装部署部署前配置 关闭iptables和selinuxservice iptables stop &amp;&amp; setenforce 02.1 jdk安装查看版本号 jdk安装完毕2.2 安装mysql数据库（如果有的可以跳过安装这一步）采用的是yum安装yum install http://www.percona.com/downloads/percona-release/redhat/0.1-3/percona-release-0.1-3.noarch.rpmyum install Percona-Server-server-56初始化mysql数据库，创建账户并赋予链接权限创建jira库和jira用户create database jiradb character set utf8; grant select,insert,update,delete,create,drop,alter,index on jiradb.* to &apos;jira&apos;@&apos;localhost&apos; identified by &apos;jira&apos;; flush privileges; 退出，使用jira账户进行登陆测试mysql –ujira –p 下载mysql-connector-java-5.1.39.tar.gz 连接2.3 安装jira上传jira文件Chmod +x./Jira web访问端口为8080由于jira默认是不支持使用mysql数据库的，如果用mysql的话就得把链接插件放到以下目录，并重启jira上传mysql – jira 连接插件cd /opt/atlassian/jira/atlassian-jira/WEB-INF/lib/上传文件cd /opt/atlassian/jira/atlassian-jira/WEB-INF/lib/上传中文语言包删除 cd /var/atlassian/application-data/jira/打开浏览器，开始设置向导连接数据库选择模式装的过程中需要在官网获取试用序列号，然后进行破解！！]]></content>
      <categories>
        <category>Linux</category>
        <category>jira</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>jira</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix 缓存数据清理]]></title>
    <url>%2F2019%2F05%2F20%2FZabbix-%E7%BC%93%E5%AD%98%E6%95%B0%E6%8D%AE%E6%B8%85%E7%90%86%2F</url>
    <content type="text"><![CDATA[zabbix监控运行一段时间以后，会留下大量的历史监控数据，zabbix数据库一直在增大；可能会造成系统性能下降，查看历史数据室查询速度缓慢。zabbix里面最大的表就是history和history_uint两个表，而且zabbix里面的时间是使用的时间戳方式记录，所以可以根据时间戳来删除历史数据一、关闭zabbix、http服务pkill -9 zabbix service httpd stop 二、清理zabbix历史数据1、查看数据库目录文件[root@zabbix-server zabbix]# cd /var/lib/mysql/zabbix/ [root@zabbix-server zabbix]# ls -lh | grep G total 177G -rw-r----- 1 mysql mysql 1.7G Dec 24 13:49 events.ibd -rw-r----- 1 mysql mysql 60G Dec 24 13:49 history.ibd -rw-r----- 1 mysql mysql 2.4G Dec 24 13:49 history_str.ibd -rw-r----- 1 mysql mysql 99G Dec 24 13:49 history_uint.ibd -rw-r----- 1 mysql mysql 4.6G Dec 24 13:02 trends.ibd -rw-r----- 1 mysql mysql 9.5G Dec 24 13:49 trends_uint.ibd [root@zabbix-server zabbix]# 生成Unix时间戳。时间定为2018年2月1日（暂定是保存18年2月以后的监控数据）[root@zabbix-server zabbix]# date +%s -d &quot;Feb 1, 2018 00:00:00&quot; #执行此命令以后会生成一个ID 1517414400 #这是生成的ID 2、数据备份[root@zabbix-server zabbix]#mysql -uroot -p zabbix &gt; /root/mysqlback/zabbix.sql #需要创建mysqlback目录 3、 登录数据库[root@zabbix-server zabbix]# mysql -uroot -p Enter password: Welcome to the MariaDB monitor. Commands end with ; or \g. Your MariaDB connection id is 7 Server version: 5.5.60-MariaDB MariaDB Server Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others. Type &apos;help;&apos; or &apos;\h&apos; for help. Type &apos;\c&apos; to clear the current input statement. MariaDB [(none)]&gt; use zabbix; #选择zabbix数据库 执行sql查看指定日期之前的数据大小：SELECT table_schema as `Database`,table_name AS `Table`,round(((data_length + index_length) / 1024 / 1024 / 1024), 2) `Size in MB`FROM information_schema.TABLES where CREATE_TIME &lt; &apos;2018-02-01 00:00:00&apos; and table_name=&apos;history.ibd&apos;; 根据需要修改日期和查询的表名称(如果查询出来的结果是0.0，需要将sql中的三个1024删除一个，以G为单位显示)4、 执行以下命令，清理指定时间之前的数据、对zabbix数据库执行以下sqldelete from history where clock &lt; 1517414400; optimize table history; delete from history_uint where clock &lt; 1517414400; optimize table history_uint; delete from trends where clock &lt; 1517414400; optimize table trends; delete from trends_uint where clock &lt; 1517414400; optimize table trends_uint; 注意：sql中的ID是生成Unix时间戳的ID号,需要改为自己生成的ID号三、启动服务/usr/sbin/zabbix_server -c /etc/zabbix/zabbix_server.conf #zabbix server /usr/sbin/zabbix_agentd -c /etc/zabbix/zabbix_agentd.conf #zabbix agent service httpd start ===============================分===========隔==========符===================================1、使用truncate命令清空zabbix 所有监控数据------------------------------------------------------- truncate table history; optimize table history; ------------------------------------------------------- truncate table history_str; optimize table history_str; ------------------------------------------------------- truncate table history_uint; optimize table history_uint; ------------------------------------------------------- truncate table trends; optimize table trends; ------------------------------------------------------- truncate table trends_uint; optimize table trends_uint; ------------------------------------------------------- truncate table events; optimize table events; ------------------------------------------------------- 注意：这些命令会把zabbix所有的监控数据清空，操作前注意备份数据库truncate是删除了表，然后根据表结构重新建立，delete删除的是记录的数据没有修改表truncate执行删除比较快，但是在事务处理安全性方面不如delete,如果我们执行truncat的表正在处理事务，这个命令退出并会产生错误信息]]></content>
      <categories>
        <category>Linux</category>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis 故障恢复]]></title>
    <url>%2F2019%2F05%2F10%2FRedis-%E6%95%85%E9%9A%9C%E6%81%A2%E5%A4%8D%2F</url>
    <content type="text"><![CDATA[案例一、ResponseError: MISCONF Redis is configured to save RDB snapshots, but is currently not able to persist on disk.Commands that may modify the data set are disabled. Please check Redis logs for details about the error.Redis被配置为保存数据库快照，但它目前不能持久化到硬盘。用来修改集合数据的命令不能用。请查看Redis日志的详细错误信息。原因：强制关闭redis快照导致不能持久化解决方案：将：stop-writes-on-bgsave-error 设置为 no案例二、logstash 连接redis失败[WARN ][logstash.outputs.redis ] Failed to send event to Redis {:event=&gt;#&lt;LogStash::Event:0x63169a41&gt;, :identity=&gt;&quot;redis://@172.31.8.107:6379/0 list:nginx-access&quot;, :exception=&gt;#&lt;Redis::CannotConnectError: Error connecting to Redis on 172.31.8.107:6379 (Errno::ECONNREFUSED)&gt;, :backtrace=&gt;[&quot;/software/logstash-6.2.2/vendor/bundle/jruby/2.3.0/gems/redis-3.3.5/lib/redis/client.rb:345:in `establish_connection&apos;&quot;, &quot;/software/logstash-6.2.2/vendor/bundle/jruby/2.3.0/gems/redis-3.3.5/lib/redis/client.rb:101:in `block in connect redis现在的版本开启redis-server后，redis-cli只能访问到127.0.0.1，因为在配置文件中固定了ip，因此需要修改redis.conf# bind 192.168.1.100 10.0.0.1 #bind 127.0.0.1 # # ~~~ If the computer running Redis is directly exposed to the12345678910# internet, binding to all the interfaces is dangerous and will expose the# instance to everybody on the internet. So by default we uncomment the# following bind directive, that will force Redis to listen only into# the IPv4 loopback interface address (this means Redis will be able to# accept connections only from clients running into the same computer it# is running).## IF YOU ARE SURE YOU WANT YOUR INSTANCE TO LISTEN TO ALL THE INTERFACES# JUST COMMENT THE FOLLOWING LINE.# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #bind 127.0.0.1 --- 此处写本机IP地址 重启redis，进行连接测试/software/redis/bin/redis-cli -h 172.31.8.107 -p 6379 如果出现如下，则表明连接成功172.31.8.107:6379&gt; 案例三Redis 运行一段时间之后会报错：Background saving terminated by signal5473:M 01 Aug 2019 15:50:23.601 # Background saving terminated by signal 9 5473:M 01 Aug 2019 15:50:24.002 * 10000 changes in 60 seconds. Saving... 5473:M 01 Aug 2019 15:50:24.021 * Background saving started by pid 7208 5473:M 01 Aug 2019 15:50:27.208 # Background saving terminated by signal 9 5473:M 01 Aug 2019 15:50:30.081 * 10000 changes in 60 seconds. Saving... 5473:M 01 Aug 2019 15:50:30.093 * Background saving started by pid 7234 5473:M 01 Aug 2019 15:50:32.218 # Background saving terminated by signal 9 5473:M 01 Aug 2019 15:50:36.064 * 10000 changes in 60 seconds. Saving... 5473:M 01 Aug 2019 15:50:36.076 * Background saving started by pid 7236 5473:M 01 Aug 2019 15:50:36.293 # Background saving terminated by signal 9 问题原因：还未定位到具体的原因决绝办法：1、加内存（如果已经充分利用了Redis的存储结构来保存了最适合的数据，即Redis层已经最优了，不然的话，需要先优化Redis层） 2、将Redis的Maxmemory调到物理内存的3/5，并且将overcommit_memory=1，这样子虽然可以避免OOM，但是内存是redis运行的瓶颈了。 案例四故障报错：WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command &apos;echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled&apos; as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled. 内核启用THP可能会导致内存使用问题解决办法：临时解决： echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled 永久： 将如下代码写入： /etc/rc.local 文件中 if test -f /sys/kernel/mm/redhat_transparent_hugepage/enabled; then echo never &gt; /sys/kernel/mm/redhat_transparent_hugepage/enabled fi 保存后重启redis]]></content>
      <categories>
        <category>Linux</category>
        <category>redis</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[系统蜜罐opencanary部署]]></title>
    <url>%2F2019%2F03%2F28%2F%E7%B3%BB%E7%BB%9F%E8%9C%9C%E7%BD%90opencanary%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[一、简介内网低交互蜜罐opencanary：opencanary是2015年blackhat在单独发布环节推出的的一款蜜罐工具，纯python模拟多种应用和服务。当模拟的服务被某人使用（交互登录）时，它就会产生相应的日志。Github项目地址1.1 模拟服务：1.端口扫描行为2.ftp登录尝试3.web蜜罐被访问4.web蜜罐被登录5.ssh建立连接6.ssh远程版本发送7.ssh登录尝试8.telnet登录尝试9.mysql登录尝试项目架构图：二、安装管理后台2.1 安装环境安装系统：Centos7 64位系统Python使用系统自带的 Python 2.72.2 系统配置关闭selinuxsetenforce 0 vim /etc/selinux/config # This file controls the state of SELinux on the system. # SELINUX= can take one of these three values: # enforcing - SELinux security policy is enforced. # permissive - SELinux prints warnings instead of enforcing. # disabled - No SELinux policy is loaded. SELINUX=disabled SELINUXTYPE= can take one of three two values: # targeted - Targeted processes are protected, # minimum - Modification of targeted policy. Only selected processes are protected. # mls - Multi Level Security protection. SELINUXTYPE=targeted 然后重启服务器，selinux 便永久生效了查看系统Python版本root@node1 ~]# python -V Python 2.7.5 [root@node1 ~]# 2.3 tornado安装下载web源码和安装依赖[root@node1 src]# git clone https://github.com/p1r06u3/opencanary_web.git 正克隆到 &apos;opencanary_web&apos;... remote: Enumerating objects: 46, done. remote: Counting objects: 100% (46/46), done. remote: Compressing objects: 100% (34/34), done. remote: Total 1083 (delta 20), reused 30 (delta 11), pack-reused 1037 接收对象中: 100% (1083/1083), 3.78 MiB | 101.00 KiB/s, done. 处理 delta 中: 100% (558/558), done. [root@node1 src]# cd opencanary_web/ [root@node1 opencanary_web]# pip install -r requirements.txt 2.4 安装配置mysql2.4.1 下载mysql5.7 安装包wget http://dev.mysql.com/get/mysql57-community-release-el7-8.noarch.rpm 2.4.2 安装mysql 源yum localinstall mysql57-community-release-el7-8.noarch.rpm 2.4.3 检查mysql源是否安装成功yum repolist enabled|grep &quot;mysql.*-community.*&quot; 2.4.4 安装mysqlyum install mysql-server 2.4.5 启动mysql并设置开机自启动systemctl start mysqld systemctl enable mysqld systemctl daemon-reload 2.4.6 修改mysql本地登陆密码mysql安装完成后在/var/log/mysqld.log文件中给root用户生成了一个默认密码通过以下方式找到root默认密码，然后登录mysql进行修改：[root@node1 ~]# grep &apos;temporary password&apos; /var/log/mysqld.log 2019-07-20T13:07:38.462181Z 1 [Note] A temporary password is generated for root@localhost: ponNmM,qj0&lt;Z root@localhost: 后面就是默认初始密码 登录mysql：mysql -u root -p [root@node1 ~]# mysql -u root -p Enter password: Welcome to the MySQL monitor. Commands end with ; or \g. Your MySQL connection id is 4 Server version: 5.7.26 Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type &apos;help;&apos; or &apos;\h&apos; for help. Type &apos;\c&apos; to clear the current input statement. mysql&gt; 重置mysql密码执行修改密码语句：ALTER USER &apos;root&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;new-password&apos;; mysql&gt; ALTER USER &apos;root&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;new-password&apos;; ---新密码需要符合要求,即密码组成应由大、小写字母、数字、符号组成 Query OK, 0 rows affected (0.00 sec) mysql&gt; flush privileges; Query OK, 0 rows affected (0.00 sec) mysql&gt; exit Bye 2.4.7 创建mysql数据库和表结构切换到opencanary_web目录cd /usr/local/src/opencanary_web 登陆mysql创建数据库并还原表结构create database honeypot; use honeypot; source honeypot.sql; 这时数据库中User表内默认用户名和密码为：admin\admin若要修改web后台登录密码请执行sql语句password的值换成自己的32位md5： UPDATE User SET password=&apos;900150983cd24fb0d6963f7d28e17f72&apos; WHERE id=1; 修改web数据库连接密码vim /usr/local/src/opencanary_web/dbs/initdb.py 修改： DB_PWD = &apos;&apos; 修改为自己的mysql密码 2.4.8 单tornado实例启动测试python server.py --port=80 [root@node1 opencanary_web]# python server.py --port=80 Development server is running at http://127.0.0.1:80/ 若输出”Development server is running at http://0.0.0.0:80/ “，且访问主机的ip能够显示出登录后台地址，则web单实例后台启动成功。2.5 安装配置supervisorSupervisor（ http://supervisord.org/ ）是用Python开发的一个client/server服务，是Linux/Unix系统下的一个进程管理工具，不支持Windows系统。它可以很方便的监听、启动、停止、重启一个或多个进程。用Supervisor管理的进程，当一个进程意外被杀死，supervisort监听到进程死后，会自动将它重新拉起，很方便的做到进程自动恢复的功能，不再需要自己写shell脚本来控制。2.5.1 supervisoryum install supervisor 设置开机自启动 systemctl enable supervisord.service 2.5.2 配置文件supervisord 的配置 文件是 /etc/supervisord.conf自定义配置文件目录是/etc/supervisord.d/,该目录下文件以.ini为后缀这里给出我的supervisor子配置：vi /etc/supervisord.d/tornado.ini [group:tornadoes] programs=tornado-8000,tornado-8001,tornado-8002,tornado-8003 [program:tornado-8000] command=python /usr/local/src/opencanary_web/server.py --port=8000 directory=/usr/local/src/opencanary_web autorestart=true redirect_stderr=true stdout_logfile=/var/log/tornado.log loglevel=debug [program:tornado-8001] command=python /usr/local/src/opencanary_web/server.py --port=8001 directory=/usr/local/src/opencanary_web autorestart=true redirect_stderr=true stdout_logfile=/var/log/tornado.log loglevel=debug [program:tornado-8002] command=python /usr/local/src/opencanary_web/server.py --port=8002 directory=/usr/local/src/opencanary_web autorestart=true redirect_stderr=true stdout_logfile=/var/log/tornado.log loglevel=debug [program:tornado-8003] command=python /usr/local/src/opencanary_web/server.py --port=8003 directory=/usr/local/src/opencanary_web autorestart=true redirect_stderr=true stdout_logfile=/var/log/tornado.log loglevel=debug 2.5.3 启动supervisorsystemctl start supervisord 其他常用命令： systemctl stop supervisord # 停止supervisord systemctl restart supervisord # 重启supervisord 2.5.4 启动多tornado实例supervisorctl start tornadoes:* 其他更多supervisord 客户端管理命令 supervisorctl status # 状态 supervisorctl stop nginx #关闭 nginx supervisorctl start nginx #启动 nginx supervisorctl restart nginx #重启 nginx supervisorctl reread supervisorctl update #更新新的配置 2.5.5 查看应用web是否启动成功ps aux|grep python root 3303 0.0 0.9 562428 18316 ? Ssl 7月12 0:49 /usr/bin/python -Es /usr/sbin/tuned -l -P root 14126 0.0 0.7 224872 13804 ? Ss 22:25 0:00 /usr/bin/python /usr/bin/supervisord -c /etc/supervisord.conf root 14128 0.6 1.9 335660 36356 ? Sl 22:25 0:00 python /usr/local/src/opencanary_web/server.py --port=8000 root 14129 0.6 1.9 409648 37572 ? Sl 22:25 0:00 python /usr/local/src/opencanary_web/server.py --port=8001 root 14130 0.6 1.9 335664 36364 ? Sl 22:25 0:00 python /usr/local/src/opencanary_web/server.py --port=8002 root 14131 0.6 1.9 335664 36360 ? Sl 22:25 0:00 python /usr/local/src/opencanary_web/server.py --port=8003 root 14279 0.0 0.0 112728 980 pts/0 R+ 22:27 0:00 grep --color=auto python 2.6 安装nginx反向代理tornado2.6.1 安装nginx可以使用源码编译安装和yum安装这里使用yum安装 。。。。省事 yum -y install nginx 2.6.2 nginx反向代理tornado配置先备份nginx配置文件 cp /etc/nginx/nginx.conf /etc/nginx/nginx.conf.bak 修改配置文件 user nginx; worker_processes 5; error_log /var/log/nginx/error.log warn; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot;&apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; fastcgi_connect_timeout 1800; fastcgi_send_timeout 1800; fastcgi_read_timeout 1800; fastcgi_buffer_size 1024k; fastcgi_buffers 32 1024k; fastcgi_busy_buffers_size 2048k; fastcgi_temp_file_write_size 2048k; map $http_upgrade $connection_upgrade { default upgrade; &apos;&apos; close; } include /etc/nginx/conf.d/*.conf; } 测试配置文件是否正确/sbin/nginx -t --使用-t参数进行验证nginx配置文件是否正确 nginx: the configuration file /etc/nginx/nginx.conf syntax is ok nginx: configuration file /etc/nginx/nginx.conf test is successful 2.6.3 添加/etc/nginx/conf.d/hp.conf配置vi /etc/nginx/conf.d/hp.conf upstream hp { server 127.0.0.1:8000; server 127.0.0.1:8001; server 127.0.0.1:8002; server 127.0.0.1:8003; } server { listen 80; server_name localhost; proxy_connect_timeout 10d; proxy_read_timeout 10d; proxy_send_timeout 10d; location /static/ { alias /usr/local/src/opencanary_web/dist/static/; } location / { proxy_pass http://hp; proxy_pass_header Server; proxy_set_header Host $http_host; proxy_redirect off; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Scheme $scheme; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &quot;upgrade&quot;; } } 启动/重启nginx启动: /sbin/nginx 查看nginx是否已经启动L ps -aux | grep nginx root 15002 0.0 0.0 56724 1212 ? Ss 22:41 0:00 nginx: master process /sbin/nginx nginx 15003 0.0 0.1 57212 2040 ? S 22:41 0:00 nginx: worker process nginx 15004 0.0 0.1 57212 2040 ? S 22:41 0:00 nginx: worker process nginx 15005 0.0 0.1 57212 2040 ? S 22:41 0:00 nginx: worker process nginx 15006 0.0 0.1 57212 2040 ? S 22:41 0:00 nginx: worker process nginx 15007 0.0 0.1 57212 2040 ? S 22:41 0:00 nginx: worker process root 15034 0.0 0.0 112728 980 pts/0 R+ 22:41 0:00 grep --color=auto nginx 访问主机ip的80端口，查看是否可以正常访问、正常登陆。2.7 登陆管理后台http://ip 2.7.1 登陆页面：2.7.2 管理控制台：三、安装客户端当蜜罐管理后台部署完成之后，可以重新启用一台虚拟主机部署客户端。这里优先推荐使用Centos7因为系统比较新默认python环境为2.7.x，类库也比较新。3.1 系统配置系统：Centos 7 Python: Python 2.7.X 安装扩展源 yum -y install epel-release 安装依赖 yum -y install libpcap-devel openssl-devel libffi-devel python-devel gcc python-pip gcc-c++ 3.2 安装opencanary客户端cd /usr/local/src/ git clone https://github.com/p1r06u3/opencanary.git cd opencanary/ 修改配置文件： vi opencanary/data/settings.json 将第2行，device.node_id的值opencanary-1代表将来告警的节点，改为主机名&quot;device.node_id&quot;: &quot;node2&quot;, 将第3行，server.ip改成自己web服务端的ip注意: 如果你的web端，不是80端口，要在配置的ip后面跟上“:端口号”。&quot;server.ip&quot;: &quot;172.31.8.8&quot;, 将第4行，device.listen_addr改成自己本机ip(非127.0.0.1)。&quot;device.listen_addr&quot;: &quot;172.31.8.13&quot;, 3.2.1 安装opencanarypython setup.py sdist cd dist pip install opencanary-0.4.tar.gz 3.2.2 配置端口扫描发现功能端口扫描发现模块是依赖于iptables；需要rsyslog配合产生kern.log日志。安装iptablesyum install iptables-services 配置rsyslog通过rsyslog 控制日志产生位置： vim /etc/rsyslog.conf修改第50行kern.* /var/log/kern.log 3.2.3 重启rsyslogsystemctl restart rsyslog 3.2.4 启动和停止opencanary方法若第一次安装opencanary，需要先运行opencanaryd --copyconfig，会生成/root/.opencanary.conf配置文件。 启动命令: opencanaryd --start 停止命令: opencanaryd --stop 重启命令: opencanaryd --restart opencanary日志: /var/tmp/opencanary.log 3.2.5 启动opencanarydopencanaryd --start 查看进程： ps -aux | grep opencan root 21586 0.1 4.4 412296 83484 ? Sl 23:46 0:00 /usr/bin/python2 /usr/bin/twistd -y /usr/bin/opencanary.tac --pidfile /usr/bin/opencanaryd.pid --syslog --prefix=opencanaryd 在后台管理页面查看主机状态：可以看到新增加的node2节点已经出现在管理页面里3.2.6 卸载opencanary方法：首先卸载旧客户端 opencanaryd --stop rm -rf /root/.opencanary.conf rm -rf /usr/local/src/opencanary/ pip uninstall opencanary -y iptables -t mangle -F 安装新客户端 curl -O https://raw.githubusercontent.com/p1r06u3/opencanary_web/master/install/install_opencanary_agent.sh bash install_opencanary_agent.sh 四、后台可统计的信息1.ftp登录尝试； 2.http访问请求； 3.http登录请求； 4.ssh建立连接； 5.ssh远程版本发送； 6.ssh登录尝试； 7.telnet登录尝试； 8.全端口(SYN)扫描识别; 9.NMAP OS扫描识别； 10.NMAP NULL扫描识别； 11.NMAP XMAS扫描识别； 12.NMAP FIN扫描识别； 13.mysql登录尝试； 14.git clone请求； 16.ntp monlist请求（默认关闭）； 16.redis命令请求； 17.TCP连接请求； 18.vnc连接请求； 19.rdp协议windows远程登录； 20.snmp扫描； 21.sip请求； 22.mssql登录sql账户认证； 23.mssql登录win身份认证； 24.http代理登录尝试； 五、参考：自动安装手动安装]]></content>
      <categories>
        <category>安全</category>
      </categories>
      <tags>
        <tag>安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Python统计nginx日志前十个IP的访问量，并以柱状图显示]]></title>
    <url>%2F2018%2F12%2F28%2F%E4%BD%BF%E7%94%A8Python%E7%BB%9F%E8%AE%A1nginx%E6%97%A5%E5%BF%97%E5%89%8D%E5%8D%81%E4%B8%AAIP%E7%9A%84%E8%AE%BF%E9%97%AE%E9%87%8F%EF%BC%8C%E5%B9%B6%E4%BB%A5%E6%9F%B1%E7%8A%B6%E5%9B%BE%E6%98%BE%E7%A4%BA%2F</url>
    <content type="text"><![CDATA[1、脚本代码可参考本人博客园文章import matplotlib.pyplot as plt nginx_file = &apos;&apos; --填写nginx日志文件名，需在同一目录 ip = {} #筛选nginx日志文件中的IP with open(nginx_file) as f: for i in f.readlines(): s = i.strip().split()[0] lengh = len(ip.keys()) #统计每个IP的访问以字典存储 if s in ip.keys(): ip[s] = ip[s] + 1 else: ip[s] = 1 #以IP出现的次数排序返回对象为list ip = sorted(ip.items(), key=lambda e:e[1], reverse=True) #取列表前十 newip = ip[0:20:1] tu = dict(newip) x = [] y = [] for k in tu: x.append(k) y.append(tu[k]) plt.title(&apos;ip access&apos;) plt.xlabel(&apos;ip address&apos;) plt.ylabel(&apos;pv&apos;) #X 轴项的翻转角度 plt.xticks(rotation=70) #显示每个柱状图的值 for a,b in zip(x,y): plt.text(a, b, &apos;%.0f&apos; % b, ha=&apos;center&apos;, va= &apos;bottom&apos;,fontsize=7) plt.bar(x,y) plt.legend() plt.show() 2、效果图:]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx入门(安装配置)]]></title>
    <url>%2F2018%2F12%2F26%2FNginx%E5%85%A5%E9%97%A8-%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Nginx 是什么？nginx是俄罗斯人 Igor Sysoev为俄罗斯访问量第二的Rambler.ru站点开发的一个十分轻量级的HTTP服务器。它是一个高性能的HTTP和反向代理服务器，同时也可以作为IMAP/POP3/SMTP的代理服务器。nginx使用的是BSD许可。Nginx 以事件驱动的方式编写，所以有非常好的性能，同时也是一个非常高效的反向代理、负载平衡。Nginx 因为它的稳定性、丰富的模块库、灵活的配置和低系统资源的消耗而闻名。核心特点：高并发请求的同时保持高效的服务热部署低内存消耗处理响应请求很快具有很高的可靠性nginx可以实现高效的反向代理、负载均衡。一、安装1.1 安装编译工具及依赖yum -y install make zlib zlib-devel gcc-c++ libtool openssl openssl-devel pcre pcre-devel 1.2 安装nginx下载nginxwget http://nginx.org/download/nginx-1.8.1.tar.gz 解压安装tar -xf nginx-1.8.1.tar.gz -C /software/ cd /software/ &amp;&amp; mkdir nginx &amp;&amp; cd nginx-1.8.1 编译，指定nginx 安装目录：/software/nginx./configure --prefix=/software/nginx --with-http_ssl_module --with-http_stub_status_module --with-threads --with-file-aio 安装make &amp;&amp; make install 启动nginx/software/nginx/sbin/nginx -t nginx: the configuration file /software/nginx/conf/nginx.conf syntax is ok nginx: configuration file /software/nginx/conf/nginx.conf test is successful /software/nginx/sbin/nginx ps -ef | grep nginx root 22917 1 0 22:01 ? 00:00:00 nginx: master process /software/nginx/sbin/nginx nobody 22918 22917 0 22:01 ? 00:00:00 nginx: worker process root 22920 21803 0 22:01 pts/1 00:00:00 grep --color=auto nginx 1.3 访问测试http://IPaddr,出现以下页面nginx就已经安装成功二、配置2.1 创建nginx 运行用户/usr/sbin/groupadd www /usr/sbin/useradd -g www www 2.2 配置nginx.confuser www www; --- 指定nginx启动用户 worker_processes 1; error_log logs/nginx_error.log crit; ---配置日志存储位置和级别 pid logs/nginx.pid; --- 设置nginx.pid 文件存储位置 events { worker_connections 65535; } http { include mime.types; default_type application/octet-stream; log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; sendfile on; #keepalive_timeout 0; keepalive_timeout 65; server { listen 80; server_name 172.31.8.11; #charset koi8-r; access_log logs/172.31.8.11_access.log main; --- 设置日志格式 access_log logs/172.31.8.11_json_access.log main; --- 设置json 日志格式 location / { root html; index index.html index.htm; } #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \.php$ { # proxy_pass http://127.0.0.1; #} # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \.php$ { # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #} # deny access to .htaccess files, if Apache&apos;s document root # concurs with nginx&apos;s one # #location ~ /\.ht { # deny all; #} } # another virtual host using mix of IP-, name-, and port-based configuration # #server { # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location / { # root html; # index index.html index.htm; # } #} # HTTPS server # #server { # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / { # root html; # index index.html index.htm; # } #} } /software/nginx/sbin/nginx -t nginx: the configuration file /software/nginx/conf/nginx.conf syntax is ok nginx: configuration file /software/nginx/conf/nginx.conf test is successful /software/nginx/sbin/nginx -s reload 相关命令： /usr/local/webserver/nginx/sbin/nginx -s reload -- 重新载入配置文件 /usr/local/webserver/nginx/sbin/nginx -s reopen -- 重启 Nginx /usr/local/webserver/nginx/sbin/nginx -s stop -- 停止 Nginx 以上就是Nginx安装后的简单配置]]></content>
      <categories>
        <category>Linux</category>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PTES渗透测试执行标准]]></title>
    <url>%2F2018%2F09%2F17%2FPTES%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E6%89%A7%E8%A1%8C%E6%A0%87%E5%87%86%2F</url>
    <content type="text"><![CDATA[渗透测试注意事项：1、不要进行恶意攻击2、不要做傻事3、在没有获得书面授权时，不要攻击任何目标4、考虑清楚攻击将会带来的后果4、如果干了非法的事情，记得天网恢恢疏而不漏参考官方对于渗透测试执行标准描述（PTES）一：前期交互阶段在前期交互阶段，渗透测试团队与客户组织进行交互讨论，最重要的是确定渗透测试的范围、目标、限制条件以及合同细节该阶段通常涉及收集客户需求，准备测试计划、定义测试范围与边界、定义业务目标、项目管理与规划等活动二：情报收集阶段在目标范围确定之后，将进入情报搜集（Information Gathering）阶段，渗透团队可以利用各种信息来源与搜集技术方法，尝试更多关于组织网络拓扑、系统配置与安全防御措施的信息。渗透测试者可以使用情报搜集方法包括公开来源信息查询、google Hacking 、社会工程学、网络踩点、扫描探测、被动监听、服务查点等。而对目标系统的情报探查能力是渗透者一项非常重要的技能，情报搜集是否充分在很大程度上决定了渗透测的成败，因为如果你遗漏关键的情报信息，你将可能在后面的阶段一无所获。三：威胁建模阶段在搜集到充分的情报信息之后，渗透测试团队的成员们停下敲击键盘，大家聚到一起针对获取的信息进行威胁建模（Threat Modeling）与攻击规划。这是渗透测试过程中非常重要，但很容易被忽视的一个关键点。通过团队共同的缜密情报分析与攻击思路头脑风暴，可以从大量的信息情报中理清头绪，确定出最可行的攻击通道。四：漏洞分析阶段在确定出最可行的攻击通道之后，接下来需要考虑该如何取得目标系统的访问控制权，即漏洞分析（Vulnerability Analysis）阶段。在该阶段，渗透测试者需要综合分析前几个阶段获取并汇总的情报信息，特别是安全漏洞扫描结果、服务查点信息等，通过搜索可获取的渗透代码资源，找出可以实施渗透攻击的攻击点，并在实验环境中进行验证。在该阶段，高水平的渗透测试团队还会针对攻击通道上的一些关键系统与服务进行安全漏洞探测与挖掘，期望找出可被利用的未知安全漏洞，并开发出渗透代码，从而打开攻击通道上的关键路径。五：渗透攻击阶段渗透攻击（Exploitation）是渗透测试过程中最具有魅力的环节。在此环节中，渗透测试团队需要利用他们所找出的目标系统安全漏洞，来真正入侵系统当中，获得访问控制权。渗透攻击可以利用公开渠道可获取的渗透代码，但一般在实际应用场景中，渗透测试者还需要充分地考虑目标系统特性来定制渗透攻击，并需要挫败目标网络与系统中实施的安全防御措施，才能成功达成渗透目的。在黑盒测试中，渗透测试者还需要考虑对目标系统检测机制的逃逸，从而避免造成目标组织安全响应团队的警觉和发现六：后渗透攻击阶段后渗透攻击（Post Exploitation）是整个渗透测试过程中最能够体现渗透测试团队创造力与技术能力的环节。前面的环节可以说都是在按部就班地完成非常普遍的目标，而在这个环节中，需要渗透测试团队根据目标组织的业务经营模式、保护资产形式与安全防御计划的不同特点，自主设计出攻击目标，识别关键基础设施，并寻找客户组织最具价值和尝试安全保护的信息和资产，最终达成能够对客户组织造成最重要业务影响的攻击途径。在不同的渗透测试场景中，这些攻击目标与途径可能是千变万化的，而设置是否准确并且可行，也取决于团队自身的创新意识、知识范畴、实际经验和技术能力。七：报告阶段渗透测试过程最终向客户组织提交，取得认可并成功获得合同付款的就是一份渗透测试报告（Reporting）。这份报告凝聚了之前所有阶段之中渗透测试团队所获取的关键情报信息、探测和发掘出的系统安全漏洞、成功渗透攻击的过程，以及造成业务影响后果的攻击途径，同时还要站在防御者的角度上，帮助他们分析安全防御体系中的薄弱环节、存在的问题，以及修补与升级技术方案。八：渗透术语：渗透攻击（Exploit）攻击者利用安全漏洞，所进行的攻击行为，常见的渗透攻击技术包括缓冲区溢出、web应用程序漏洞攻击（SQL注入）、利用配置错误等攻击载荷（Payload）目标系统在被渗透攻击之后执行的代码Shellcode在渗透攻击时作为攻击载荷运行的一组机器指令，通常用汇编语言编写模块（Module）一段软件代码组件监听器（Listener）用来等待连入网络链接的组件]]></content>
      <categories>
        <category>安全</category>
        <category>渗透测试</category>
      </categories>
      <tags>
        <tag>安全</tag>
        <tag>渗透测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker 仓库harbor搭建]]></title>
    <url>%2F2018%2F09%2F12%2Fdocker-%E4%BB%93%E5%BA%93harbor%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[一、初始化在正式安装harbor之前，需要对OS环境进行初始化1.1 升级OS内核，具体内核升级步骤可以自己了解下1.2 安装yum源因为需要安装相关的以来软件，所以需要安装yum源，安装前先将原先的yum备份[root@harbor yum.repos.d]# mv CentOS-Base.repo CentOS-Base.repo.bak [root@harbor yum.repos.d]# vim CentOS-Base.repo [base] name=CentOS-$releasever – Base – 163.com #mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=os baseurl=http://mirrors.163.com/centos/$releasever/os/$basearch/ gpgcheck=1 gpgkey=http://mirrors.163.com/centos/RPM-GPG-KEY-CentOS-7 #released updates [updates] name=CentOS-$releasever – Updates – 163.com #mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=updates baseurl=http://mirrors.163.com/centos/$releasever/updates/$basearch/ gpgcheck=1 gpgkey=http://mirrors.163.com/centos/RPM-GPG-KEY-CentOS-7 #additional packages that may be useful [extras] name=CentOS-$releasever – Extras – 163.com #mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=extras baseurl=http://mirrors.163.com/centos/$releasever/extras/$basearch/ gpgcheck=1 gpgkey=http://mirrors.163.com/centos/RPM-GPG-KEY-CentOS-7 #additional packages that extend functionality of existing packages [centosplus] name=CentOS-$releasever – Plus – 163.com baseurl=http://mirrors.163.com/centos/$releasever/centosplus/$basearch/ gpgcheck=1 enabled=0 gpgkey=http://mirrors.163.com/centos/RPM-GPG-KEY-CentOS-7 1.3 安装阿里云epel源wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo 1.4 安装dockeryum -y install docker 启动docker并查看docker版本1.5 安装docker-composeyum -y install certbot libevent-devel gcc libffi-devel python-devel openssl-devel python2-pip 使用pip的方式进行安装，命令如下pip install -U docker-compose 查看安装的版本docker-compose version 二、下载安装harbor，选择自己需要的版本官网地址：http://harbor.orientsoft.cn/2.1 修改Harbor配置文件，修改服务地址[root@harbor ~]# ls anaconda-ks.cfg harbor-offline-installer-v1.4.0.tgz [root@harbor ~]# tar xf harbor-offline-installer-v1.4.0.tgz [root@harbor ~]# ls anaconda-ks.cfg harbor harbor-offline-installer-v1.4.0.tgz [root@harbor ~]# mv harbor /usr/local/ [root@harbor ~]# vim harbor.cfg 修改hostname为主机的IP（没有域名的情况下）2.2 修改harbor的默认admin密码（默认密码为Harbor12345）2.3 安装harbor步骤一会下载相关的docker镜像，这个过程根据各自的网络情况不同花费的时间也不同，相关的docker镜像如下：docker images 2.4 查看容器，可以看到没有Notary与Clair相关服务；也可使用”docker ps”；“docker-compose ps”需要在”docker-compose.yml”文件所在目录执行相关操作[root@harbor harbor]# docker-compose ps 三、安装后配置3.1 访问harbor ui （注意服务器的防火墙和selinux，可以关闭或者放行相关端口）admin/默认密码harbor安装完成3.2 harbor 使用docker login报错的问题从harbor安装文档中可以看到https://github.com/vmware/harbor/blob/master/docs/installation_guide.md在Harbor主机和客户机都对这个文件进行设置/etc/docker/daemon.json：{ &quot;insecure-registries&quot;:[&quot;192.168.33.10&quot;] } 四、简单使用4.1 向harbor上推拉镜象给docker.io/tomcat这个镜像打上tag[root@harbor ~]# docker tag docker.io/tomcat 172.31.8.25/library/tomcat2 4.2 推送至harbor[root@harbor ~]# docker push 172.31.8.25/library/tomcat2]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[(二)、Ansible在使用过程中出现的错误解决方法]]></title>
    <url>%2F2018%2F09%2F02%2F%E4%BA%8C-%E3%80%81Ansible%E5%9C%A8%E4%BD%BF%E7%94%A8%E8%BF%87%E7%A8%8B%E4%B8%AD%E5%87%BA%E7%8E%B0%E7%9A%84%E9%94%99%E8%AF%AF%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[1.安装完成后允许命令出错Traceback (most recent call last): File &quot;/usr/bin/ansible&quot;, line 197, in &lt;module&gt; (runner, results) = cli.run(options, args) File &quot;/usr/bin/ansible&quot;, line 163, in run extra_vars=extra_vars, File &quot;/usr/lib/python2.6/site-packages/ansible/runner/__init__.py&quot;, line 233, in __init__ cmd = subprocess.Popen([&apos;ssh&apos;,&apos;-o&apos;,&apos;ControlPersist&apos;], stdout=subprocess.PIPE, stderr=subprocess.PIPE) File &quot;/usr/lib64/python2.6/subprocess.py&quot;, line 639, in __init__ errread, errwrite) File &quot;/usr/lib64/python2.6/subprocess.py&quot;, line 1228, in _execute_child raise child_exception OSError: [Errno 2] No such file or directory 解决办法yum -y install openssh-clients2.出现Error: ansible requires a json module, none found!SSH password: 10.0.1.110 | FAILED &gt;&gt; { &quot;failed&quot;: true, &quot;msg&quot;: &quot;Error: ansible requires a json module, nonefound!&quot;, &quot;parsed&quot;: false } 解决办法python版本过低，可以升级python或者python-simplejson3.安装完成后链接客户端报错（配图为我在使用ansible推送文件到客户端的时候遇到的，这个客户端是第一次推送）FAILED =&gt; Using a SSH password insteadof a key is not possible because Host Key checking is enabled and sshpass doesnot support this. Please add this host&apos;sfingerprint to your known_hosts file to manage this host. 解决办法：在ansible 服务器上使用ssh 登陆下/etc/ansible/hosts 里面配置的服务器。然后再次使用ansible 去管理就不会报上面的错误了！但这样大批量登陆就麻烦来。因为默认ansible是使用key验证的，如果使用密码登陆的服务器，使用ansible的话，要不修改ansible.cfg配置文件的ask_pass = True给取消注释，要不就在运行命令时候加上-k，这个意思是-k, –ask-pass ask for SSH password。再修改：host_key_checking= False即可4.如果客户端不在know_hosts里将会报错paramiko: The authenticity of host &apos;192.168.24.15&apos;can&apos;t be established. The ssh-rsa key fingerprint is397c139fd4b0d763fcffaee346a4bf6b. Are you sure you want to continueconnecting (yes/no)? 解决办法需要修改ansible.cfg的#host_key_checking= False取消注释5.出现FAILED =&gt; FAILED: not a valid DSA private key file解决办法：需要你在最后命令内添加参数-k6.openssh升级后无法登录报错PAM unable todlopen(/lib64/security/pam_stack.so): /lib64/security/pam_stack.so: cannot openshared object file: No such file or directory 解决方法：sshrpm 升级后会修改/etc/pam.d/sshd 文件。需要升级前备份此文件最后还原即可登录。7.第一次系统初始化运行生成本机ansible用户key时报错failed: [127.0.0.1] =&gt;{&quot;checksum&quot;: &quot;f5f2f20fc0774be961fffb951a50023e31abe920&quot;,&quot;failed&quot;: true} msg: Aborting, target uses selinux but pythonbindings (libselinux-python) aren&apos;t installed! FATAL: all hosts have already failed –aborting 解决办法yum -y install libselinux-python参考: http://blog.csdn.net/longxibendi/article/details/46989735]]></content>
      <categories>
        <category>自动化</category>
      </categories>
      <tags>
        <tag>自动化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible]]></title>
    <url>%2F2018%2F09%2F01%2FAnsible%2F</url>
    <content type="text"><![CDATA[1、ansible介绍：Ansible是一款基于Python开发的自动化运维工具，主要是实现批量系统配置、批量程序部署、批量运行命令、批量执行任务等等诸多功能。Ansible是一款灵活的开源工具，能够很大程度简化运维中的配置管理与流程控制方式，它利用推送方式对客户系统加以配置，这样所有工作都可在主服务器端完成。Asible是基于模块工作的，其本身没有批量部署的能力，Ansible~一款运维自动化的软件！1.1特性(1)、no agents：不需要在被管控主机上安装任何客户端；(2)、no server：无服务器端，使用时直接运行命令即可；(3)、modules in any languages：基于模块工作，可使用任意语言开发模块；(4)、yaml，not code：使用yaml语言定制剧本playbook；(5)、ssh by default：基于SSH工作；(6)、strong multi-tier solution：可实现多级指挥。1.1 优点(1)、轻量级，无需在客户端安装agent，更新时，只需在操作机上进行一次更新即可；(2)、批量任务执行可以写成脚本，而且不用分发到远程就可以执行；(3)、使用python编写，维护更简单，ruby语法过于复杂；(4)、支持sudo。2、ansible安装安装epel 源：rpm -ivh https://dl.fedoraproject.org/pub/epel/epel-release-latest-6.noarch.rpm安装ansible ：yum install ansible -yssh-keygen 生成秘钥文件,如果不想输入密码可以一直回车ssh-keygen -t rsacd /root/.ssh/ &amp;&amp; ll ./*配置ansible 的hosts 文件：vim /etc/ansible/hosts]]></content>
      <categories>
        <category>自动化</category>
      </categories>
      <tags>
        <tag>自动化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[solr6+tomcat8+zookeeper 环境部署]]></title>
    <url>%2F2018%2F08%2F22%2Fsolr6%2Btomcat8%2Bzookeeper%20%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[安装概述：以下是部署环境：系统环境为：三台系统为Centos 6.8 的服务器主机IP：10.6.11.19 10.6.11.23 10.6.11.22软件环境为：tomcat 8.5.24jdk1.8.0_162solr6.6.3zookeepr-3.4.10tomcat安装不多说，配置java环境即可启动，出现以下画面就说明tomcat服务已经部署完成将solr6部署到tomcat 8 容器内（仅以单节点安装为例，三个节点的安装步骤是一样的）cp -r /home/tomcat/software/solr-6.6.3/server/solr-webapp/webapp /home/tomcat/apache-tomcat-8.5.24-solr/webapps/solr cp -r /home/tomcat/software/solr-6.6.3/server/lib/metrics* /home/tomcat/apache-tomcat-8.5.24-solr/webapps/solr/WEB-INF/lib/ rm -f /home/tomcat/apache-tomcat-8.5.24-solr/webapps/solr/WEB-INF/lib/metrics-jetty9-3.2.2.jar cp -r /home/tomcat/software/solr-6.6.3/server/lib/ext/* /home/tomcat/apache-tomcat-8.5.24-solr/webapps/solr/WEB-INF/lib/ cp -r /home/tomcat/software/solr-6.6.3/dist/solr-dataimporthandler-* /home/tomcat/apache-tomcat-8.5.24-solr/webapps/solr/WEB-INF/lib cp -r /home/tomcat/software/solr-6.6.3/dist/solr-clustering-6.6.3.jar /home/tomcat/apache-tomcat-8.5.24-solr/webapps/solr/WEB-INF/lib mkdir /home/tomcat/apache-tomcat-8.5.24-solr/webapps/solr/WEB-INF/classes cp -r /home/tomcat/software/solr-6.6.3/server/resources/log4j.properties /home/tomcat/apache-tomcat-8.5.24-solr/webapps/solr/WEB-INF/classes 创建solrhome目录mkdir /home/tomcat/apache-tomcat-8.5.24-solr/solrhomecp -r /home/tomcat/software/solr-6.6.3/server/solr/* /home/tomcat/apache-tomcat-8.5.24-solr/solrhome/修改web.xml文件，配置solrhome目录和solr访问权限vim /home/tomcat/apache-tomcat-8.5.24-solr/webapps/solr/WEB-INF/web.xml找到solr/home 根据自己的实际情况配置solr路径&lt;env-entry&gt; &lt;env-entry-name&gt;solr/home&lt;/env-entry-name&gt; &lt;env-entry-value&gt;/home/tomcat/apache-tomcat-8.5.24-solr/solrhome&lt;/env-entry-value&gt; &lt;env-entry-type&gt;java.lang.String&lt;/env-entry-type&gt; &lt;/env-entry&gt; 配置访问权限，注释下图红圈部分内容修改tomcat server.xml文件，配置服务访问端口vim /home/tomcat/apache-tomcat-8.5.24-solr/conf/server.xml&lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; maxHttpHeaderSize=&quot;8192&quot; connectionTimeout=&quot;20000&quot; maxThreads=&quot;150&quot; maxSpareThreads=&quot;75&quot; redirectPort=&quot;8443&quot; /&gt; &lt;!-- A &quot;Connector&quot; using the shared thread pool--&gt; 修改solr配置文件 host设置为本机IP，port设置和tomcat端口一致，均为8080vim /home/tomcat/apache-tomcat-8.5.24-solr/solrhome/solr.xml&lt;solr&gt; &lt;solrcloud&gt; &lt;str name=&quot;host&quot;&gt;${host:10.6.11.19}&lt;/str&gt; &lt;int name=&quot;hostPort&quot;&gt;${jetty.port:8080}&lt;/int&gt; &lt;str name=&quot;hostContext&quot;&gt;${hostContext:solr}&lt;/str&gt; &lt;bool name=&quot;genericCoreNodeNames&quot;&gt;${genericCoreNodeNames:true}&lt;/bool&gt; &lt;int name=&quot;zkClientTimeout&quot;&gt;${zkClientTimeout:30000}&lt;/int&gt; &lt;int name=&quot;distribUpdateSoTimeout&quot;&gt;${distribUpdateSoTimeout:600000}&lt;/int&gt; &lt;int name=&quot;distribUpdateConnTimeout&quot;&gt;${distribUpdateConnTimeout:60000}&lt;/int&gt; &lt;str name=&quot;zkCredentialsProvider&quot;&gt;${zkCredentialsProvider:org.apache.solr.common.cloud.DefaultZkCredentialsProvider}&lt;/str&gt; &lt;str name=&quot;zkACLProvider&quot;&gt;${zkACLProvider:org.apache.solr.common.cloud.DefaultZkACLProvider}&lt;/str&gt; &lt;/solrcloud&gt; &lt;shardHandlerFactory name=&quot;shardHandlerFactory&quot; class=&quot;HttpShardHandlerFactory&quot;&gt; &lt;int name=&quot;socketTimeout&quot;&gt;${socketTimeout:600000}&lt;/int&gt; &lt;int name=&quot;connTimeout&quot;&gt;${connTimeout:60000}&lt;/int&gt; &lt;/shardHandlerFactory&gt; &lt;/solr&gt; 重启tomcat 服务，验证安装访问地址：http://IP:8080/solr/#/出现以上页面，solr就已成功部署到tomcat容器内创建根据需求创建分片,使用以下命令进行创建：http://IP:8080/solr/admin/collections?action=CREATE&amp;name=分片名称&amp;numShards=分片数&amp;replicationFactor=副本数&amp;maxShardsPerNode=节点数&amp;collection.configName=conf目录名称 例如：http://10.6.11.19:8080/solr/admin/collections?action=CREATE&amp;name=user&amp;numShards=2&amp;replicationFactor=3&amp;maxShardsPerNode=3&amp;collection.configName=user 出现以下参数即说明分片创建成功访问http://IP:8080/solr/#/~cloud 验证分片使用此命令创建了两个分片，三个副本一般只可以创建两个副本，增加&amp;maxShardsPerNode=3&amp;collection.configName=user 参数突破副本创建限制]]></content>
      <categories>
        <category>Linux</category>
        <category>搜索</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>solr</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单臂路由的简单配置]]></title>
    <url>%2F2018%2F08%2F06%2F%E5%8D%95%E8%87%82%E8%B7%AF%E7%94%B1%E7%9A%84%E7%AE%80%E5%8D%95%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[操作步骤：路由器配置：Router&gt;en Router#config t Enter configuration commands, one per line. End with CNTL/Z. Router(config)#no ip domain-lookup Router(config)#line console 0 Router(config-line)#exec-timeout 0 0 Router(config-line)#logging synchronous Router(config-line)#exit Router(config)#int f0/0.1 Router(config-subif)#encapsulation dot1Q 20 Router(config-subif)#ip address 192.168.10.1 255.255.255.0 Router(config-subif)#no shutdown Router(config-subif)#exit Router(config)#int f0/0.2 Router(config-subif)#encapsulation dot1Q 10 Router(config-subif)#ip address 172.18.74.1 255.255.255.0 Router(config-subif)#no shutdown Router(config-subif)#int f0/0 Router(config-if)#no shut Router(config-if)# %LINK-5-CHANGED: Interface FastEthernet0/0, changed state to up %LINEPROTO-5-UPDOWN: Line protocol on Interface FastEthernet0/0, changed state to up %LINK-5-CHANGED: Interface FastEthernet0/0.1, changed state to up %LINEPROTO-5-UPDOWN: Line protocol on Interface FastEthernet0/0.1, changed state to up %LINK-5-CHANGED: Interface FastEthernet0/0.2, changed state to up %LINEPROTO-5-UPDOWN: Line protocol on Interface FastEthernet0/0.2, changed state to up Router(config-if)# SwitchA 配置：SwitchA&gt;en SwitchA#config t Enter configuration commands, one per line. End with CNTL/Z. SwitchA(config)#no ip domain-lookup SwitchA(config)#line console 0 SwitchA(config-line)#exec-timeout 0 0 SwitchA(config-line)#logging synchronous SwitchA(config-line)#exit SwitchA(config)#int f0/1 SwitchA(config-if)#switchport mode trunk SwitchA(config-if)# %LINEPROTO-5-UPDOWN: Line protocol on Interface FastEthernet0/1, changed state to down %LINEPROTO-5-UPDOWN: Line protocol on Interface FastEthernet0/1, changed state to up SwitchA(config-if)#exit SwitchA(config)#int f0/2 SwitchA(config-if)#switchport mode trunk SwitchA(config-if)# %LINEPROTO-5-UPDOWN: Line protocol on Interface FastEthernet0/2, changed state to down %LINEPROTO-5-UPDOWN: Line protocol on Interface FastEthernet0/2, changed state to up SwitchA(config-if)#exit SwitchA(config)#vlan 10 SwitchA(config-vlan)#exit SwitchA(config)#vlan 20 SwitchA(config-vlan)#exit SwitchA(config)#int f0/3 SwitchA(config-if)#switchport access vlan 10 SwitchA(config-if)#exit SwitchA(config)#int f0/4 SwitchA(config-if)#switchport access vlan 20 SwitchA(config-if)# SwitchB 配置:SwitchB&gt;en SwitchB#config t Enter configuration commands, one per line. End with CNTL/Z. SwitchB(config)#line console 0 SwitchB(config-line)#exec-timeout 0 0 SwitchB(config-line)#logging synchronous SwitchB(config-line)#exit SwitchB(config)#no ip domain-lookup SwitchB(config)#int f0/1 SwitchB(config-if)#switchport mode trunk SwitchB(config-if)#exit SwitchB(config)#vlan 10 SwitchB(config-vlan)#exit SwitchB(config)#vlan 20 SwitchB(config-vlan)#exit SwitchB(config)#int f0/2 SwitchB(config-if)#switchport access vlan 10 SwitchB(config-if)#exit SwitchB(config)#int f0/3 SwitchB(config-if)#switchport access vlan 20 SwitchB(config-if)# 测试:在PC3 ping PC0、1、2在PC0 ping pc1、2、3参数说明：config t 进入全局配置模式 no ip domain-lookup 禁用DNS查找功能 line console 0 进入console #配置模式 exec-timeout 0 0 配置控制台会话永不超时 logging synchronous 配置控制台输出日志同步 int f0/0.1 进入子接口 encapsulation dot1Q 20 设置该接口的封装模式为802.1q，并配置vlan20服务 ip address 192.168.10.1 255.255.255.0 配置IP地址和子网掩码 no shutdown 开启子接口 switchport mode trunk 把端口设置为trunk模式 vlan 10 创建vlan10 switchport access vlan 10 把端口加入到vlan当中]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat 入门(安装配置篇)]]></title>
    <url>%2F2018%2F07%2F09%2Ftomcat-%E5%85%A5%E9%97%A8(%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%E7%AF%87)%2F</url>
    <content type="text"><![CDATA[tomcat简介Tomcat 服务器是一个免费的开放源代码的Web 应用服务器，Tomcat是Apache 软件基金会（Apache Software Foundation）的Jakarta 项目中的一个核心项目，它早期的名称为catalina，后来由Apache、Sun 和其他一些公司及个人共同开发而成，并更名为Tomcat。Tomcat 是一个小型的轻量级应用服务器，在中小型系统和并发访问用户不是很多的场合下被普遍使用，是开发和调试JSP 程序的首选，因为Tomcat 技术先进、性能稳定，成为目前比较流行的Web 应用服务器。Tomcat是应用（java）服务器，它只是一个servlet容器，是Apache的扩展，但它是独立运行的。目前最新的版本为Tomcat 8.0.24 Released。Tomcat不是一个完整意义上的Jave EE服务器，它甚至都没有提供对哪怕是一个主要Java EE API的实现；但由于遵守apache开源协议，tomcat却又为众多的java应用程序服务器嵌入自己的产品中构建商业的java应用程序服务器，如JBoss和JOnAS。尽管Tomcat对Jave EE API的实现并不完整，然而很企业也在渐渐抛弃使用传统的Java EE技术（如EJB）转而采用一些开源组件来构建复杂的应用。这些开源组件如Structs、Spring和Hibernate，而Tomcat能够对这些组件实现完美的支持。详细请参考-运维生存时间1、安装环境:Centos 7 tomcat版本: apache-tomcat-8.5.42.tar java版本: java8官方网站下载tomcat82、安装上传至Linux 服务器创建tomcat安装目录mkdir /tomcat 解压tomcat、jdk[root@node1 tomcat]# ll 总用量 178712 -rw-r--r--. 1 root root 9711748 7月 9 10:55 apache-tomcat-8.5.42.tar.gz -rw-r--r--. 1 root root 173281904 7月 9 10:55 jdk-8u51-linux-x64.tar.gz [root@node1 tomcat]# tar xf jdk-8u51-linux-x64.tar.gz [root@node1 tomcat]# tar xf apache-tomcat-8.5.42.tar.gz [root@node1 tomcat]# 3、启动脚本配置#!/bin/bash source /etc/sysconfig/i18n export JAVA_HOME=/tomcat/jdk1.8.0_51 export PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$PATH --配置启动java export CLASSPATH=.$CLASSPATH:$JAVA_HOME/lib:$JAVA_HOME/jre/lib:$JAVA_HOME/lib/tools.jar export TOMCAT_HOME=/tomcat/apache-tomcat-8.5.42/ export PATH=$PATH:$TOMCAT_HOME/bin #export JAVA_OPTS=&quot;$JAVA_OPTS -Xms10000m -Xmx10000m -Xmn4000m -XX:PermSize=256m -XX:MaxPermSize=512m&quot; -配置程序内存 PROG=&quot;tomcat&quot; IP_ADDR=$(/sbin/ifconfig eth0 | grep &quot;inet addr&quot; | awk &apos;{print $2}&apos; | awk -F &quot;:&quot; &apos;{print $2}&apos;) tomcat_start() ---启动tomcat { rm -fr /tomcat/apache-tomcat-8.5.42/work/* ----删除缓存 rm -fr /tomcat/apache-tomcat-8.5.42/temp/* ----删除临时缓存 echo $&quot;Starting $IP_ADDR $PROG: &quot; cd /tomcat/apache-tomcat-8.5.42/bin/ ./startup.sh echo &quot;tomcat 8 starting......&quot; } tomcat_log() ---查看程序日志 { echo -n $&quot;ShowLoging $IP_ADDR $PROG log: &quot; tail -n200 -f /tomcat/apache-tomcat-8.5.42/logs/catalina.out } tomcat_stop() ---停止tomcat { echo $&quot;Stopping $IP_ADDR $PROG: &quot; kill $(ps -ef | grep java | grep -v &quot;grep&quot; | grep &quot;apache-tomcat&quot; |awk -F &apos; &apos; &apos;{print $2}&apos;) sleep 12 TOMCAT_STATUS1=$(ps -ef | grep java | grep -v &quot;grep&quot;| grep &quot;apache-tomcat&quot;) if [ -n &quot;$TOMCAT_STATUS1&quot; ];then echo &quot;Run Kill -9&quot; kill -9 $(ps -ef | grep java | grep -v &quot;grep&quot; | grep &quot;apache-tomcat&quot; |awk -F &quot; &quot; &apos;{print $2}&apos;) sleep 2 fi TOMCAT_STATUS2=$(ps -ef | grep java | grep -v &quot;grep&quot;| grep &quot;apache-tomcat&quot; ) if [ -z &quot;$TOMCAT_STATUS2&quot; ];then echo &quot;Tomcat Stop ok&quot; else exit 1 fi } tomcat_status() ---查看tomcat程序状态 { ps -ef | grep java | grep -v &quot;grep&quot;| grep &quot;tomcat&quot; } case &quot;$1&quot; in start) tomcat_start; ;; stop) tomcat_stop; ;; restart) tomcat_stop; tomcat_start; ;; status) tomcat_status; ;; log) tomcat_log; ;; *) echo $&quot;Usage: $prog {start | stop | restart | log | status}&quot; exit 1 esac tomcat 需要jdk才能运行，上面解压以后我是在tomcat启动脚本里面配置的jdk目录，也可以定义在系统全局变量里面，但是我不会这么做，因为我们的环境经常是运行多个实例且JDK版本要求不同，如果安装多个jdk会造成全局冲突全局变量定义方式:vim /etc/profile 写入以下内容: export JAVA_HOME=/jboss/jdk1.8.0_51 export CLASSPATH=$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar export JRE_HOME=$JAVA_HOME/jre export PATH=$PATH:$JAVA_HOME/bin source /etc/profile -- 生效配置 验证java [root@node1 ~]# java -version java version &quot;1.8.0_51&quot; Java(TM) SE Runtime Environment (build 1.8.0_51-b16) Java HotSpot(TM) 64-Bit Server VM (build 25.51-b03, mixed mode) [root@node1 ~]# 4、启动tomcat[root@node1 ~]# ./tomcat.sh start ---启动服务 Starting tomcat: Using CATALINA_BASE: /tomcat/apache-tomcat-8.5.42 Using CATALINA_HOME: /tomcat/apache-tomcat-8.5.42 Using CATALINA_TMPDIR: /tomcat/apache-tomcat-8.5.42/temp Using JRE_HOME: /jboss/jdk1.8.0_51/jre Using CLASSPATH: /tomcat/apache-tomcat-8.5.42/bin/bootstrap.jar:/tomcat/apache-tomcat-8.5.42/bin/tomcat-juli.jar Tomcat started. tomcat 8 starting...... [root@node1 ~]# ./tomcat.sh status root 24103 1 0 11:39 ? 00:00:04 /jboss/jdk1.8.0_51/jre/bin/java -Djava.util.logging.config.file=/tomcat/apache-tomcat-8.5.42/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Xms1000m -Xmx1000m -Xmn400m -XX:PermSize=256m -XX:MaxPermSize=512m -Djdk.tls.ephemeralDHKeySize=2048 -Djava.protocol.handler.pkgs=org.apache.catalina.webresources -Dorg.apache.catalina.security.SecurityListener.UMASK=0027 -Dignore.endorsed.dirs= -classpath /tomcat/apache-tomcat-8.5.42/bin/bootstrap.jar:/tomcat/apache-tomcat-8.5.42/bin/tomcat-juli.jar -Dcatalina.base=/tomcat/apache-tomcat-8.5.42 -Dcatalina.home=/tomcat/apache-tomcat-8.5.42 -Djava.io.tmpdir=/tomcat/apache-tomcat-8.5.42/temp org.apache.catalina.startup.Bootstrap start 09-Jul-2019 11:39:42.759 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Server version: Apache Tomcat/8.5.42 09-Jul-2019 11:39:42.763 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Server built: Jun 4 2019 20:29:04 UTC 09-Jul-2019 11:39:42.763 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Server number: 8.5.42.0 09-Jul-2019 11:39:42.763 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log OS Name: Linux 09-Jul-2019 11:39:42.763 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log OS Version: 3.10.0-327.el7.x86_64 09-Jul-2019 11:39:42.763 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Architecture: amd64 09-Jul-2019 11:39:42.763 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Java Home: /jboss/jdk1.8.0_51/jre 09-Jul-2019 11:39:42.763 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log JVM Version: 1.8.0_51-b16 09-Jul-2019 11:39:42.763 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log JVM Vendor: Oracle Corporation 09-Jul-2019 11:39:42.763 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log CATALINA_BASE: /tomcat/apache-tomcat-8.5.42 09-Jul-2019 11:39:42.764 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log CATALINA_HOME: /tomcat/apache-tomcat-8.5.42 09-Jul-2019 11:39:42.764 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Djava.util.logging.config.file=/tomcat/apache-tomcat-8.5.42/conf/logging.properties 09-Jul-2019 11:39:42.764 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager 09-Jul-2019 11:39:42.764 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Xms1000m 09-Jul-2019 11:39:42.764 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Xmx1000m 09-Jul-2019 11:39:42.764 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Xmn400m 09-Jul-2019 11:39:42.764 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -XX:PermSize=256m 09-Jul-2019 11:39:42.764 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -XX:MaxPermSize=512m 09-Jul-2019 11:39:42.764 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Djdk.tls.ephemeralDHKeySize=2048 09-Jul-2019 11:39:42.765 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Djava.protocol.handler.pkgs=org.apache.catalina.webresources 09-Jul-2019 11:39:42.765 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Dorg.apache.catalina.security.SecurityListener.UMASK=0027 09-Jul-2019 11:39:42.765 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Dignore.endorsed.dirs= 09-Jul-2019 11:39:42.765 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Dcatalina.base=/tomcat/apache-tomcat-8.5.42 09-Jul-2019 11:39:42.765 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Dcatalina.home=/tomcat/apache-tomcat-8.5.42 09-Jul-2019 11:39:42.765 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Djava.io.tmpdir=/tomcat/apache-tomcat-8.5.42/temp 09-Jul-2019 11:39:42.765 信息 [main] org.apache.catalina.core.AprLifecycleListener.lifecycleEvent The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib] 09-Jul-2019 11:39:43.048 信息 [main] org.apache.coyote.AbstractProtocol.init Initializing ProtocolHandler [&quot;http-nio-8080&quot;] 09-Jul-2019 11:39:43.071 信息 [main] org.apache.tomcat.util.net.NioSelectorPool.getSharedSelector Using a shared selector for servlet write/read 09-Jul-2019 11:39:43.095 信息 [main] org.apache.coyote.AbstractProtocol.init Initializing ProtocolHandler [&quot;ajp-nio-8009&quot;] 09-Jul-2019 11:39:43.113 信息 [main] org.apache.tomcat.util.net.NioSelectorPool.getSharedSelector Using a shared selector for servlet write/read 09-Jul-2019 11:39:43.124 信息 [main] org.apache.catalina.startup.Catalina.load Initialization processed in 1109 ms 09-Jul-2019 11:39:43.158 信息 [main] org.apache.catalina.core.StandardService.startInternal Starting service [Catalina] 09-Jul-2019 11:39:43.158 信息 [main] org.apache.catalina.core.StandardEngine.startInternal Starting Servlet Engine: Apache Tomcat/8.5.42 09-Jul-2019 11:39:43.207 信息 [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deploying web application directory [/tomcat/apache-tomcat-8.5.42/webapps/ROOT] 09-Jul-2019 11:44:19.656 警告 [localhost-startStop-1] org.apache.catalina.util.SessionIdGeneratorBase.createSecureRandom Creation of SecureRandom instance for session ID generation using [SHA1PRNG] took [276,003] milliseconds. 09-Jul-2019 11:44:19.697 信息 [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deployment of web application directory [/tomcat/apache-tomcat-8.5.42/webapps/ROOT] has finished in [276,491] ms 09-Jul-2019 11:44:19.697 信息 [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deploying web application directory [/tomcat/apache-tomcat-8.5.42/webapps/docs] 09-Jul-2019 11:44:19.739 信息 [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deployment of web application directory [/tomcat/apache-tomcat-8.5.42/webapps/docs] has finished in [42] ms 09-Jul-2019 11:44:19.739 信息 [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deploying web application directory [/tomcat/apache-tomcat-8.5.42/webapps/examples] 09-Jul-2019 11:44:20.212 信息 [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deployment of web application directory [/tomcat/apache-tomcat-8.5.42/webapps/examples] has finished in [473] ms 09-Jul-2019 11:44:20.213 信息 [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deploying web application directory [/tomcat/apache-tomcat-8.5.42/webapps/host-manager] 09-Jul-2019 11:44:20.266 信息 [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deployment of web application directory [/tomcat/apache-tomcat-8.5.42/webapps/host-manager] has finished in [53] ms 09-Jul-2019 11:44:20.266 信息 [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deploying web application directory [/tomcat/apache-tomcat-8.5.42/webapps/manager] 09-Jul-2019 11:44:20.293 信息 [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deployment of web application directory [/tomcat/apache-tomcat-8.5.42/webapps/manager] has finished in [27] ms 09-Jul-2019 11:44:20.314 信息 [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler [&quot;http-nio-8080&quot;] 09-Jul-2019 11:44:20.342 信息 [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler [&quot;ajp-nio-8009&quot;] 09-Jul-2019 11:44:20.344 信息 [main] org.apache.catalina.startup.Catalina.start Server startup in 277219 ms ----看到此输出，程序就已经正常启动 通过浏览器访问tomcat服务,tomcat 默认端口号为8080http://ipaddr:8080 tomcat端口可在/conf/server.xml文件中修改67 Define a non-SSL/TLS HTTP/1.1 Connector on port 8080 68 --&gt; 69 &lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; --将8080修改为80或其他需要的端口 70 connectionTimeout=&quot;20000&quot; 71 redirectPort=&quot;8443&quot; /&gt; 72 &lt;!-- A &quot;Connector&quot; using the shared thread pool--&gt; tomcat已安装完毕5、tomcat目录结构说明bin -- 程序启动目录 conf -- 配置文件目录 lib -- 库文件目录 logs -- 日志文件目录 temp -- 临时缓存目录 webapps -- web 应用家目录 work -- 工作缓存目录]]></content>
      <categories>
        <category>Linux</category>
        <category>Apache</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Apache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[clamav Linux杀毒软件]]></title>
    <url>%2F2018%2F06%2F10%2Fclamav%20Linux-%E6%9D%80%E6%AF%92%E8%BD%AF%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[一、clamav简介ClamAV是一个C语言开发的开源病毒扫描工具用于检测木马/病毒/恶意软件等。可以在线更新病毒库，Linux系统的病毒较少，但是并不意味着病毒免疫，尤其是对于诸如邮件或者归档文件中夹杂的病毒往往更加难以防范，而ClamAV则能起到不少作用。官网上关于clamav的解释很简单，就是一款用于木马、病毒、恶意软件以及其他恶意威胁的杀毒软件(点击此处跳转到官网)官网下载地址更能特性：1、主要用途 邮件网关的病毒扫描，内建支持多种邮件格式2、高性能 提供多线程的扫描进程3、命令行 提供密令行扫描方式4、扫描对象 可以对要发送的邮件或者文件进行扫描5、文件格式 支持多种文件格式6、病毒库更新频度 一天多次病毒库的更新7、归档文件 支持扫描多种归档文件,比如Zip, RAR, Dmg, Tar, Gzip, Bzip2, OLE2, Cabinet, CHM, BinHex, SIS等8、文档 支持流行的文档文件，比如： MS Office文件，MacOffice文件, HTML, Flash, RTF，PDF安装方式CENTOS/RHELyum -y install clamav Ubuntu/Debianapt-get install clamav 二、安装杀毒软件yum -y install clamav 更新数据库freshclam 病毒库文件/var/lib/clamav/daily.cvd /var/lib/clamav/main.cvd 添加定时任务，设置自动更新:每两个小时自动更新crontab -e 0 */2 * * * root /usr/share/clamav/freshclam-sleep 三、使用clamscan是病毒扫描命令，以下是一些常用参数： clamscan ---不加参数的使用：扫描当前目录下的文件 clamscan -V ---查看clamAV的版本 clamscan -r ---递归扫描子文件夹 clamscan -i ---仅仅显示被感染的文件 clamscan -o ---跳过显示状态ok的文件 clamscan --remove ---检测到有病毒时，直接删除 clamscan --no-summary ---不显示统计信息 clamscan -l scan.log ---将扫描日志写入scan.log文件 ---以上命令都可以在末尾添加文件夹，来扫描指定目录，如 clamscan -r -i /home --remove -l scan.log ---递归扫描/home/目录下的所有文件，只显示病毒文件，并同时删除 示例：clamscan -l scan.log 执行完以后会有详细的扫描信息]]></content>
      <categories>
        <category>安全</category>
        <category>系统病毒扫描</category>
      </categories>
      <tags>
        <tag>安全</tag>
        <tag>Linux</tag>
        <tag>系统杀毒</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 系统安全检查（shell）]]></title>
    <url>%2F2018%2F04%2F22%2FLinux%20%E7%B3%BB%E7%BB%9F%E5%AE%89%E5%85%A8%E6%A3%80%E6%9F%A5%EF%BC%88shell%EF%BC%89%2F</url>
    <content type="text"><![CDATA[脚本内容:#!/bin/bash echo &quot; (__)&quot; echo &quot; (oo)&quot; echo &quot; /------\/ &quot; echo &quot; / | || &quot; echo &quot; * /\---/\ &quot; echo &quot; ~~ ~~ &quot; echo &quot;Are You Ready?&quot; read key echo &quot;警告：本脚本只作为日常巡检使用，不会对服务器做任何修改，管理员可以根据此报告进行相应的设置。&quot; echo ------------------------------------------------------------------------ echo &quot;查看系统时间&quot; DATE=`date` echo &quot;Date is $DATE&quot; echo ------------------------------------------------------------------------ echo &quot;进行系统时间同步&quot; ntpdate time.nist.gov echo ------------------------开始进行检查---------------------- echo &quot;检查时间为&quot; DATE=`date` echo &quot;Date is $DATE&quot; echo ------------------------主机基本信息检查----------------------- echo &quot;系统版本（Centos或Rehead）&quot; cat /etc/redhat-release echo -------------------------------------------------------------------------- echo &quot;系统位数（32位或64位）&quot; getconf LONG_BIT echo -------------------------检查IP信息----------------------------------------- echo &quot;本机的ip地址是：&quot; ifconfig | grep --color &quot;\([0-9]\{1,3\}\.\)\{3\}[0-9]\{1,3\}&quot; echo -------------------------检查系统用户信息--------------------------------------- awk -F&quot;:&quot; &apos;{if($2!~/^!|^*/){print &quot;(&quot;$1&quot;)&quot; &quot; 是一个未被锁定的账户，请管理员检查是否需要锁定它或者删除它。&quot;}}&apos; /etc/shadow echo -------------------------------------------------------------------------- more /etc/login.defs | grep -E &quot;PASS_MAX_DAYS&quot; | grep -v &quot;#&quot; |awk -F&apos; &apos; &apos;{if($2!=90){print &quot;/etc/login.defs里面的&quot;$1 &quot;设置的是&quot;$2&quot;天，请管理员改成90天。&quot;}}&apos; echo -------------------------------------------------------------------------- more /etc/login.defs | grep -E &quot;PASS_MIN_LEN&quot; | grep -v &quot;#&quot; |awk -F&apos; &apos; &apos;{if($2!=6){print &quot;/etc/login.defs里面的&quot;$1 &quot;设置的是&quot;$2&quot;个字符，请管理员改成6个字符。&quot;}}&apos; echo -------------------------------------------------------------------------- more /etc/login.defs | grep -E &quot;PASS_WARN_AGE&quot; | grep -v &quot;#&quot; |awk -F&apos; &apos; &apos;{if($2!=10){print &quot;/etc/login.defs里面的&quot;$1 &quot;设置的是&quot;$2&quot;天，请管理员将口令到期警告天数改成10天。&quot;}}&apos; echo -------------------------------------------------------------------------- grep TMOUT /etc/profile /etc/bashrc &gt; /dev/null|| echo &quot;未设置登录超时限制，请设置之，设置方法：在/etc/profile或者/etc/bashrc里面添加TMOUT=600参数&quot; echo ------------------------检查服务运行情况----------------------------------- if ps -elf |grep xinet |grep -v &quot;grep xinet&quot;;then echo &quot;xinetd 服务正在运行，请检查是否可以把xinnetd服务关闭&quot; else echo &quot;xinetd 服务未开启&quot; fi echo -------------------------------------------------------------------------- echo &quot;查看系统密码文件修改时间&quot; ls -ltr /etc/passwd echo -------------------------------------------------------------------------- echo &quot;查看是否开启了ssh服务&quot; if service sshd status | grep -E &quot;listening on|active \(running\)&quot;; then echo &quot;SSH服务已开启&quot; else echo &quot;SSH服务未开启&quot; fi echo -------------------------------------------------------------------------- echo &quot;查看是否开启了TELNET服务&quot; if more /etc/xinetd.d/telnetd 2&gt;&amp;1|grep -E &quot;disable=no&quot;; then echo &quot;TELNET服务已开启 &quot; else echo &quot;TELNET服务未开启 &quot; fi echo -------------------------------------------------------------------------- echo &quot;查看系统SSH远程访问设置策略(host.deny拒绝列表)&quot; if more /etc/hosts.deny | grep -E &quot;sshd: &quot;;more /etc/hosts.deny | grep -E &quot;sshd&quot;; then echo &quot;远程访问策略已设置 &quot; else echo &quot;远程访问策略未设置 &quot; fi echo -------------------------------------------------------------------------- echo &quot;查看系统SSH远程访问设置策略(hosts.allow允许列表)&quot; if more /etc/hosts.allow | grep -E &quot;sshd: &quot;;more /etc/hosts.allow | grep -E &quot;sshd&quot;; then echo &quot;远程访问策略已设置 &quot; else echo &quot;远程访问策略未设置 &quot; fi echo &quot;当hosts.allow和 host.deny相冲突时，以hosts.allow设置为准。&quot; echo ------------------------------------------------------------------------- echo &quot;查看shell是否设置超时锁定策略&quot; if more /etc/profile | grep -E &quot;TIMEOUT= &quot;; then echo &quot;系统设置了超时锁定策略 &quot; else echo &quot;未设置超时锁定策略 &quot; fi echo ------------------------------------------------------------------------- echo &quot;查看syslog日志审计服务是否开启&quot; if service syslog status | egrep &quot; active \(running&quot;;then echo &quot;syslog服务已开启&quot; else echo &quot;syslog服务未开启，建议通过service syslog start开启日志审计功能&quot; fi echo ------------------------------------------------------------------------- echo &quot;查看syslog日志是否开启外发&quot; if more /etc/rsyslog.conf | egrep &quot;@...\.|@..\.|@.\.|\*.\* @...\.|\*\.\* @..\.|\*\.\* @.\.&quot;;then echo &quot;客户端syslog日志已开启外发&quot; else echo &quot;客户端syslog日志未开启外发&quot; fi echo ------------------------------------------------------------------------- echo &quot;查看passwd文件中有哪些特权用户&quot; awk -F: &apos;$3==0 {print $1}&apos; /etc/passwd echo ------------------------------------------------------------------------ echo &quot;查看系统中是否存在空口令账户&quot; awk -F: &apos;($2==&quot;!!&quot;) {print $1}&apos; /etc/shadow echo &quot;该结果不适用于Ubuntu系统&quot; echo ------------------------------------------------------------------------ echo &quot;查看系统中root用户外连情况&quot; lsof -u root |egrep &quot;ESTABLISHED|SYN_SENT|LISTENING&quot; echo ----------------------------状态解释------------------------------ echo &quot;ESTABLISHED的意思是建立连接。表示两台机器正在通信。&quot; echo &quot;LISTENING的&quot; echo &quot;SYN_SENT状态表示请求连接&quot; echo ------------------------------------------------------------------------ echo &quot;查看系统中root用户TCP连接情况&quot; lsof -u root |egrep &quot;TCP&quot; echo ------------------------------------------------------------------------ echo &quot;查看系统中存在哪些非系统默认用户&quot; echo &quot;root:x:“该值大于500为新创建用户，小于或等于500为系统初始用户”&quot; more /etc/passwd |awk -F &quot;:&quot; &apos;{if($3&gt;500){print &quot;/etc/passwd里面的&quot;$1 &quot;的值为&quot;$3&quot;，请管理员确认该账户是否正常。&quot;}}&apos; echo ------------------------------------------------------------------------ echo &quot;检查系统守护进程&quot; more /etc/xinetd.d/rsync | grep -v &quot;^#&quot; echo ------------------------------------------------------------------------ echo &quot;检查系统是否存在入侵行为&quot; more /var/log/secure |grep refused echo ------------------------------------------------------------------------ echo &quot;-----------------------检查系统是否存在PHP脚本后门---------------------&quot; if find / -type f -name *.php | xargs egrep -l &quot;mysql_query\($query, $dbconn\)|专用网马|udf.dll|class PHPzip\{|ZIP压缩程序 荒野无灯修改版|$writabledb|AnonymousUserName|eval\(|Root_CSS\(\)|黑狼PHP木马|eval\(gzuncompress\(base64_decode|if\(empty\($_SESSION|$shellname|$work_dir |PHP木马|Array\(&quot;$filename&quot;| eval\($_POST\[|class packdir|disk_total_space|wscript.shell|cmd.exe|shell.application|documents and settings|system32|serv-u|提权|phpspy|后门&quot; |sort -n|uniq -c |sort -rn 1&gt;/dev/null 2&gt;&amp;1;then echo &quot;检测到PHP脚本后门&quot; find / -type f -name *.php | xargs egrep -l &quot;mysql_query\($query, $dbconn\)|专用网马|udf.dll|class PHPzip\{|ZIP压缩程序 荒野无灯修改版|$writabledb|AnonymousUserName|eval\(|Root_CSS\(\)|黑狼PHP木马|eval\(gzuncompress\(base64_decode|if\(empty\($_SESSION|$shellname|$work_dir |PHP木马|Array\(&quot;$filename&quot;| eval\($_POST\[|class packdir|disk_total_space|wscript.shell|cmd.exe|shell.application|documents and settings|system32|serv-u|提权|phpspy|后门&quot; |sort -n|uniq -c |sort -rn find / -type f -name *.php | xargs egrep -l &quot;mysql_query\($query, $dbconn\)|专用网马|udf.dll|class PHPzip\{|ZIP压缩程序 荒野无灯修改版|$writabledb|AnonymousUserName|eval\(|Root_CSS\(\)|黑狼PHP木马|eval\(gzuncompress\(base64_decode|if\(empty\($_SESSION|$shellname|$work_dir |PHP木马|Array\(&quot;$filename&quot;| eval\($_POST\[|class packdir|disk_total_space|wscript.shell|cmd.exe|shell.application|documents and settings|system32|serv-u|提权|phpspy|后门&quot; |sort -n|uniq -c |sort -rn |awk &apos;{print $2}&apos; | xargs -I{} cp {} /tmp/ echo &quot;后门样本已拷贝到/tmp/目录&quot; else echo &quot;未检测到PHP脚本后门&quot; fi echo ------------------------------------------------------------------------ echo &quot;-----------------------检查系统是否存在JSP脚本后门---------------------&quot; find / -type f -name *.jsp | xargs egrep -l &quot;InputStreamReader\(this.is\)|W_SESSION_ATTRIBUTE|strFileManag|getHostAddress|wscript.shell|gethostbyname|cmd.exe|documents and settings|system32|serv-u|提权|jspspy|后门&quot; |sort -n|uniq -c |sort -rn 2&gt;&amp;1 find / -type f -name *.jsp | xargs egrep -l &quot;InputStreamReader\(this.is\)|W_SESSION_ATTRIBUTE|strFileManag|getHostAddress|wscript.shell|gethostbyname|cmd.exe|documents and settings|system32|serv-u|提权|jspspy|后门&quot; |sort -n|uniq -c |sort -rn| awk &apos;{print $2}&apos; | xargs -I{} cp {} /tmp/ 2&gt;&amp;1 echo ------------------------------------------------------------------------ echo &quot;----------------------检查系统是否存在HTML恶意代码---------------------&quot; if find / -type f -name *.html | xargs egrep -l &quot;WriteData|svchost.exe|DropPath|wsh.Run|WindowBomb|a1.createInstance|CurrentVersion|myEncString|DropFileName|a = prototype;|204.351.440.495.232.315.444.550.64.330&quot; 1&gt;/dev/null 2&gt;&amp;1;then echo &quot;发现HTML恶意代码&quot; find / -type f -name *.html | xargs egrep -l &quot;WriteData|svchost.exe|DropPath|wsh.Run|WindowBomb|a1.createInstance|CurrentVersion|myEncString|DropFileName|a = prototype;|204.351.440.495.232.315.444.550.64.330&quot; |sort -n|uniq -c |sort -rn find / -type f -name *.html | xargs egrep -l &quot;WriteData|svchost.exe|DropPath|wsh.Run|WindowBomb|a1.createInstance|CurrentVersion|myEncString|DropFileName|a = prototype;|204.351.440.495.232.315.444.550.64.330&quot; |sort -n|uniq -c |sort -rn| awk &apos;{print $2}&apos; | xargs -I{} cp {} /tmp/ echo &quot;后门样本已拷贝到/tmp/目录&quot; else echo &quot;未检测到HTML恶意代码&quot; fi echo &quot;----------------------检查系统是否存在perl恶意程序----------------------&quot; if find / -type f -name *.pl | xargs egrep -l &quot;SHELLPASSWORD|shcmd|backdoor|setsockopt|IO::Socket::INET;&quot; 1&gt;/dev/null 2&gt;&amp;1;then echo &quot;发现perl恶意程序&quot; find / -type f -name *.pl | xargs egrep -l &quot;SHELLPASSWORD|shcmd|backdoor|setsockopt|IO::Socket::INET;&quot;|sort -n|uniq -c |sort -rn find / -type f -name *.pl | xargs egrep -l &quot;SHELLPASSWORD|shcmd|backdoor|setsockopt|IO::Socket::INET;&quot;|sort -n|uniq -c |sort -rn| awk &apos;{print $2}&apos; | xargs -I{} cp {} /tmp/ echo &quot;可疑样本已拷贝到/tmp/目录&quot; else echo &quot;未检测到perl恶意程序&quot; fi echo &quot;----------------------检查系统是否存在Python恶意程序----------------------&quot; find / -type f -name *.py | xargs egrep -l &quot;execCmd|cat /etc/issue|getAppProc|exploitdb&quot; |sort -n|uniq -c |sort -rn find / -type f -name *.py | xargs egrep -l &quot;execCmd|cat /etc/issue|getAppProc|exploitdb&quot; |sort -n|uniq -c |sort -rn| awk &apos;{print $2}&apos; | xargs -I{} cp {} /tmp/ echo ------------------------------------------------------------------------ echo &quot;-----------------------检查系统是否存在恶意程序---------------------&quot; find / -type f -perm -111 |xargs egrep &quot;UpdateProcessER12CUpdateGatesE6C|CmdMsg\.cpp|MiniHttpHelper.cpp|y4&apos;r3 1uCky k1d\!|execve@@GLIBC_2.0|initfini.c|ptmalloc_unlock_all2|_IO_wide_data_2|system@@GLIBC_2.0|socket@@GLIBC_2.0|gettimeofday@@GLIBC_2.0|execl@@GLIBC_2.2.5|WwW.SoQoR.NeT|2.6.17-2.6.24.1.c|Local Root Exploit|close@@GLIBC_2.0|syscall\(\__NR\_vmsplice,|Linux vmsplice Local Root Exploit|It looks like the exploit failed|getting root shell&quot; 2&gt;/dev/null echo ------------------------------------------------------------------------ echo &quot;检查网络连接和监听端口&quot; netstat -an echo &quot;--------------------------路由表、网络连接、接口信息--------------&quot; netstat -rn echo &quot;------------------------查看网卡详细信息--------------------------&quot; ifconfig -a echo ------------------------------------------------------------------------ echo &quot;查看正常情况下登录到本机的所有用户的历史记录&quot; last echo ------------------------------------------------------------------------ echo &quot;检查系统中core文件是否开启&quot; ulimit -c echo &quot;core是unix系统的内核。当你的程序出现内存越界的时候,操作系统会中止你的进程,并将当前内存状态倒出到core文件中,以便进一步分析，如果返回结果为0，则是关闭了此功能，系统不会生成core文件&quot; echo ------------------------------------------------------------------------ echo &quot;检查系统中关键文件修改时间&quot; ls -ltr /bin/ls /bin/login /etc/passwd /bin/ps /usr/bin/top /etc/shadow|awk &apos;{print &quot;文件名：&quot;$8&quot; &quot;&quot;最后修改时间：&quot;$6&quot; &quot;$7}&apos; echo &quot;ls文件：是存储ls命令的功能函数，被删除以后，就无法执行ls命令，黑客可利用篡改ls文件来执行后门或其他程序。 login文件：login是控制用户登录的文件，一旦被篡改或删除，系统将无法切换用户或登陆用户 user/bin/passwd是一个命令，可以为用户添加、更改密码，但是，用户的密码并不保存在/etc/passwd当中，而是保存在了/etc/shadow当中 etc/passwd是一个文件，主要是保存用户信息。 sbin/portmap是文件转换服务，缺少该文件后，无法使用磁盘挂载、转换类型等功能。 bin/ps 进程查看命令功能支持文件，文件损坏或被更改后，无法正常使用ps命令。 usr/bin/top top命令支持文件，是Linux下常用的性能分析工具,能够实时显示系统中各个进程的资源占用状况。 etc/shadow shadow 是 /etc/passwd 的影子文件，密码存放在该文件当中，并且只有root用户可读。&quot; echo -------------------------------------------------------------------------- echo &quot;-------------------查看系统日志文件是否存在--------------------&quot; log=/var/log/syslog log2=/var/log/messages if [ -e &quot;$log&quot; ]; then echo &quot;syslog日志文件存在！ &quot; else echo &quot;/var/log/syslog日志文件不存在！ &quot; fi if [ -e &quot;$log2&quot; ]; then echo &quot;/var/log/messages日志文件存在！ &quot; else echo &quot;/var/log/messages日志文件不存在！ &quot; fi echo -------------------------------------------------------------------------- echo &quot;检查系统文件完整性2(MD5检查)&quot; echo &quot;该项会获取部分关键文件的MD5值并入库，默认保存在/etc/md5db中&quot; echo &quot;如果第一次执行，则会提示md5sum: /sbin/portmap: 没有那个文件或目录&quot; echo &quot;第二次重复检查时，则会对MD5DB中的MD5值进行匹配，来判断文件是否被更改过&quot; file=&quot;/etc/md5db&quot; if [ -e &quot;$file&quot; ]; then md5sum -c /etc/md5db 2&gt;&amp;1; else md5sum /etc/passwd &gt;&gt;/etc/md5db md5sum /etc/shadow &gt;&gt;/etc/md5db md5sum /etc/group &gt;&gt;/etc/md5db md5sum /usr/bin/passwd &gt;&gt;/etc/md5db md5sum /sbin/portmap&gt;&gt;/etc/md5db md5sum /bin/login &gt;&gt;/etc/md5db md5sum /bin/ls &gt;&gt;/etc/md5db md5sum /bin/ps &gt;&gt;/etc/md5db md5sum /usr/bin/top &gt;&gt;/etc/md5db; fi echo ---------------------------------------------------------------------- echo &quot;------------------------主机性能检查--------------------------------&quot; echo &quot;CPU检查&quot; dmesg | grep -i cpu echo ----------------------------------------------------------------------- more /proc/cpuinfo echo ----------------------------------------------------------------------- echo &quot;内存状态检查&quot; vmstat 2 5 echo ----------------------------------------------------------------------- more /proc/meminfo echo ----------------------------------------------------------------------- free -m echo ----------------------------------------------------------------------- echo &quot;文件系统使用情况&quot; df -h echo ----------------------------------------------------------------------- echo &quot;网卡使用情况&quot; lspci -tv echo ---------------------------------------------------------------------- echo &quot;查看僵尸进程&quot; ps -ef | grep zombie echo ---------------------------------------------------------------------- echo &quot;耗CPU最多的进程&quot; ps auxf |sort -nr -k 3 |head -5 echo ---------------------------------------------------------------------- echo &quot;耗内存最多的进程&quot; ps auxf |sort -nr -k 4 |head -5 echo ---------------------------------------------------------------------- echo --------------------------------------------------------------------- echo &quot;COPY RIGHT &quot; echo &quot;QQ：&quot; echo ----------------------结束时间为------------------------------------- DATE=`date` echo &quot;Date is $DATE&quot; echo ----------------------------------------------------------------------]]></content>
      <categories>
        <category>Linux</category>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nmap简单使用的技巧]]></title>
    <url>%2F2018%2F04%2F19%2FNmap%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[nmap支持很多扫描技术，例如：UDP、TCP connect()、TCP SYN(半开扫描)、ftp代理(bounce攻击)、反向标志、ICMP、FIN、ACK扫描、圣诞树(Xmas Tree)、null扫描。nmap还提供了一些高级的特征，例如：通过TCP/IP协议栈特征探测操作系统类型，秘密扫描，动态延时和重传计算，并行扫描，通过并行ping扫描探测关闭的主机，诱饵扫描，避开端口过滤检测，直接RPC扫描(无须端口影射)，碎片扫描，以及灵活的目标和端口设定.nmap总会给出well known端口的服务名(如果可能)、端口号、状态和协议等信息。每个端口的状态有：open、filtered、 unfiltered。open状态意味着目标主机能够在这个端口使用accept()系统调用接受连接。filtered状态表示：防火墙、包过滤和其 它的网络安全软件掩盖了这个端口，禁止 nmap探测其是否打开。unfiltered表示：这个端口关闭，并且没有防火墙/包过滤软件来隔离nmap的探测企图。通常情况下，端口的状态基本都 是unfiltered状态，只有在大多数被扫描的端口处于filtered状态下，才会显示处于unfiltered状态的端口。根据使用的功能选 项，nmap也可以报告远程主机的下列特征：使用的操作系统、TCP序列、运行绑定到每个端口上的应用程序的用户名、DNS名、主机地址是否是欺骗地址、 以及其它一些东西。可以使用nmap -h快速列出功能选项的列表。[root@node1 ~]# nmap -h Nmap 6.40 ( http://nmap.org ) Usage: nmap [Scan Type(s)] [Options] {target specification} TARGET SPECIFICATION: Can pass hostnames, IP addresses, networks, etc. Ex: scanme.nmap.org, microsoft.com/24, 192.168.0.1; 10.0.0-255.1-254 -iL &lt;inputfilename&gt;: Input from list of hosts/networks -iR &lt;num hosts&gt;: Choose random targets --exclude &lt;host1[,host2][,host3],...&gt;: Exclude hosts/networks --excludefile &lt;exclude_file&gt;: Exclude list from file HOST DISCOVERY: -sL: List Scan - simply list targets to scan -sn: Ping Scan - disable port scan -Pn: Treat all hosts as online -- skip host discovery -PS/PA/PU/PY[portlist]: TCP SYN/ACK, UDP or SCTP discovery to given ports -PE/PP/PM: ICMP echo, timestamp, and netmask request discovery probes -PO[protocol list]: IP Protocol Ping -n/-R: Never do DNS resolution/Always resolve [default: sometimes] --dns-servers &lt;serv1[,serv2],...&gt;: Specify custom DNS servers --system-dns: Use OS&apos;s DNS resolver --traceroute: Trace hop path to each host SCAN TECHNIQUES: -sS/sT/sA/sW/sM: TCP SYN/Connect()/ACK/Window/Maimon scans -sU: UDP Scan -sN/sF/sX: TCP Null, FIN, and Xmas scans --scanflags &lt;flags&gt;: Customize TCP scan flags -sI &lt;zombie host[:probeport]&gt;: Idle scan -sY/sZ: SCTP INIT/COOKIE-ECHO scans -sO: IP protocol scan -b &lt;FTP relay host&gt;: FTP bounce scan PORT SPECIFICATION AND SCAN ORDER: -p &lt;port ranges&gt;: Only scan specified ports Ex: -p22; -p1-65535; -p U:53,111,137,T:21-25,80,139,8080,S:9 -F: Fast mode - Scan fewer ports than the default scan -r: Scan ports consecutively - don&apos;t randomize --top-ports &lt;number&gt;: Scan &lt;number&gt; most common ports --port-ratio &lt;ratio&gt;: Scan ports more common than &lt;ratio&gt; SERVICE/VERSION DETECTION: -sV: Probe open ports to determine service/version info --version-intensity &lt;level&gt;: Set from 0 (light) to 9 (try all probes) --version-light: Limit to most likely probes (intensity 2) --version-all: Try every single probe (intensity 9) --version-trace: Show detailed version scan activity (for debugging) SCRIPT SCAN: -sC: equivalent to --script=default --script=&lt;Lua scripts&gt;: &lt;Lua scripts&gt; is a comma separated list of directories, script-files or script-categories --script-args=&lt;n1=v1,[n2=v2,...]&gt;: provide arguments to scripts --script-args-file=filename: provide NSE script args in a file --script-trace: Show all data sent and received --script-updatedb: Update the script database. --script-help=&lt;Lua scripts&gt;: Show help about scripts. &lt;Lua scripts&gt; is a comma separted list of script-files or script-categories. OS DETECTION: -O: Enable OS detection --osscan-limit: Limit OS detection to promising targets --osscan-guess: Guess OS more aggressively TIMING AND PERFORMANCE: Options which take &lt;time&gt; are in seconds, or append &apos;ms&apos; (milliseconds), &apos;s&apos; (seconds), &apos;m&apos; (minutes), or &apos;h&apos; (hours) to the value (e.g. 30m). -T&lt;0-5&gt;: Set timing template (higher is faster) --min-hostgroup/max-hostgroup &lt;size&gt;: Parallel host scan group sizes --min-parallelism/max-parallelism &lt;numprobes&gt;: Probe parallelization --min-rtt-timeout/max-rtt-timeout/initial-rtt-timeout &lt;time&gt;: Specifies probe round trip time. --max-retries &lt;tries&gt;: Caps number of port scan probe retransmissions. --host-timeout &lt;time&gt;: Give up on target after this long --scan-delay/--max-scan-delay &lt;time&gt;: Adjust delay between probes --min-rate &lt;number&gt;: Send packets no slower than &lt;number&gt; per second --max-rate &lt;number&gt;: Send packets no faster than &lt;number&gt; per second FIREWALL/IDS EVASION AND SPOOFING: -f; --mtu &lt;val&gt;: fragment packets (optionally w/given MTU) -D &lt;decoy1,decoy2[,ME],...&gt;: Cloak a scan with decoys -S &lt;IP_Address&gt;: Spoof source address -e &lt;iface&gt;: Use specified interface -g/--source-port &lt;portnum&gt;: Use given port number --data-length &lt;num&gt;: Append random data to sent packets --ip-options &lt;options&gt;: Send packets with specified ip options --ttl &lt;val&gt;: Set IP time-to-live field --spoof-mac &lt;mac address/prefix/vendor name&gt;: Spoof your MAC address --badsum: Send packets with a bogus TCP/UDP/SCTP checksum OUTPUT: -oN/-oX/-oS/-oG &lt;file&gt;: Output scan in normal, XML, s|&lt;rIpt kIddi3, and Grepable format, respectively, to the given filename. -oA &lt;basename&gt;: Output in the three major formats at once -v: Increase verbosity level (use -vv or more for greater effect) -d: Increase debugging level (use -dd or more for greater effect) --reason: Display the reason a port is in a particular state --open: Only show open (or possibly open) ports --packet-trace: Show all packets sent and received --iflist: Print host interfaces and routes (for debugging) --log-errors: Log errors/warnings to the normal-format output file --append-output: Append to rather than clobber specified output files --resume &lt;filename&gt;: Resume an aborted scan --stylesheet &lt;path/URL&gt;: XSL stylesheet to transform XML output to HTML --webxml: Reference stylesheet from Nmap.Org for more portable XML --no-stylesheet: Prevent associating of XSL stylesheet w/XML output MISC: -6: Enable IPv6 scanning -A: Enable OS detection, version detection, script scanning, and traceroute --datadir &lt;dirname&gt;: Specify custom Nmap data file location --send-eth/--send-ip: Send using raw ethernet frames or IP packets --privileged: Assume that the user is fully privileged --unprivileged: Assume the user lacks raw socket privileges -V: Print version number -h: Print this help summary page. EXAMPLES: nmap -v -A scanme.nmap.org nmap -v -sn 192.168.0.0/16 10.0.0.0/8 nmap -v -iR 10000 -Pn -p 80 SEE THE MAN PAGE (http://nmap.org/book/man.html) FOR MORE OPTIONS AND EXAMPLES [root@node1 ~]# 参考nmap中文网一、nmap安装1.1 Centos 系统安装nmapyum -y install nmap 1.2 查看安装版本[root@node1 ~]# nmap -version Nmap version 6.40 ( http://nmap.org ) Platform: x86_64-redhat-linux-gnu Compiled with: nmap-liblua-5.2.2 openssl-1.0.2k libpcre-8.32 libpcap-1.5.3 nmap-libdnet-1.12 ipv6 Compiled without: Available nsock engines: epoll poll select [root@node1 ~]# 二、nmap常用命令2.1 基础命令nmap 172.31.8.8 ---扫描单个主机 nmap 172.31.8.0/24 ---扫描整个子网 nmap 172.31.8.8 172.31.8.13 ---扫描多个目标 nmap 172.31.8.8-20 ---扫描一个指定范围内的目标 nmap -iL pinglist.txt ---如果有一个IP地址列表，将这些IP保存在一个pinglist.txt文件内，使用nmap -iL iplist.txt 扫描指定文件内的目标 list 例： [root@node1 ~]# cat pinglist.txt 172.31.8.2 172.31.8.3 172.31.8.75 172.31.8.107 [root@node1 ~]# nmap -iL pinglist.txt Starting Nmap 6.40 ( http://nmap.org ) at 2019-07-20 17:13 CST Nmap scan report for 172.31.8.3 Host is up (0.0034s latency). Not shown: 995 filtered ports PORT STATE SERVICE 135/tcp open msrpc 139/tcp open netbios-ssn 445/tcp open microsoft-ds 3389/tcp open ms-wbt-server 5357/tcp open wsdapi MAC Address: 50:7B:9D:99:AA:D9 (Unknown) Nmap scan report for node4 (172.31.8.75) Host is up (0.000022s latency). Not shown: 999 closed ports PORT STATE SERVICE 22/tcp open ssh MAC Address: 00:0C:29:E3:5F:D2 (VMware) Nmap scan report for node3 (172.31.8.107) Host is up (0.000066s latency). Not shown: 999 closed ports PORT STATE SERVICE 22/tcp open ssh MAC Address: 00:0C:29:9A:43:BC (VMware) Nmap done: 4 IP addresses (3 hosts up) scanned in 5.15 seconds [root@node1 ~]# nmap 172.31.8.0/24 -exclude 172.31.8.8 ---扫描172.31.8.0/24 这个子网除172.31.8.8以外的所有IP nmap 172.31.8/0/24 -exclude iplist.txt ---扫描172.31.8.0/24 这个子网所有的IP，排除iplist.txt这个文件内列出的IP nmap -p8080,22 172.31.8.8 ---扫描特定主机上的8080，22端口 2.2 深入探究nmap -sS 172.31.8.8 ---SYN扫描，指定IP/IP范围指定扫描端口:nmap -sS 172.31.8.8 -p 8080 nmap -sP 172.31.8.0/24 ---扫描存活主机,可以添加 | grep up 参数过滤存活主机:nmap -sP 172.31.8.0/24 | grep up nmap -sV 172.31.8.8 -p 8080 ---扫描主机的8080端口的服务和服务版本 nmap -O 172.31.8.8 ---扫描目标主机的系统版本 nmap -A 172.31.8.8 ---扫描目标主机，-A参数包括:-sV、-O 系统全面检测、启动脚本检测、扫描等操作 nmap -PO 172.31.8.8 ---扫描之前不使用ping操作，适用于禁ping的系统和设备 nmap -v 172.31.8.8 ---显示目标主机上详细信息 例： [root@node1 ~]# nmap -v 172.31.8.8 Starting Nmap 6.40 ( http://nmap.org ) at 2019-07-20 17:15 CST Initiating SYN Stealth Scan at 17:15 Scanning node1 (172.31.8.8) [1000 ports] Discovered open port 8080/tcp on 172.31.8.8 adjust_timeouts2: packet supposedly had rtt of 1428142253061189 microseconds. Ignoring time. adjust_timeouts2: packet supposedly had rtt of 1428142253061189 microseconds. Ignoring time. Discovered open port 22/tcp on 172.31.8.8 adjust_timeouts2: packet supposedly had rtt of 1428142253061166 microseconds. Ignoring time. adjust_timeouts2: packet supposedly had rtt of 1428142253061166 microseconds. Ignoring time. Discovered open port 8009/tcp on 172.31.8.8 adjust_timeouts2: packet supposedly had rtt of 1428142274531622 microseconds. Ignoring time. adjust_timeouts2: packet supposedly had rtt of 1428142274531622 microseconds. Ignoring time. Completed SYN Stealth Scan at 17:15, 0.01s elapsed (1000 total ports) Nmap scan report for node1 (172.31.8.8) Host is up (0.0000010s latency). Not shown: 997 closed ports PORT STATE SERVICE 22/tcp open ssh 8009/tcp open ajp13 8080/tcp open http-proxy Read data files from: /usr/bin/../share/nmap Nmap done: 1 IP address (1 host up) scanned in 0.03 seconds Raw packets sent: 1000 (44.000KB) | Rcvd: 2003 (84.132KB) [root@node1 ~]# nmap -T4 -sP 172.31.8.0/24 &amp;&amp; egrep &quot;00:00:00:00:00:00&quot; /proc/net/arp | grep Unknown ---扫描子网上未使用的IP nmap -PN -T4 -p139,445 -n -v --script=smb-check-vulns --script-args safe=1 172.31.8.0/24 ---在子网中探测Conficker 蠕虫病毒 nmap -F -O 172.31.8.0/24 | grep &quot;Running: &quot; &gt; /tmp/os; echo &quot;$(cat /tmp/os | grep Linux | wc -l) Linux device(s)&quot;; echo &quot;$(cat /tmp/os | grep Windows | wc -l) Window(s) device&quot; ---扫描子网中存在的Linux、windows设备数量 nmap是一款非常强大的扫描工具，以上的命令基本都是比较常用的命令，如果想深入了解nmap的功能，可以自己去研究一下。]]></content>
      <categories>
        <category>安全</category>
        <category>Nmap</category>
      </categories>
      <tags>
        <tag>安全</tag>
        <tag>Nmap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[memcache服务器搭建]]></title>
    <url>%2F2018%2F02%2F19%2Fmemcache%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[一、memcache简介Memcache是什么Memcache是danga.com的一个项目，最早是为 LiveJournal 服务的，目前全世界不少人使用这个缓存项目来构建自己大负载的网站，来分担数据库的压力。它可以应对任意多个连接，使用非阻塞的网络IO。由于它的工作机制是在内存中开辟一块空间，然后建立一个HashTable，Memcached自管理这些HashTable。Memcache官方网站,更多详细的信息可以来这里了解为什么会有Memcache和memcached两种名称？其实Memcache是这个项目的名称，而memcached是它服务器端的主程序文件名。一个是项目名称，一个是主程序文件名，不要混用了。二、Memcache的安装安装分为两个过程：memcache服务器端的安装和memcached客户端的安装。所谓服务器端的安装就是在服务器（一般都是linux系统）上安装Memcache实现数据的存储所谓客户端的安装就是指php（或者其他程序，Memcache还有其他不错的api接口提供）去使用服务器端的Memcache提供的函数，需要php添加扩展。2.1、memcache服务器的安装这里安装memcache需要指定libevent，查看系统是否已经安装libeventrpm -qa | grep libevent 如果已经有，先进行升级yum -y install libevent 测试libevent是否已经安装成功ll /usr/share/doc/ | grep libevent 可以看到有已经安装类包进行安装memchache （到官网下载自己需要的软件版本）解压文件并将文件移动到 /usr/local/ 目录下进入memcache目录进行安装可能会有一个报错因为libevent这个包是系统默认安装的，没有安装相应的开发所用的头文件，所以需要使用以下命令进行安装再次编译即可通过，编译通过后执行 make &amp;&amp; make install命令进行安装启动memcache/usr/local/memcached/bin/memcached -d -m 128 -l 172.31.8.50 -p 11211 -u root 进行连接测试telnet 172.31.8.50 11211 #出现以下内容即为安装成功 输出数据的格式如下：set foo 0 0 3 bar 如果保存成功，控制台会输出STORED获取数据的命令格式如下get foo 在控制台的输出信息如下链接到memcache后输入stats可以获得包括资源利用率在内的个种信息此外输入”stats items”可以获得关于缓存记录的信息，推出程序输入“quit”这些参数的具体含义可以参考下面的列表]]></content>
      <categories>
        <category>Linux</category>
        <category>memcache</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>memcache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis集群构建（伪集群）]]></title>
    <url>%2F2018%2F02%2F13%2Fredis%E9%9B%86%E7%BE%A4%E6%9E%84%E5%BB%BA%EF%BC%88%E4%BC%AA%E9%9B%86%E7%BE%A4%EF%BC%89%2F</url>
    <content type="text"><![CDATA[简介：用两个虚拟机模拟6个redis节点，一台机器三个节点，创建3个master、3个salve节点。redis采用3.2.4两台机器都是centos6.8，分别为172.31.8.102、172.31.8.24一、安装过程1、下载并解压[root@localhost ~]# mkdir /software [root@localhost software]#wget http://download.redis.io/releases/redis-3.2.4.tar.gz [root@localhost software]# tar -zxvf redis-3.2.4.tar.gz 2、编译安装[root@localhost software]# cd redis-3.2.4 [root@localhost redis-3.2.4]# make &amp;&amp; make install 3、将redis-trib.rb 复制到/usr/local/bin/[root@localhost redis-3.2.4]# ll src/redis-trib.rb -rwxrwxr-x. 1 root root 60852 9月 26 2016 src/redis-trib.rb [root@localhost redis-3.2.4]# cp src/redis-trib.rb /usr/local/bin/ 4、创建redis节点首先在172.31.8.102节点上/software/redis-3.2.4目录下创建redis_cluster目录[root@localhost redis-3.2.4]# mkdir redis_cluster 在redis_cluster目录下创建7000、7001、7002目录，并把redis.conf文件copy到这三个目录中[root@localhost redis_cluster]# mkdir 7000 7001 7002 [root@localhost redis-3.2.4]# cp redis.conf redis_cluster/7000/ [root@localhost redis-3.2.4]# cp redis.conf redis_cluster/7001/ [root@localhost redis-3.2.4]# cp redis.conf redis_cluster/7002/ 分别修改三个文件port 7000 //端口7000,7002,7003 bind 本机ip //默认ip为127.0.0.1 需要改为其他节点机器可访问的ip 否则创建集群时无法访问对应的端口，无法创建集群 daemonize yes //redis后台运行 pidfile /var/run/redis_7000.pid //pidfile文件对应7000,7001,7002 cluster-enabled yes //开启集群 把注释#去掉 cluster-config-file nodes_7000.conf //集群的配置 配置文件首次启动自动生成 7000,7001,7002 cluster-node-timeout 15000 //请求超时 默认15秒，可自行设置 appendonly yes //aof日志开启 有需要就开启，它会每次写操作都记录一条日志 接着在另一台机器上（172.31.8.24）重复操作以上四步，只是把目录改为7003、7004、7005，对应的配置文件也按照相应的规则修改即可5、启动各个节点在第一台机器上操作[root@localhost redis-3.2.4]# redis-server redis_cluster/7000/redis.conf [root@localhost redis-3.2.4]# redis-server redis_cluster/7001/redis.conf [root@localhost redis-3.2.4]# redis-server redis_cluster/7002/redis.conf 在第二台机器上操作[root@localhost redis-3.2.4]# redis-server redis_cluster/7003/redis.conf [root@localhost redis-3.2.4]# redis-server redis_cluster/7004/redis.conf [root@localhost redis-3.2.4]# redis-server redis_cluster/7005/redis.conf 6、检查redis启动情况第一台机器第二台机器7、创建集群redis官方提供了redis-trib.rb工具，就在已解压的src目录中，第三步已经将它拷贝到了/usr/local/bin/目录中，可以在命令行中使用了，使用以下命令创建集群：使用这个工具需要ruby，使用yum安装即可：yum -y install ruby ruby-devel rubygems rpm-build [root@localhost redis-3.2.4]# redis-trib.rb create --replicas 1 172.31.8.102:7000 172.31.8.102:7001 172.31.8.102:7002 172.31.8.24:7003 172.31.8.24:7004 172.31.8.24:7005 前三个IP:port为第一个节点，后面三个为第二个节点可能会出现的报错：这是因为ruby版本较低。yum安装的版本是1.8.7，但是redis需要的是1.9.3或者更高[root@localhost bin]# gem sources -a https://ruby.taobao.org/ [root@localhost bin]# gem install redis --version 3.0.0 之后再运行redis-trib.rb，会出现如下提示：输入“yes”回车即可，然后出现如下内容，说明安装成功二、集群验证在第一台机器上连接集群的7002端口的节点，在另外一台连接7005节点，连接方式为 redis-cli -h 172.31.8.102 -c -p 7002,加参数 -c 可连接到集群，因为上面 redis.conf 将 bind 改为了ip地址，所以 -h 参数不可以省略。在7005节点执行命令：然后在另外一台7002端口,查看key为hello的内容,get hello,执行结果如下：说明集群运作正常三、原理简介：redis cluster在设计的时候，就考虑到了去中心化,去中间件,也就是说,集群中的每个节点都是平等的关系,都是对等的,每个节点都保存各自的数据和整个集群的状态,每个节点都和其他所有节点连接而且这些连接保持活跃这样就保证了我们只需要连接集群中的任意一个节点,就可以获取到其他节点的数据.Redis 集群没有并使用传统的一致性哈希来分配数据，而是采用另外一种叫做哈希槽(hash slot)方式来分配的。rediscluster默认分配了16384个slot,当我们set一个key时,会用CRC16算法来取模得到所属的slot,然后将这个key 分到哈希槽区间的节点上,具体算法就是：CRC16(key) % 16384,所以我们在测试的时候看到set 和 get 的时候，直接跳转到了7000端口的节点.Redis集群会把数据存在一个master节点,然后在这个master和其对应的salve之间进行数据同步.当读取数据时,也根据一致性哈希算法到对应的master节点获取数据,只有当一个master 挂掉之后，才会启动一个对应的salve节点,充当 master.需要注意的是：必须要3个或以上的主节点，否则在创建集群时会失败，并且当存活的主节点数小于总节点数的一半时，整个集群就无法提供服务了。]]></content>
      <categories>
        <category>Linux</category>
        <category>redis</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[批量ping存活主机]]></title>
    <url>%2F2017%2F11%2F17%2F%E6%89%B9%E9%87%8Fping%E5%AD%98%E6%B4%BB%E4%B8%BB%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[创建一个ip.txt文件，把需要测试IP地址写入文档创建一个ping.sh 的shell 脚本，并修改ip.txt 文件路径#!/bin/bash for ips in `cat /root/manager/script/ip.txt` do result=`ping -w 2 -c 3 ${ips} | grep packet | awk -F&quot; &quot; &apos;{print $6}&apos;| awk -F&quot;%&quot; &apos;{print $1}&apos;| awk -F&apos; &apos; &apos;{print $1}&apos;` if [ $result -eq 0 ]; then echo &quot;&quot;${ips}&quot; is ok !&quot; else echo &quot;&quot;${ips}&quot; is not connected .....&quot; fi done 给脚本执行权限 chmod +x ping.sh执行脚本[root@k8s-node1 script]# ./ping.sh 172.31.8.101 is ok ! 172.31.8.192 is ok ! 172.31.8.42 is ok ! 172.31.8.176 is ok ! 172.31.8.45 is ok ! [root@k8s-node1 script]#]]></content>
      <categories>
        <category>Linux</category>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Haproxy入门(安装篇)]]></title>
    <url>%2F2017%2F11%2F09%2FHaproxy%E5%85%A5%E9%97%A8-%E5%AE%89%E8%A3%85%E7%AF%87%2F</url>
    <content type="text"><![CDATA[一、安装部署1.1 下载需要的haproxy版本并上传到服务器上wget http://pkgs.fedoraproject.org/repo/pkgs/haproxy/haproxy-1.7.9.tar.gz 1.2 解压haproxytar -zxvf haproxy-1.7.9.tar.gz cd haproxy-1.7.9 查看linux内核版本1.3 安装make TARGET=linux26 prefix=/usr/local/haproxy make install PREFIX=/usr/local/haproxy 参数说明： TARGET=linux26 #使用uname -r查看内核，如：2.6.18-371.el5，此时该参数就为linux26 #kernel 大于2.6.28的用：TARGET=linux2628 CPU=x86_64 #使用uname -r查看系统信息，如x86_64 x86_64 x86_64 GNU/Linux，此时该参数就为x86_64 PREFIX=/usr/local/haprpxy #/usr/local/haprpxy为haprpxy安装路径 1.4 设置HAproxyhaproxy的配置文件需要自己创建 mkdir /usr/local/haproxy/conf/ mkdir /usr/local/haproxy/logs 1.5 配置haproxy.cfg参数vim /usr/local/haproxy/haproxy.cfg 填写以下内容： global log 127.0.0.1 local3 chroot /usr/local/haproxy pidfile /usr/local/haproxy/logs/haproxy.pid maxconn 4000 uid 99 gid 99 daemon nbproc 1 stats socket /usr/local/haproxy/haproxy.sock level admin #--------------------------------------------------------------------- # common defaults that all the &apos;listen&apos; and &apos;backend&apos; sections will # use if not designated in their block #--------------------------------------------------------------------- defaults log global option dontlognull option redispatch mode http timeout connect 5000 timeout client 50000 timeout server 50000 listen stats mode http bind 172.31.8.102:8888 stats enable stats uri /haproxy-status stats auth haproxy:haproxy stats hide-version stats admin if TRUE ######################################################################## backend test-web mode http acl being_scanned be_conn gt 1500 http-request deny if being_scanned option httplog option httpclose option forwardfor log global server mobile-node9 172.31.8.24:80 cookie web1 check inter 500 rise 3 fall 3 1.6 启动haproxy/usr/local/haproxy/sbin/haproxy -f /usr/local/haproxy/haproxy.cfg 查看haproxy启动进程配置文件设置的访问用户名和密码为haproxy，web访问IP为172.31.8.102端口号为88881.7 使用浏览器进行访问测试http://172.31.8.102:8888/haproxy-status 1.8 测试1.8.1 启动nginx服务，检测到的状态为正常1.8.2 停掉nginx服务，检测到的状态为DOWN1.9 编写haproxy启动脚本vim haproxy.sh 填写入以下内容：#!/bin/bash BASE_DIR=&quot;/usr/local/haproxy&quot; ARGV=&quot;$@&quot; pp=`ps -fe |grep haproxy |grep -v &quot;grep&quot; |grep -v &quot;haproxy.sh&quot;|awk &apos;{print $2}&apos;` start() { echo &quot;START HAPoxy SERVERS OK&quot; $BASE_DIR/sbin/haproxy -f /usr/local/haproxy/haproxy.cfg } stop() { kill -9 $pp echo &quot;STOP HAPoxy Listen OK&quot; } case $ARGV in start) start ERROR=$? ;; stop) stop ERROR=$? ;; restart) stop start ERROR=$? ;; *) echo &quot;haproxy.sh [start|restart|stop]&quot; esac exit $ERROR 1.9.1 给脚本执行权限chmod +x haproxy.sh 1.9.2 脚本验证安装验证正常，HAproxy安装完毕（以上为haproxy单节点安装，启动脚本、haproxy.cfg配置文件可看下面汇总内容）二、配置文件汇总:2.1 haproxy.cfg 配置文件 global log 127.0.0.1 local3 chroot /usr/local/haproxy pidfile /usr/local/haproxy/logs/haproxy.pid maxconn 4000 uid 99 gid 99 daemon nbproc 1 stats socket /usr/local/haproxy/haproxy.sock level admin #--------------------------------------------------------------------- # common defaults that all the &apos;listen&apos; and &apos;backend&apos; sections will # use if not designated in their block #--------------------------------------------------------------------- defaults log global option dontlognull option redispatch mode http timeout connect 5000 timeout client 50000 timeout server 50000 listen stats mode http bind 172.31.8.102:8888 stats enable stats uri /haproxy-status stats auth haproxy:haproxy stats hide-version stats admin if TRUE ######################################################################## backend test-web mode http acl being_scanned be_conn gt 1500 http-request deny if being_scanned option httplog option httpclose option forwardfor log global server mobile-node9 172.31.8.24:80 cookie web1 check inter 500 rise 3 fall 3 server mobile-node8 172.31.8.102:80 cookie web1 check inter 500 rise 3 fall 3 2.2 haproxy.sh 启动脚本：#!/bin/bash BASE_DIR=&quot;/usr/local/haproxy&quot; ARGV=&quot;$@&quot; pp=`ps -fe |grep haproxy |grep -v &quot;grep&quot; |grep -v &quot;haproxy.sh&quot;|awk &apos;{print $2}&apos;` start() { echo &quot;START HAPoxy SERVERS OK&quot; $BASE_DIR/sbin/haproxy -f /usr/local/haproxy/haproxy.cfg } stop() { kill -9 $pp echo &quot;STOP HAPoxy Listen OK&quot; } case $ARGV in start) start ERROR=$? ;; stop) stop ERROR=$? ;; restart) stop start ERROR=$? ;; *) echo &quot;haproxy.sh [start|restart|stop]&quot; esac exit $ERROR]]></content>
      <categories>
        <category>Linux</category>
        <category>Haproxy</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Haproxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql性能的检查和调优方法]]></title>
    <url>%2F2017%2F08%2F20%2Fmysql%E6%80%A7%E8%83%BD%E7%9A%84%E6%A3%80%E6%9F%A5%E5%92%8C%E8%B0%83%E4%BC%98%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[我一直是使用mysql这个数据库软件，它工作比较稳定，效率也很高。在遇到严重性能问题时，一般都有这么几种可能：1、索引没有建好；2、sql写法过于复杂；3、配置错误；4、机器实在负荷不了；1、索引没有建好如果看到mysql消耗的cpu很大，可以用mysql的client工具来检查。在linux下执行/usr/local/mysql/bin/mysql -hlocalhost -uroot -p 输入密码，如果没有密码，则不用-p参数就可以进到客户端界面中。看看当前的运行情况show full processlist 可以多运行几次这个命令可以看到当前正在执行的sql语句，它会告知执行的sql、数据库名、执行的状态、来自的客户端ip、所使用的帐号、运行时间等信息在我的cache后端，这里面大部分时间是看不到显示任何sql语句的，我认为这样才算比较正常。如果看到有很多sql语句，那么这台mysql就一定会有性能问题如果出现了性能问题，则可以进行分析：1、是不是有sql语句卡住了？这是出现比较多的情况，如果数据库是采用myisam，那么有可能有一个写入的线程会把数据表给锁定了，如果这条语句不结束，则其它语句也无法运行。查看processlist里的time这一项，看看有没有执行时间很长的语句，要留意这些语句。2、大量相同的sql语句正在执行如果出现这种情况，则有可能是该sql语句执行的效率低下，同样要留意这些语句。然后把你所怀疑的语句统统集合一下，用desc（explain）来检查这些语句。首先看看一个正常的desc输出：mysql&gt; desc select * from imgs where imgid=1651768337; +—-+————-+——-+——-+—————+———+———+——-+——+——-+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +—-+————-+——-+——-+—————+———+———+——-+——+——-+ | 1 | SIMPLE | imgs | const | PRIMARY | PRIMARY | 8 | const | 1 | | +—-+————-+——-+——-+—————+———+———+——-+——+——-+ 1 row in set (0.00 sec) 注意key、rows和Extra这三项，这条语句返回的结果说明了该sql会使用PRIMARY主键索引来查询，结果集数量为1条，Extra没有显 示，证明没有用到排序或其他操作。由此结果可以推断，mysql会从索引中查询imgid=1651768337这条记录，然后再到真实表中取出所有字 段，是很简单的操作。key是指明当前sql会使用的索引，mysql执行一条简单语句时只能使用到一条索引，注意这个限制；rows是返回的结果集大小，结果集就是使用该索引进行一次搜索的所有匹配结果；Extra一般会显示查询和排序的方式，。如果没有使用到key，或者rows很大而用到了filesort排序，一般都会影响到效率，例如：mysql&gt; desc select * from imgs where userid=”7mini” order by clicks desc limit 10; +—-+————-+——-+——+—————+——+———+——+——-+—————————–+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +—-+————-+——-+——+—————+——+———+——+——-+—————————–+ | 1 | SIMPLE | imgs | ALL | NULL | NULL | NULL | NULL | 12506 | Using where; Using filesort | +—-+————-+——-+——+—————+——+———+——+——-+—————————–+ 1 row in set (0.00 sec) 这条sql结果集会有12506条，用到了filesort，所以执行起来会非常消耗效率的。这时mysql执行时会把整个表扫描一遍，一条一条去找到匹 配userid=”7mini”的记录，然后还要对这些记录的clicks进行一次排序，效率可想而知。真实执行时如果发现还比较快的话，那是因为服务器 内存还足够将12506条比较短小的记录全部读入内存，所以还比较快，但是并发多起来或者表大起来的话，效率问题就严重了。这时我把userid加入索引：create index userid on imgs (userid); 然后再检查：mysql&gt; desc select * from imgs where userid=”7mini” order by clicks desc limit 10; +—-+————-+——-+——+—————+——–+———+——-+——+—————————–+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +—-+————-+——-+——+—————+——–+———+——-+——+—————————–+ | 1 | SIMPLE | imgs | ref | userid | userid | 51 | const | 8 | Using where; Using filesort | +—-+————-+——-+——+—————+——–+———+——-+——+—————————–+ 1 row in set (0.00 sec) 嗯，这时可以看到mysql使用了userid这个索引搜索了，用userid索引一次搜索后，结果集有8条。然后虽然使用了filesort一条一条排序，但是因为结果集只有区区8条，效率问题得以缓解。但是，如果我用别的userid查询，结果又会有所不同：mysql&gt; desc select * from imgs where userid=”admin” order by clicks desc limit 10; +—-+————-+——-+——+—————+——–+———+——-+——+—————————–+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +—-+————-+——-+——+—————+——–+———+——-+——+—————————–+ | 1 | SIMPLE | imgs | ref | userid | userid | 51 | const | 2944 | Using where; Using filesort | +—-+————-+——-+——+—————+——–+———+——-+——+—————————–+ 1 row in set (0.00 sec) 这个结果和userid=”7mini”的结果基本相同，但是mysql用userid索引一次搜索后结果集的大小达到2944条，这2944条记录都会 加入内存进行filesort，效率比起7mini那次来说就差很多了。这时可以有两种办法可以解决，第一种办法是再加一个索引和判断条件，因为我只需要 根据点击量取最大的10条数据，所以有很多数据我根本不需要加进来排序，比如点击量小于10的，这些数据可能占了很大部分。我对clicks加一个索引，然后加入一个where条件再查询：create index clicks on imgs(clicks); mysql&gt; desc select * from imgs where userid=”admin” order by clicks desc limit 10; +—-+————-+——-+——+—————+——–+———+——-+——+—————————–+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +—-+————-+——-+——+—————+——–+———+——-+——+—————————–+ | 1 | SIMPLE | imgs | ref | userid,clicks | userid | 51 | const | 2944 | Using where; Using filesort | +—-+————-+——-+——+—————+——–+———+——-+——+—————————–+ 1 row in set (0.00 sec) 这时可以看到possible_keys变成了userid,clicks，possible_keys是可以匹配的所有索引，mysql会从 possible_keys中自己判断并取用其中一个索引来执行语句，值得注意的是，mysql取用的这个索引未必是最优化的。这次查询mysql还是使 用userid这个索引来查询的，并没有按照我的意愿，所以结果还是没有什么变化。改一下sql加上use index强制mysql使用clicks索引：mysql&gt; desc select * from imgs use index (clicks) where userid=’admin’ and clicks&gt;10 order by clicks desc limit 10 +—-+————-+——-+——-+—————+——–+———+——+——+————-+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +—-+————-+——-+——-+—————+——–+———+——+——+————-+ | 1 | SIMPLE | imgs | range | clicks | clicks | 4 | NULL | 5455 | Using where | +—-+————-+——-+——-+—————+——–+———+——+——+————-+ 1 row in set (0.00 sec) 这时mysql用到了clicks索引进行查询，但是结果集比userid还要大！看来还要再进行限制：mysql&gt; desc select * from imgs use index (clicks) where userid=’admin’ and clicks&gt;1000 order by clicks desc limit 10 +—-+————-+——-+——-+—————+——–+———+——+——+————-+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +—-+————-+——-+——-+—————+——–+———+——+——+————-+ | 1 | SIMPLE | imgs | range | clicks | clicks | 4 | NULL | 312 | Using where | +—-+————-+——-+——-+—————+——–+———+——+——+————-+ 1 row in set (0.00 sec) 加到1000的时候结果集变成了312条，排序效率应该是可以接受。不过，采用换索引这种优化方式需要取一个采样点，比如这个例子中的1000这个数字，这样，对userid的每个数值，都要去找一个采样点，这样对程序来 说是很难办的。如果按1000取样的话，那么userid=’7mini’这个例子中，取到的结果将不会是8条，而是2条，给用户造成了困惑。当然还有另一种办法，加入双索引：create index userid_clicks on imgs (userid, clicks) mysql&gt; desc select * from imgs where userid=”admin” order by clicks desc limit 10; +—-+————-+——-+——+———————-+—————+———+——-+——+————-+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +—-+————-+——-+——+———————-+—————+———+——-+——+————-+ | 1 | SIMPLE | imgs | ref | userid,userid_clicks | userid_clicks | 51 | const | 2944 | Using where | +—-+————-+——-+——+———————-+—————+———+——-+——+————-+ 1 row in set (0.00 sec) 这时可以看到，结果集还是2944条，但是Extra中的filesort不见了。这时mysql使用userid_clicks这个索引去查询，这不但 能快速查询到userid=”admin”的所有记录，并且结果是根据clicks排好序的！所以不用再把这个结果集读入内存一条一条排序了，效率上会高 很多。但是用多字段索引这种方式有个问题，如果查询的sql种类很多的话，就得好好规划一下了，否则索引会建得非常多，不但会影响到数据insert和update的效率，而且数据表也容易损坏。以上是对索引优化的办法，因为原因可能会比较复杂，所以写得比较的长，一般好好优化了索引之后，mysql的效率会提升n个档次，从而也不需要考虑增加机器来解决问题了。但是，mysql甚至所有数据库，可能都不好解决limit的问题。在mysql中，limit 0,10只要索引合适，是没有问题的，但是limit 100000,10就会很慢了，因为mysql会扫描排好序的结果，然后找到100000这个点，取出10条返回。要找到100000这个点，就要扫描 100000条记录，这个循环是比较耗时的。不知道会不会有什么好的算法可以优化这个扫描引擎，我冥思苦想也想不出有什么好办法。对于limit，目前直 至比较久远的将来，我想只能通过业务、程序和数据表的规划来优化，我想到的这些优化办法也都还没有一个是万全之策，往后再讨论。2、sql写法过于复杂sql写法假如用到一些特殊的功能，比如groupby、或者多表联合查询的话，mysql用到什么方式来查询也可以用desc来分析，我这边用复杂sql的情况还不算多，所以不常分析，暂时就没有好的建议。3、配置错误配置里主要参数是key_buffer、sort_buffer_size/myisam_sort_buffer_size，这两个参数意思是：key_buffer=128M：全部表的索引都会尽可能放在这块内存区域内，索引比较大的话就开稍大点都可以，我一般设为128M，有个好的建议是把很少用到并且比较大的表想办法移到别的地方去，这样可以显著减少mysql的内存占用。sort_buffer_size=1M：单个线程使用的用于排序的内存，查询结果集都会放进这内存里，如果比较小，mysql会多放几次，所以稍微开大一点就可以了，重要是优化好索引和查询语句，让他们不要生成太大的结果集。另外一些配置：thread_concurrency=8：这个配置标配=cpu数量x2interactive_timeout=30wait_timeout=30：这两个配置使用10-30秒就可以了，这样会尽快地释放内存资源，注意：一直在使用的连接是不会断掉的，这个配置只是断掉了长时间不动的连接。query_cache：这个功能不要使用，现在很多人看到cache这几个字母就像看到了宝贝，这是不唯物主义的。mysql的query_cache 在每次表数据有变化的时候都会重新清理连至该表的所有缓存，如果更新比较频繁，query_cache不但帮不上忙，而且还会对效率影响很大。这个参数只 适合只读型的数据库，如果非要用，也只能用query_cache_type=2自行用SQL_CACHE指定一些sql进行缓存。max_connections：默认为100，一般情况下是足够用的，但是一般要开大一点，开到400-600就可以了，能超过600的话一般就有效率问题，得另找对策，光靠增加这个数字不是办法。其它配置可以按默认就可以了，个人觉得问题还不是那么的大，提醒一下：1、配置虽然很重要，但是在绝大部分情况下都不是效率问题的罪魁祸首。2、mysql是一个数据库，对于数据库最重要考究的不应是效率，而是稳定性和数据准确性。4、机器实在负荷不了如果做了以上调整，服务器还是不能承受，那就只能通过架构级调整来优化了。1、mysql同步。通过mysql同步功能将数据同步到数台从数据库，由主数据库写入，从数据库提供读取。我个人不是那么乐意使用mysql同步，因为这个办法会增加程序的复杂性，并常常会引起数据方面的错误。在高负荷的服务中，死机了还可以快速重启，但数据错误的话要恢复就比较麻烦。2、加入缓存加入缓存之后，就可以解决并发的问题，效果很明显。如果是实时系统，可以考虑用刷新缓存方式使缓存保持最新。在前端加入squid的架构比较提倡使用，在命中率比较高的应用中，基本上可以解决问题。如果是在程序逻辑层里面进行缓存，会增加很多复杂性，问题会比较多而且难解决，不建议在这一层面进行调整。3、程序架构调整，支持同时连接多个数据库如果web加入缓存后问题还是比较严重，只能通过程序架构调整，把应用拆散，用多台的机器同时提供服务。如果拆散的话，对业务是有少许影响，如果业务当中有部分功能必须使用所有的数据，可以用一个完整库+n个分散库这样的架构，每次修改都在完整库和分散库各操作一次，或定期整理完整库。当然，还有一种最笨的，把数据库整个完完整整的做拷贝，然后程序每次都把完整的sql在这些库执行一遍，访问时轮询访问，我认为这样要比mysql同步的方式安全。4、使用 mysql proxy 代理mysql proxy 可以通过代理把数据库中的各个表分散到数台服务器，但是它的问题是没有能解决热门表的问题，如果热门内容散在多个表中，用这个办法是比较轻松就能解决问题。我没有用过这个软件也没有认真查过，不过我对它的功能有一点点怀疑，就是它怎么实现多个表之间的联合查询？如果能实现，那么效率如何呢？5、使用memcachedb数据库换用支持mysql的memcachedb，是可以一试的想法，从memcachedb的实现方式和层面来看对数据没有什么影响，不会对用户有什么困扰。为我现在因为数据库方面问题不多，没有试验过这个玩意。不过，只要它支持mysql的大部分主要的语法，而且本身稳定，可用性是无需置疑的。]]></content>
      <categories>
        <category>Linux</category>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[快速清除MySQL数据库的密码]]></title>
    <url>%2F2017%2F08%2F19%2F%E5%BF%AB%E9%80%9F%E6%B8%85%E9%99%A4MySQL%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%AF%86%E7%A0%81%2F</url>
    <content type="text"><![CDATA[关闭mysql数据库：service mysqld stop &amp; mysqladmin shutdown 跳过mysql服务器授权mysqld_safe --skip-grant-tables --skip-networking &amp; 登录数据库：mysql 打开mysql库：use mysql 更新数据库密码：update user set password=password (&quot;新密码&quot;) where user=&quot;root&quot;; 更新用户权限使其立即生效：flush privileges; 退出数据库：exit; 重新启动mysql数据库：service mysqld start]]></content>
      <categories>
        <category>Linux</category>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL索引管理]]></title>
    <url>%2F2017%2F08%2F13%2FMySQL%E7%B4%A2%E5%BC%95%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[1、重建索引命令mysql&amp;gt; REPAIR TABLE tbl_name QUICK; 2、查询数据表索引mysql&amp;gt; SHOW INDEX FROM tbl_name; 3、创建索引（PRIMARY KEY，INDEX，UNIQUE）支持创建主键索引，联合索引和普通索引命令mysql&amp;gt;ALTER TABLE tbl_name ADD INDEX index_name (column list);mysql&amp;gt;ALTER TABLE tbl_name ADD UNIQUE index_name (column list);mysql&amp;gt;ALTER TABLE tbl_name ADD PRIMARY KEY index_name (column list); 4、删除索引（PRIMARY KEY，INDEX，UNIQUE）支持删除主键索引，联合索引和普通索引命令mysql&amp;gt;ALTER TABLE tbl_name DROP INDEX index_name (column list);mysql&amp;gt;ALTER TABLE tbl_name DROP UNIQUE index_name (column list);mysql&amp;gt;ALTER TABLE tbl_name DROP PRIMARY KEY index_name (column list); 其中 tbl_name 表示数据表名，index_name 表示索引名，column list 表示字段列表]]></content>
      <categories>
        <category>Linux</category>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux服务器制定mysql数据库备份的计划任务]]></title>
    <url>%2F2017%2F08%2F11%2FLinux%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%88%B6%E5%AE%9Amysql%E6%95%B0%E6%8D%AE%E5%BA%93%E5%A4%87%E4%BB%BD%E7%9A%84%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[首先，创建一个shell脚本：#!/bin/bash mysql_pwd=&quot;1234567890&quot; mysql_dump=&quot;/usr/local/mysql/bin/mysqldump&quot; cur_year=$(date +&quot;%Y&quot;) cur_month=$(date +&quot;%m&quot;) cur_day=$(date +&quot;%d&quot;) #dump_path=&quot;/data0/mysql_backup/$cur_year-$cur_month/$cur_day&quot; arr_databases=( &quot;db1&quot; &quot;db2&quot; &quot;db3&quot; &quot;db4&quot; ) for cur_database in ${arr_databases[*]}; do #mkdir backup path dump_path=&quot;/data0/mysql_backup/$cur_database&quot; if [ ! -d &quot;$dump_path&quot; ]; then mkdir -p &quot;$dump_path&quot; fi #backup database $mysql_dump -uroot -p$mysql_pwd $cur_database | gzip &gt; $dump_path/$cur_database-$cur_year-$cur_month-$cur_day.sql.gz #Delete backup files 10 days ago cd $dump_path rm -rf `find . -name &apos;*.sql.gz&apos; -mtime 20` done 可以保存到路径：/data0/scripts/backup_database.sh设置可执行权限 cd /data0/scripts/ chmod +x * 添加计划任务vi /etc/crontab 添加命令： 01 1 * * * root /data0/scripts/backup_database.sh #每天的01点01分执行 20 2 * * 0 root /data0/scripts/backup_database.sh #每周星期天的02点20分执行 重启服务 /sbin/service crond restart]]></content>
      <categories>
        <category>Linux</category>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[查看MySQL运行状况]]></title>
    <url>%2F2017%2F08%2F06%2F%E6%9F%A5%E7%9C%8BMySQL%E8%BF%90%E8%A1%8C%E7%8A%B6%E5%86%B5%2F</url>
    <content type="text"><![CDATA[直接在命令行下登陆MySQL运行SHOW STATUS;查询语句，详细如下图SHOW STATUS SHOW VARIABLES SHOW VARIABLES --- 是查看MySQL的配置参数，还可以使用类似SHOW VARIABLES LIKE ‘Key%’ SHOW PROCESSLIST SHOW PROCESSLIST --- 是查看当前正在进行的进程，对于有锁表等情况的排查很有用处。一般情况下，打开MySQL的慢查询记录同样有利于排查。 SHOW OPEN TABLES SHOW OPEN TABLES --- 是显示当前已经被打开的表列表。 mysqladmin status 使用MySQL自带的mysqladmin 工具查看status，使用以下命令mysqladmin -uroot –password=’password’ status 显示的结果如下：Uptime: 87117 Threads: 1 Questions: 5481626 Slow queries: 16 Opens: 2211 Flush tables: 1 Open tables: 512 Queries per second avg: 62.923 另外可以添加 -i 5 参数，让其每五秒自动刷新之。mysqladmin -uroot –password=’password’ status -i 5 mysqladmin extended-status 同样的可以使用以下命令来查看更多的MySQL运行信息，这种方式和第一种查看的信息基本一样。mysqladmin -uroot –password=’password’ extended-status]]></content>
      <categories>
        <category>Linux</category>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL数据库备份命令]]></title>
    <url>%2F2017%2F08%2F06%2F%E5%A4%87%E4%BB%BDMySQL%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[备份MySQL数据库的命令mysqldump -hhostname -uusername -ppassword databasename &gt; backupfile.sql 备份MySQL数据库为带删除表的格式，能够让该备份覆盖已有数据库而不需要手动删除原有数据库。mysqldump -–dd-drop-table -uusername -ppassword databasename &gt; backupfile.sql 直接将MySQL数据库压缩备份mysqldump -hhostname -uusername -ppassword databasename | gzip &gt; backupfile.sql.gz 备份MySQL数据库某个（些）表mysqldump -hhostname -uusername -ppassword databasename specific_table specific_table2 &gt; backupfile.sql 同时备份多个MySQL数据库mysqldump -hhostname -uusername -ppassword -databases databasename databasename2 databasename3 &gt; multibackupfile.sql 仅仅备份数据库结构mysqldump –no-data – databases databasename databasename2 databasename3 &gt; structurebackupfile.sql 备份服务器上所有数据库mysqldump –all-databases &gt; allbackupfile.sql 还原MySQL数据库的命令mysql -hhostname -uusername -ppassword databasename &lt; backupfile.sql 还原压缩的MySQL数据库gunzip &lt; backupfile.sql.gz | mysql -uusername -ppassword databasename 将数据库转移到新服务器mysqldump -uusername -ppassword databasename | mysql –host=*.*.*.* -C databasename]]></content>
      <categories>
        <category>Linux</category>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 挂载新磁盘]]></title>
    <url>%2F2017%2F07%2F23%2FLinux-%E6%8C%82%E8%BD%BD%E6%96%B0%E7%A3%81%E7%9B%98%2F</url>
    <content type="text"><![CDATA[需求：新增加一块硬盘sdb，只分一个区，格式化挂载到/date1、查看现在已有的分区状态df -h图中显示没有看到sdb硬盘2、查看服务器安装的硬盘状态（包括格式化和未格式化的）fdisk -l图中显示，有sdb硬盘，但是没有分区3、添加新分区fdisk /dev/sdb按照以下红框输入：N 回车 P 回车 1 回车 两次回车 W 回车用以下命令查看分区fdisk -l图中红框显示已经多出了一个分区，但是没有格式化4、格式化分区mkfs -t ext4 -c /dev/sdb1-t 指定要把磁盘格式化成什么类型-c 在建立文件系统之前检查坏道，可能会很费时间，新硬盘一般不需要5、挂载新硬盘在根目录下建一个文件夹，待会将分区挂载在这个文件夹上，以后要往新硬盘存东西，就放在这个新建的文件夹里就可以mkdir /data挂载硬盘mount /dev/sdb1 /data6、让系统开机自动挂载这块硬盘echo “/dev/sdb1 /data ext4 defaults 0 0”&gt; /etc/fstab]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 软链接和硬链接介绍]]></title>
    <url>%2F2017%2F07%2F22%2FLinux-%E8%BD%AF%E9%93%BE%E6%8E%A5%E5%92%8C%E7%A1%AC%E9%93%BE%E6%8E%A5%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[一、硬链接（Hard Link）1.1 含义硬链接共用同一个inode号，只是文件名不同。1.2 查找文件的步骤当我们查找一个硬链接文件，比如/root/test-hard时，要经过以下步骤：1）首先找到根目录的inode（根目录的inode是系统已知的，inode号是2），然后判断用户是否有权限访问根目录的block。2）如果有权限，则可以在根目录的block中访问到/root的文件名及对应的inode号。3）通过/root/目录的inode号，可以查找到/root/目录的inode信息，接着判断用户是否有权限访问/root/目录的block。4）如果有权限，则可以从/root/目录的block中读取到test-hard文件的文件名及对应的inode号。5）通过test-hard文件的inode号，就可以找到test-hard文件的inode信息，接着判断用户是否有权限访问test-hard文件的block。6）如果有权限，则可以读取block中的数据，这样就完成了/root/test-hard文件的读取与访问。1.3 硬链接的特点1）不论是修改源文件（test文件），还是修改硬链接文件（test-hard文件），另一个文件中的数据都会发生改变。2）不论是删除源文件，还是删除硬链接文件，只要还有一个文件存在，这个文件都可以被访问。3）硬链接不会建立新的inode信息，也不会更改inode的总数。4）硬链接不能跨文件系统（分区）建立，因为在不同的文件系统中，inode号是重新计算的。5）硬链接不能链接目录，因为如果给目录建立硬链接，那么不仅目录本身需要重新建立，目录下所有的子文件，包括子目录中的所有子文件都需要建立硬链接，这对当前的Linux来讲过于复杂。6）硬链接不会占用inode和block。二、软链接（Symbolic link）2.1 含义软链接有着自己的inode号以及用户数据块。只不过用户数据块中存放的内容是另一文件的路径名的指向。2.2 查找文件的步骤当我们查找一个软链接文件，比如/root/test-soft时，要经过以下步骤：1）首先找到根目录的inode索引信息，然后判断用户是否有权限访问根目录的block。2）如果有权限访问根目录的block，就会在block中查找到/root/目录的inode号。3）接着访问/root/目录的inode信息，判断用户是否有权限访问/root/目录的block。4）如果有权限，就会在block中读取到软链接文件test-soft的inode号。因为软链接文件会真正建立自己的inode索引和block，所以软链接文件和源文件的inode号是不一样的。5）通过软链接文件的inode号，找到了test-soft文件inode信息，判断用户是否有权限访问block。6）如果有权限，就会发现test-soft文件的block中没有实际数据，仅有源文件test的inode号。7）接着通过源文件的inode号，访问到源文件test的inode信息，判断用户是否有权限访问block。8）如果有权限，就会在test文件的block中读取到真正的数据，从而完成数据访问。2.3 软连接的特点1）不论是修改源文件（test），还是修改硬链接文件（test-soft)，另一个文件中的数据都会发生改变。2）删除软链接文件，源文件不受影响。而删除原文件，软链接文件将找不到实际的数据，从而显示文件不存在。3）软链接会新建自己的inode信息和block，只是在block中不存储实际文件数据，而存储的是源文件的文件名及inode号。4）软链接可以链接目录。5）软链接可以跨分区。6）软链接会占用inode和block。原文来自：https://www.linuxprobe.com/about-linux-link.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[防病毒体系规划]]></title>
    <url>%2F2017%2F07%2F03%2F%E9%98%B2%E7%97%85%E6%AF%92%E4%BD%93%E7%B3%BB%E8%A7%84%E5%88%92%2F</url>
    <content type="text"><![CDATA[计算机病毒形式及传播途径日趋多样化，网络防病毒工作已不再是简单的单台计算机病毒的检测及清除，需要建立多层次的、立体的病毒防护体系，而且要具备完善的管理系统来设置和维护病毒防护策略。这里的多层次病毒防护体系是指在企业的每台客户端计算机上安装防病毒系统，在服务器上安装基于服务器的防病毒系统，在Internet网关安装基于Internet网关的防病毒系统。对企业来说，防止病毒的攻击并不是保护某一台服务器或客户端计算机，而是从客户端计算机到服务器到网关以至于每台不同业务应用服务器的全面保护，这样才能保证整个网络不受计算机病毒的侵害。一、 防病毒系统总体规划防病毒系统不仅是检测和清除病毒，还应加强对病毒的防护工作，在网络中不仅要部署被动防御体系（防病毒系统）还要采用主动防御机制（防火墙、安全策略、漏洞修复等），将病毒隔离在网络大门之外。通过管理控制台统一部署防病毒系统，保证不出现防病毒漏洞。因此，远程安装、集中管理、统一防病毒策略成为企业级防病毒产品的重要需求。在跨区域的广域网内，要保证整个广域网安全无毒，首先要保证每一个局域网的安全无毒。也就是说，一个企业网的防病毒系统是建立在每个局域网的防病毒系统上的。应该根据每个局域网的防病毒要求，建立局域网防病毒控制系统，分别设置有针对性的防病毒策略。从总部到分支机构，由上到下，各个局域网的防病毒系统相结合，最终形成一个立体的、完整的企业网病毒防护体系。1. 构建控管中心集中管理架构保证网络中的所有客户端计算机、服务器可以从管理系统中及时得到更新，同时系统管理人员可以在任何时间、任何地点通过浏览器对整个防毒系统进行管理，使整个系统中任何一个节点都可以被系统管理人员随时管理，保证整个防毒系统有效、及时地拦截病毒。2. 构建全方位、多层次的防毒体系结合企业实际网络防毒需求，构建了多层次病毒防线，分别是网络层防毒、邮件网关防毒、Web网关防毒、群件防毒、应用服务器防毒、客户端防毒，保证斩断病毒可以传播、寄生的每一个节点，实现病毒的全面布控。3. 构建高效的网关防毒子系统网关防毒是最重要的一道防线，一方面消除外来邮件SMTP、POP3病毒的威胁，另一方面消除通过HTTP、FTP等应用的病毒风险，同时对邮件中的关键字、垃圾邮件进行阻挡，有效阻断病毒最主要传播途径。4. 构建高效的网络层防毒子系统企业中网络病毒的防范是最重要的防范工作，通过在网络接口和重要安全区域部署网络病毒系统，在网络层全面消除外来病毒的威胁，使得网络病毒不再肆意传播，同时结合病毒所利用的传播途径，结合安全策略进行主动防御。5. 构建覆盖病毒发作生命周期的控制体系当一个恶性病毒入侵时，防毒系统不仅仅使用病毒代码来防范病毒，而是具备完善的预警机制、清除机制、修复机制来实现病毒的高效处理，特别是对利用系统漏洞、端口攻击为手段瘫痪整个网络的新型病毒具有很好的防护手段。防毒系统在病毒代码到来之前，可以通过网关可疑信息过滤、端口屏蔽、共享控制、重要文件/文件夹写保护等多种手段来对病毒进行有效控制，使得新病毒未进来的进不来、进来后又没有扩散的途径。在清除与修复阶段又可以对发现的病毒高效清除，快速恢复系统至正常状态。6. 病毒防护能力防病毒能力要强、产品稳定、操作系统兼容性好、占用系统资源少、不影响应用程序的正常运行，减少误报的几率。7. 系统服务系统服务是整体防毒系统中极为重要的一环。防病毒体系建立起来之后，能否对病毒进行有效的防范，与病毒厂商能否提供及时、全面的服务有着极为重要的关系。这一方面要求软件提供商要有全球化的防毒体系为基础，另一方面也要求厂商能有精良的本地化技术人员作依托，不管是对系统使用中出现的问题，还是用户发现的可疑文件，都能进行快速的分析和方案提供。如果有新病毒爆发及其它网络安全事件，需要防病毒厂商具有较强的应急处理能力及售后服务保障，并且做出具体、详细的应急处理机制计划表和完善的售后服务保障体系。二、 防病毒系统具体需求在选择防病毒系统时，首先要考虑到整体性。企业级防病毒系统解决方案针对一个特定的网络环境，涉及不同的软硬件设备。与此同时，病毒的来源也远比单机环境复杂得多。因此所选择的防病毒系统不仅要能保护文件服务，同时也要对邮件服务器、客户端计算机、网关等所有设备进保护。同时，必须支持电子邮件、FTP文件、网页、软盘、光盘、U盘移动设备等所有可能带来病毒的信息源进行监控和病毒拦截。1. 病毒查杀能力病毒查杀能力是最容易引起用户注意的产品参数，可查杀病毒的种数固然是多多益善，但也要关注对实际流行病毒的查杀能力。因为用户是要用它查杀可能染上的病毒，有些病毒虽然曾流行过，但却是今后不会再遇上的。例如使用系统漏洞泛滥的病毒，当系统补丁成功更新后，该类病毒将不再生效。病毒查杀能力将体现在以下方面：· 病毒检测及清除能力：防病毒系统应具有对普通文件监控、内存监控、网页监控、引导区和注册表监控功能；具有间谍软件防护功能；可检测并清除隐藏于电子邮件、公共文件夹及数据库中的计算机病毒、恶性程序和垃圾邮件功能，能够自动隔离感染而暂时无法修复的文件；具有全网漏洞扫描和管理功能，可以通过扫描系统中存在的漏洞和不安全的设置，提供相应的解决方案，支持共享文件、OFFICE文档的病毒查杀、能够实现立体的多层面的病毒防御体系。· 电子邮件检测及清除能力：防病毒系统应具有对电子邮件接收/发送检测、邮件文件和邮箱的静态检测及清毒、至少同时支持Foxmail、Outlook、Outlook Express、等客户端邮件系统的防（杀）病毒、防止DDoS恶意攻击，保护重要的邮件服务器资源，不被大量散布的邮件病毒攻击，维护正常运作。· 未知病毒检测及清除能力：该杀毒软件应具有对未知病毒检测、清除能力、支持族群式变种病毒的查杀、能够对加壳的病毒文件进行病毒查杀、具有智能解包还原技术，能够对原始程序的入口进行检测。2. 对新病毒的反应能力对新病毒的反应能力是考察一个防病毒系统好坏的重要方面。这一点主要从三个方面衡量：软件供应商的病毒信息搜集网络、病毒代码的更新周期和供应商对用户发现的新病毒反应周期。通常，防病毒系统供应商都会在全国甚至全世界各地建立一个病毒信息的收集、分析和预测网络，使其软件能更加及时、有效地查杀新出现的病毒。因此，这一搜集网络多少反映了软件商对新病毒的反应能力。病毒代码的更新周期各个厂商也不尽相同，有的一个周更新一次，有的半个月。而供应商对用户发现的新病毒的反应周期不仅体现了厂商对新病毒的反应速度，实际上也反映了厂商对新病毒查杀的技术实力。3. 病毒实时监测能力按照统计，目前的病毒中最常见的是通过邮件系统来传输，另外还有一些病毒通过网页传播。这些传播途径都有一定的实时性，用户无法人为地了解可能感染的时间。因此，防病毒系统的实时监测能力显得相当重要。4. 快速、方便的升级企业级防病毒系统对更新的及时性需求尤其突出。多数防病毒系统采用Internet进行病毒代码和病毒查杀引擎的更新，并可以通过一定的设置自动进行，尽可能地减少人力的介入。升级信息需要和安装客户端计算机防病毒系统一样，能方便地“分发”到每台客户端计算机。5. 智能安装、远程识别由于局域网中，服务器、客户端承担的任务不同，在防病毒方面的要求也不同。因此在安装时需要能够自动区分服务器与客户端，并安装相应的软件。防病毒系统需要提供远程安装、远程设置、统一部署策略以及单台策略部署功能。该功能可以减轻管理员“奔波”于每台机器进行安装、设置的繁重工作，即可对全网的机器进行统一安装，又可以有针对性的设置。防病毒系统支持多种安装方式，包括：智能安装、远程客户端安装、WEB安装、E-mail安装、文件共享安装以及脚本登录安装等，通过这些多样化的安装方式，管理员可以轻松地在最短的时间内完成系统部署。6. 管理方便，易于操作系统的可管理性是衡量防病毒系统的重要指标。例如防病毒系统的参数设置。管理员从系统整体角度出发对各台计算机上的设置，如果各员工随意修改自己使用的计算机上防毒软件参数，可能会造成一些意想不到的漏洞，使病毒趁虚而入。管理者需要随时随地地了解各台计算机病毒感染的情况，并借此制定或调整防病毒策略。因此，生成病毒监控报告等辅助管理措施将会有助于防病毒系统应用更加得心应手。防病毒系统将支持以下管理功能：· 防病毒系统能够实现分级、分组管理，不同组及客户端执行不同病毒查杀策略，全网定时/定级查杀病毒、全网远程查杀策略设置、远程报警、移动式管理、集中式授权管理、全面监控主流邮件服务器、全面监控邮件客户端、 统一的管理界面，直接监视和操纵服务器端/客户端，根据实际需要，添加自定义任务（例如更新和扫描任务等），支持大型网络统一管理的多级中心系统等多种复杂的管理功能。· 防病毒系统支持“分布处理、集中控制”功能，以系统中心、控制台、服务器端、客房端为核心结构，控制台可支持跨网段使用，实现远程自动安装、远程集中控管、远程病毒报警、远程卸载、远程配置、智能升级、全网查杀、日志管理、病毒溯源等功能，将网络中的所有计算机有机地联系在一起，构筑成协调一致的立体防毒体系。· 防病毒系统具有病毒日志查询与统计功能，可以随时对网络中病毒发生的情况进行查询统计，能按时间（日、周或任意时间段）、按IP地址、机器名、按病毒名称、病毒类型进行统计查询；能将染毒机器进行排名，能将查询统计结果打印或导出，查询统计功能不需要借助其他数据库软件，减少用户总体成本。· 防病毒系统支持企业反病毒的统一管理和分布式管理。统一管理表现为由上级中心统一发送病毒命令、下达版本升级提示，并及时掌握整个网络的病毒分布情况等，分布管理表现为下级中心既可以对收到的上一级中心命令做出相应，也可以管理本级系统，并主动向上级中心请求和回报信息。7. 资源占用率防病毒系统进行实时监控或多或少地要占用部分系统资源，这就不可避免地要带来系统性能的降低。尤其是对邮件、网页和FTP文件的监控扫描，由于工作量相当大，因此对系统资源的占用较大。因此，防病毒系统占用系统资源要较低，不影响系统的正常运行。8. 系统兼容性防病毒系统要具备良好的兼容性，将支持以下操作系统：Windows NT、Windows2000、Windows 9X/Me、Windows XP/Vista、Windows 2000/2003 /2008 Server、 Unix、Linux等X86和X64架构的操作系统。9. 病毒库组件升级防病毒系统提供多种升级方式以及自动分发的功能，支持多种网络连接方式，具有升级方便、更新及时等特点，管理员可以十分轻松地按照预先设定的升级方式实现全网内的统一升级，减少病毒库增量升级对网络资源的占用，并且采用均衡流量的策略，尽快将新版本部署到全部计算机上，时刻保证病毒库都是最新的，且版本一致，杜绝因版本不一致而可能造成的安全漏洞和安全隐患。10. 软件商的企业实力软件商的实力一方面指它对现有产品的技术支持和服务能力，另一方面是指它的后续发展能力。因为企业级防毒软件实际是用户企业与防病毒厂商的长期合作，企业实力将会影响这种合作的持续性，从而影响到用户企业在此方面的投入成本三、 部署防病毒系统后的效果网络中部署防病毒系统后，将达到以下效果：· 在网络的网关处进行网络层病毒包扫描，及时清除蠕虫病毒攻击包，同时对控制病毒传播途径，对未安装防毒软件或未安装补丁的网络节点进行访问控制。· 对整个网络节点的脆弱性进行评估，及时阻挡不符合安全策略的节点的访问。· 对进出网关的邮件进行全面防毒扫描，发现病毒即时进行处理，并且给出管理员即时通知信息。· 采用数据库比对技术和智能性判断技术，对进出网关的邮件进行垃圾邮件过滤，在网关处将垃圾邮件有效删除掉。· 对进出网关的Web访问、FTP访问行全面防毒扫描，发现病毒即时进行处理，并且给出管理员即时的通知信息，同时对不良网站和URL地址进行过滤，阻挡恶意类型文件。· 对整个网络内的应用服务器进行全面防护，斩断病毒在服务器内的寄生及传播。· 对所有的客户机进行全面防护，彻底消除病毒对客户机的破坏，保证所有客户端计算机都有一个干净、安全的工作平台。· 所有防毒软件的升级、防毒策略的制定，将通过控管系统集中实现，一方面保证所有防毒软件得到即时更新，另一方面保证整个防毒策略的一致。同时生成整个网络统一的病毒报告日志，便于系统管理人员即时对病毒发现情况进行掌握，制定更加有效的网络平台安全使用策略。]]></content>
      <categories>
        <category>安全</category>
      </categories>
      <tags>
        <tag>安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[恶意代码相关术语解释]]></title>
    <url>%2F2017%2F06%2F29%2F%E6%81%B6%E6%84%8F%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3%E6%9C%AF%E8%AF%AD%E8%A7%A3%E9%87%8A%2F</url>
    <content type="text"><![CDATA[1. 什么是信息系统、漏洞、恶意代码?1.1 信息系统信息系统是指由计算机硬件、软件、网络和通信设备等组成的以处理信息和数据为目的的系统。1.2 漏洞漏洞是指信息系统中的软件、硬件或通信协议中存在缺陷或不适当的配置，从而可使攻击者在未授权的情况下访问或破坏系统，导致信息系统面临安全风险。1.3 恶意代码恶意代码是指在未经授权的情况下，在信息系统中安装、执行以达到不正当目的的程序。恶意代码分类说明如下：2. 特洛伊木马（Trojan Horse）特洛伊木马（简称木马）是以盗取用户个人信息，甚至是远程控制用户计算机为主要目的的恶意代码。由于它像间谍一样潜入用户的电脑，与战争中的“木马”战术十分相似，因而得名木马。按照功能，木马程序可进一步分为：盗号木马7、网银木马8、窃密木马9、远程控制木马10、流量劫持木马11、下载者木马12和其它木马六类。注：盗号木马是用于窃取用户电子邮箱、网络游戏等账号的木马。 注8：网银木马是用于窃取用户网银、证券等账号的木马。 注9：窃密木马是用于窃取用户主机中敏感文件或数据的木马。 注10：远程控制木马是以不正当手段获得主机管理员权限，并能够通过网络操控用户主机的木马。 注11：流量劫持木马是用于劫持用户网络浏览的流量到攻击者指定站点的木马。 注12：下载者木马是用于下载更多恶意代码到用户主机并运行，以进一步操控用户主机的木马。3. 僵尸程序（Bot）僵尸程序是用于构建大规模攻击平台的恶意代码。按照使用的通信协议，僵尸程序可进一步分为：IRC僵尸程序、Http僵尸程序、P2P僵尸程序和其它僵尸程序四类。4. 蠕虫（Worm）蠕虫是指能自我复制和广泛传播，以占用系统和网络资源为主要目的的恶意代码。按照传播途径，蠕虫可进一步分为：邮件蠕虫、即时消息蠕虫、U盘蠕虫、漏洞利用蠕虫和其它蠕虫五类。5. 病毒（Virus）病毒是通过感染计算机文件进行传播，以破坏或篡改用户数据，影响信息系统正常运行为主要目的恶意代码。6. 其它上述分类未包含的其它恶意代码。 随着黑客地下产业链的发展，互联网上出现的一些恶意代码还具有上述分类中的多重功能属性和技术特点，并不断发展。对此，我们将按照恶意代码的主要用途参照上述定义进行归类。6.1 僵尸网络僵尸网络是被黑客集中控制的计算机群，其核心特点是黑客能够通过一对多的命令与控制信道操纵感染木马或僵尸程序的主机执行相同的恶意行为，如可同时对某目标网站进行分布式拒绝服务攻击，或发送大量的垃圾邮件等。6.2 拒绝服务攻击拒绝服务攻击是向某一目标信息系统发送密集的攻击包，或执行特定攻击操作，以期致使目标系统停止提供服务。6.3 网页篡改网页篡改是恶意破坏或更改网页内容，使网站无法正常工作或出现黑客插入的非正常网页内容。6.4 网页仿冒网页仿冒是通过构造与某一目标网站高度相似的页面（俗称钓鱼网站），并通常以垃圾邮件、即时聊天、手机短信或网页虚假广告等方式发送声称来自于被仿冒机构的欺骗性消息，诱骗用户访问钓鱼网站，以获取用户个人秘密信息（如银行帐号和帐户密码）。6.5 网页挂马网页挂马是通过在网页中嵌入恶意代码或链接，致使用户计算机在访问该页面时被植入恶意代码。6.6 网站后门网站后门事件是指黑客在网站的特定目录中上传远程控制页面从而能够通过该页面秘密远程控制网站服务器的攻击事件。6.7 垃圾邮件垃圾邮件是将不需要的消息（通常是未经请求的广告）发送给众多收件人。包括：（一）收件人事先没有提出要求或者同意接收的广告、电子刊物、各种形式的宣传品等宣传性的电子邮件；（二）收件人无法拒收的电子邮件；（三）隐藏发件人身份、地址、标题等信息的电子邮件；（四）含有虚假的信息源、发件人、路由等信息的电子邮件。6.8 域名劫持域名劫持是通过拦截域名解析请求或篡改域名服务器上的数据，使得用户在访问相关域名时返回虚假IP地址或使用户的请求失败。6.9 非授权访问非授权访问是没有访问权限的用户以非正当的手段访问数据信息。非授权访问事件一般发生在存在漏洞的信息系统中，黑客利用专门的漏洞利用程序（Exploit）来获取信息系统访问权限。6.10 路由劫持路由劫持是通过欺骗方式更改路由信息，以导致用户无法访问正确的目标，或导致用户的访问流量绕行黑客设定的路径，以达到不正当的目的。]]></content>
      <categories>
        <category>安全</category>
        <category>代码审计</category>
      </categories>
      <tags>
        <tag>安全</tag>
        <tag>代码审计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zimbra 邮箱系统安装配置]]></title>
    <url>%2F2017%2F06%2F21%2Fzimbra%20%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[1、Zimbra介绍Zimbra与众不同的特点是其“Zimlet”网络服务提供了更多的电子邮件功能。例如，人们可以简单地用鼠标点击电子邮件程序中的航班信息以检查航班的状况。用户还可以在电子邮件中跟踪FedEx公司的投递情况并且获得地图、股票和其它信息。Zimbra的核心产品是Zimbra协作套件（Zimbra Collaboration Suite，简称ZCS）。除了它的核心功能是电子邮件和日程安排服务器，当然还包括许多其它的功能，就象是下一代的微软Exchange。在电子邮件和日程安排之外，它还提供文档存储和编辑、即时消息以及一个利用获奖技术开发的全功能的管理控制台。ZCS同时也提供移动设备的支持，以及与部署于Windows、Linux或apple操作系统中的桌面程序的同步功能。(来自百度百科)注:Zimbra安装时，须在linux系统上，系统内存至少一个GB，5G磁盘空间；否则安装过程会很长，且会因为内存和磁盘空间不够而导致安装失败2、安装配置DNS1、安装配置DNS配置vim /etc/named.conf #修改一下内容配置 vim /etc/named.rfc1912.zones #添加以下内容配置正向解析文件解析文件cd /var/namedcp named.localhost tzh.com.zonevim tzh.com.zone配置反向解析文件 #添加以下内容vim 10.90.10.zone启动bindservice named start解析nslookup www.tzh.comnslookup mail.tzh.com3、安装zimbra3.1、停止系统默认邮件服务Chkconfig postfix off &amp;&amp; /etc/init.d/postfix stop3.2、关闭iptables和selinuxsetenforce 0 &amp;&amp; service iptables stop &amp;&amp; chkconfig iptables off3.3、设置hosts文件 #添加以下内容3.4、 安装点击显/隐内容[root@tzh zcs-8.6.0_GA_1153.RHEL6_64.20141215151155]# ./install.shOperations logged to /tmp/install.log.29747Checking for existing installation…zimbra-ldap…NOT FOUNDzimbra-logger…NOT FOUNDzimbra-mta…NOT FOUNDzimbra-dnscache…NOT FOUNDzimbra-snmp…NOT FOUNDzimbra-store…NOT FOUNDzimbra-apache…NOT FOUNDzimbra-spell…NOT FOUNDzimbra-convertd…NOT FOUNDzimbra-memcached…NOT FOUNDzimbra-proxy…NOT FOUNDzimbra-archiving…NOT FOUNDzimbra-core…NOT FOUNDPLEASE READ THIS AGREEMENT CAREFULLY BEFORE USING THE SOFTWARE.ZIMBRA, INC. (“ZIMBRA”) WILL ONLY LICENSE THIS SOFTWARE TO YOU IF YOUFIRST ACCEPT THE TERMS OF THIS AGREEMENT. BY DOWNLOADING OR INSTALLINGTHE SOFTWARE, OR USING THE PRODUCT, YOU ARE CONSENTING TO BE BOUND BYTHIS AGREEMENT. IF YOU DO NOT AGREE TO ALL OF THE TERMS OF THISAGREEMENT, THEN DO NOT DOWNLOAD, INSTALL OR USE THE PRODUCT.License Terms for the Zimbra Collaboration Suite:http://www.zimbra.com/license/zimbra-public-eula-2-5.htmlDo you agree with the terms of the software license agreement? [N] yChecking for prerequisites…FOUND: NPTLFOUND: nc-1.84-24FOUND: sudo-1.8.6p3-19FOUND: libidn-1.18-2FOUND: gmp-4.3.1-7FOUND: libaio-0.3.107-10FOUND: libstdc++-4.4.7-16FOUND: unzip-6.0-2Checking for suggested prerequisites…FOUND: perl-5.10.1FOUND: sysstatFOUND: sqlitePrerequisite check complete.Checking for installable packagesFound zimbra-coreFound zimbra-ldapFound zimbra-loggerFound zimbra-mtaFound zimbra-dnscacheFound zimbra-snmpFound zimbra-storeFound zimbra-apacheFound zimbra-spellFound zimbra-memcachedFound zimbra-proxySelect the packages to installInstall zimbra-ldap [Y] yInstall zimbra-logger [Y] yInstall zimbra-mta [Y] yInstall zimbra-dnscache [Y] yInstall zimbra-snmp [Y] yInstall zimbra-store [Y] yInstall zimbra-apache [Y]Install zimbra-spell [Y] yInstall zimbra-memcached [Y] yInstall zimbra-proxy [Y] yChecking required space for zimbra-coreChecking space for zimbra-storeChecking required packages for zimbra-storezimbra-store package check complete.Installing:zimbra-corezimbra-ldapzimbra-loggerzimbra-mtazimbra-dnscachezimbra-snmpzimbra-storezimbra-apachezimbra-spellzimbra-memcachedzimbra-proxyThe system will be modified. Continue? [N] yRemoving /opt/zimbraRemoving zimbra crontab entry…done.Cleaning up zimbra init scripts…done.Cleaning up /etc/ld.so.conf…done.Cleaning up /etc/prelink.conf…done.Cleaning up /etc/security/limits.conf…done.Finished removing Zimbra Collaboration Server.Installing packageszimbra-core……zimbra-core-8.6.0_GA_1153.RHEL6_64-20141215151155.x86_64.rpm…zimbra-ldap……zimbra-ldap-8.6.0_GA_1153.RHEL6_64-20141215151155.x86_64.rpm…donezimbra-logger……zimbra-logger-8.6.0_GA_1153.RHEL6_64-20141215151155.x86_64.rpm…donezimbra-mta……zimbra-mta-8.6.0_GA_1153.RHEL6_64-20141215151155.x86_64.rpm…donezimbra-dnscache……zimbra-dnscache-8.6.0_GA_1153.RHEL6_64-20141215151155.x86_64.rpm…donezimbra-snmp……zimbra-snmp-8.6.0_GA_1153.RHEL6_64-20141215151155.x86_64.rpm…donezimbra-store……zimbra-store-8.6.0_GA_1153.RHEL6_64-20141215151155.x86_64.rpm…donezimbra-apache……zimbra-apache-8.6.0_GA_1153.RHEL6_64-20141215151155.x86_64.rpm…donezimbra-spell……zimbra-spell-8.6.0_GA_1153.RHEL6_64-20141215151155.x86_64.rpm…donezimbra-memcached……zimbra-memcached-8.6.0_GA_1153.RHEL6_64-20141215151155.x86_64.rpm…donezimbra-proxy……zimbra-proxy-8.6.0_GA_1153.RHEL6_64-20141215151155.x86_64.rpm…doneOperations logged to /tmp/zmsetup06292016-184521.logInstalling LDAP configuration database…done.Setting defaults… MX: mail.user-mail.net (54.227.254.216)MX: mail.user-mail.net (54.225.221.198)Interface: 10.90.10.190Interface: 127.0.0.1Interface: ::154.225.221.19854.227.254.21654.227.254.21654.225.221.19854.225.221.19854.227.254.216DNS ERROR - none of the MX records for mail.tzh.comresolve to this hostChange domain name? [Yes] ndone.Checking for port conflictsMain menu1) Common Configuration:2) zimbra-ldap: Enabled3) zimbra-logger: Enabled4) zimbra-mta: Enabled5) zimbra-dnscache: Enabled6) zimbra-snmp: Enabled7) zimbra-store: Enabled+Create Admin User: yes+Admin user to create: admin@mail.tzh.com*** +Admin Password UNSET+Anti-virus quarantine user: virus-quarantine.iv8_lcko@mail.tzh.com+Enable automated spam training: yes+Spam training user: spam.f8aglxrf@mail.tzh.com+Non-spam(Ham) training user: ham.ugur2xpeby@mail.tzh.com+SMTP host: mail.tzh.com+Web server HTTP port: 8080+Web server HTTPS port: 8443+Web server mode: https+IMAP server port: 7143+IMAP server SSL port: 7993+POP server port: 7110+POP server SSL port: 7995+Use spell check server: yes+Spell server URL: http://mail.tzh.com:7780/aspell.php+Enable version update checks: TRUE+Enable version update notifications: TRUE+Version update notification email: admin@mail.tzh.com+Version update source email: admin@mail.tzh.com+Install mailstore (service webapp): yes+Install UI (zimbra,zimbraAdmin webapps): yes8) zimbra-spell: Enabled9) zimbra-proxy: Enabled10) Default Class of Service Configuration:s) Save config to filex) Expand menuq) QuitAddress unconfigured () items (? - help) 7Store configuration1) Status: Enabled2) Create Admin User: yes3) Admin user to create: admin@mail.tzh.com 4) Admin Password UNSET5) Anti-virus quarantine user: virus-quarantine.iv8_lcko@mail.tzh.com6) Enable automated spam training: yes7) Spam training user: spam.f8aglxrf@mail.tzh.com8) Non-spam(Ham) training user: ham.ugur2xpeby@mail.tzh.com9) SMTP host: mail.tzh.com10) Web server HTTP port: 808011) Web server HTTPS port: 844312) Web server mode: https13) IMAP server port: 714314) IMAP server SSL port: 799315) POP server port: 711016) POP server SSL port: 799517) Use spell check server: yes18) Spell server URL: http://mail.tzh.com:7780/aspell.php19) Enable version update checks: TRUE20) Enable version update notifications: TRUE21) Version update notification email: admin@mail.tzh.com22) Version update source email: admin@mail.tzh.com23) Install mailstore (service webapp): yes24) Install UI (zimbra,zimbraAdmin webapps): yesSelect, or ‘r’ for previous menu [r] 4Password for admin@mail.tzh.com (min 6 characters): [1mrCHrfp] 558842Store configuration1) Status: Enabled2) Create Admin User: yes3) Admin user to create: admin@mail.tzh.com4) Admin Password set5) Anti-virus quarantine user: virus-quarantine.iv8_lcko@mail.tzh.com6) Enable automated spam training: yes7) Spam training user: spam.f8aglxrf@mail.tzh.com8) Non-spam(Ham) training user: ham.ugur2xpeby@mail.tzh.com9) SMTP host: mail.tzh.com10) Web server HTTP port: 808011) Web server HTTPS port: 844312) Web server mode: https13) IMAP server port: 714314) IMAP server SSL port: 799315) POP server port: 711016) POP server SSL port: 799517) Use spell check server: yes18) Spell server URL: http://mail.tzh.com:7780/aspell.php19) Enable version update checks: TRUE20) Enable version update notifications: TRUE21) Version update notification email: admin@mail.tzh.com22) Version update source email: admin@mail.tzh.com23) Install mailstore (service webapp): yes24) Install UI (zimbra,zimbraAdmin webapps): yesSelect, or ‘r’ for previous menu [r] rMain menu1) Common Configuration:2) zimbra-ldap: Enabled3) zimbra-logger: Disabled4) zimbra-mta: Enabled5) zimbra-dnscache: Enabled6) zimbra-snmp: Enabled7) zimbra-store: Enabled8) zimbra-spell: Enabled9) zimbra-proxy: Enabled10) Default Class of Service Configuration:s) Save config to filex) Expand menuq) QuitSelect from menu, or press ‘a’ to apply config (? - help) aSave configuration data to a file? [Yes] ySave config in file: [/opt/zimbra/config.39633]Saving config in /opt/zimbra/config.39633…done.The system will be modified - continue? [No] yOperations logged to /tmp/zmsetup06292016-184521.logSetting local config values…done.Initializing core config…Setting up CA…done.Deploying CA to /opt/zimbra/conf/ca …done.Creating SSL zimbra-store certificate…done.Creating new zimbra-ldap SSL certificate…done.Creating new zimbra-mta SSL certificate…done.Creating new zimbra-proxy SSL certificate…done.Installing mailboxd SSL certificates…done.Installing MTA SSL certificates…done.Installing LDAP SSL certificate…done.Installing Proxy SSL certificate…done.Initializing ldap…done.Setting replication password…done.Setting Postfix password…done.Setting amavis password…done.Setting nginx password…done.Setting BES searcher password…done.Creating server entry for mail.tzh.com…done.Setting Zimbra IP Mode…done.Saving CA in ldap …done.Saving SSL Certificate in ldap …done.Setting spell check URL…done.Setting service ports on mail.tzh.com…done.Setting zimbraFeatureTasksEnabled=TRUE…done.Setting zimbraFeatureBriefcasesEnabled=TRUE…done.Setting Master DNS IP address(es)…done.Setting DNS cache tcp lookup preference…done.Setting DNS cache udp lookup preference…done.Setting DNS tcp upstream preference…done.Setting TimeZone Preference…done.Initializing mta config…done.Setting services on mail.tzh.com…done.Adding mail.tzh.com to zimbraMailHostPool in default COS…done.Creating domain mail.tzh.com…done.Setting default domain name…done.Creating domain mail.tzh.com…already exists.Creating admin account admin@mail.tzh.com…done.Creating root alias…done.Creating postmaster alias…done.Creating user spam.f8aglxrf@mail.tzh.com…done.Creating user ham.ugur2xpeby@mail.tzh.com…done.Creating user virus-quarantine.iv8_lcko@mail.tzh.com…done.Setting spam training and Anti-virus quarantine accounts…done.Initializing store sql database…done.Setting zimbraSmtpHostname for mail.tzh.com…done.Configuring SNMP…done.Setting up syslog.conf…done.Starting servers…Installing common zimlets…com_zimbra_ymemoticons…done.com_zimbra_clientuploader…done.com_zimbra_webex…done.com_zimbra_proxy_config…done.com_zimbra_srchhighlighter…done.com_zimbra_bulkprovision…done.com_zimbra_viewmail…done.com_zimbra_date…done.com_zimbra_attachcontacts…done.com_zimbra_mailarchive…done.com_zimbra_cert_manager…done.com_zimbra_url…done.com_zimbra_adminversioncheck…done.com_zimbra_attachmail…done.com_zimbra_tooltip…done.com_zimbra_email…done.com_zimbra_phone…done.Finished installing common zimlets.Restarting mailboxd…done.Creating galsync account for default domain…done.You have the option of notifying Zimbra of your installation.This helps us to track the uptake of the Zimbra Collaboration Server.The only information that will be transmitted is:The VERSION of zcs installed (8.6.0_GA_1153_RHEL6_64)The ADMIN EMAIL ADDRESS created (admin@mail.tzh.com)Notify Zimbra of your installation? [Yes] yesNotifying Zimbra of installation via http://www.zimbra.com/cgi-bin/notify.cgi?VER=8.6.0_GA_1153_RHEL6_64&amp;MAIL=admin@mail.tzh.comNotification completeSetting up zimbra crontab…done.Moving /tmp/zmsetup06292016-184521.log to /opt/zimbra/logConfiguration complete - press return to exit3.5、重启zimbra点击显/隐内容[root@tzh zcs-8.6.0_GA_1153.RHEL6_64.20141215151155]# /etc/init.d/zimbra restartHost mail.tzh.comStopping vmware-ha…skipped./opt/zimbra/bin/zmhactl missing or not executable.Stopping zmconfigd…Done.Stopping zimlet webapp…Done.Stopping zimbraAdmin webapp…Done.Stopping zimbra webapp…Done.Stopping service webapp…Done.Stopping stats…Done.Stopping mta…Done.Stopping spell…Done.Stopping snmp…Done.Stopping cbpolicyd…Done.Stopping archiving…Done.Stopping opendkim…Done.Stopping amavis…Done.Stopping antivirus…Done.Stopping antispam…Done.Stopping proxy…Done.Stopping memcached…Done.Stopping mailbox…Done.Stopping logger…Done.Stopping dnscache…Done.Stopping ldap…Done.Host mail.tzh.comStarting ldap…Done.略~~~4、服务发件测试4.1 登陆测试创建一个账户，进行邮件发送测试账户创建登陆网页客户端进行邮件发送测试注：上图时间为周三（6月29）下午17：29是因为我在本地搭建的虚拟机，时间没有同步因为域名问题，以及DNS在内网的虚拟机上，收取邮件是无法收取的，需要做公网解析，所以暂不进行邮件收取测试]]></content>
      <categories>
        <category>Linux</category>
        <category>zimbra</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>zimbra</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 系统安装confluence]]></title>
    <url>%2F2017%2F06%2F20%2FLinux%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85confluence%2F</url>
    <content type="text"><![CDATA[一、系统初始化OS：Centos 6.9注意：系统需要安装图形桌面，破解需要用到，如果是最小化安装则需要安装图形化组件部署前设置：service iptables stop #关闭防火墙（如果是内网，可以直接关闭，如果不是则需要设置相关规则） chkconfig iptables off #关闭开机自启动 setenforce 0 #临时关闭selinux 二、安装数据库：yum install -y mysql-server mysql mysql-devel service mysqld start #启动数据库 chkconfig mysqld on #设置开机自启动 mysqladmin -u root password &apos;需要设置的密码&apos; #设置数据库密码 2.1 登录数据库，创建conference需要的数据库：mysql -uroot -p create database confluence character set UTF8; grant all on confluence.* to confluence@&quot;%&quot; identified by &quot;confluence&quot;; grant all on confluence.* to confluence@&quot;localhost&quot; identified by &quot;confluence&quot;; FLUSH PRIVILEGES; quit #退出 2.2 修复中文乱码service mysqld stop #关闭mysql数据库 vim /etc/my.cnf 在[mysqld]下面加上character-set-server =utf8 #解决中文显示的乱码问题 service mysqld start #启动MySQL服务 三、安装java环境：3.1 创建安装目录mkdir /usr/java 将java程序复制到/usr/java/下 cp jre-7u67-linux-x64.rpm /usr/java 3.2 安装rpm -ivh jre-7u67-linux-x64.rpm java版本：java version &quot;1.7.0_151&quot; 3.3 环境变量配置：vim /etc/profile #在最后添加以下几行 export JAVA_HOME=/usr/java/jre1.7.0_67 export CLASSPATH=.:$JAVA_HOME/jre/lib/rt.jar:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar export PATH=$PATH:$JAVA_HOME/bin 保存退出后source一下环境变量 source /etc/profile 四、安装conference程序chmod +x atlassian-confluence-5.4.4-x64.bin #给文件执行权限 ./atlassian-confluence-5.4.4-x64.bin #执行安装 默认回车即可 打开浏览器输入：http://IP地址：8090进行访问 记住页面显示的server ID号 4.1 进行破解关闭confluence服务：service confluence stop 将confluence5.1-crack.zip 解压 将/opt/atlassian/confluence/confluence/WEB-INF/lib/atlassian-extras-2.4.jar 复制出来。替换confluence5.1-crack 中的atlassian-extras-2.4.jar chmod +x keygen.sh ./keygen.sh #执行破解文件 【1】输入Name，及之前记录下来的Server ID，按.patch! 选择需要破解的atlassian-extras-2.4.jar 【2】 按.gen!得到key 【3】把破解好的包，复制回去 复制破解后的atlassian-extras-2.4.jar 到 “/opt/atlassian/confluence/confluence/WEB-INF/lib/”cp atlassian-extras-2.4.jar /opt/atlassian/confluence/confluence/WEB-INF/lib/ #按“y”覆盖原文件 复制mysql-connector-java-5.1.32-bin.jar 到“/opt/atlassian/confluence/confluence/WEB-INF/lib/”cp mysql-connector-java-5.1.32-bin.jar /opt/atlassian/confluence/confluence/WEB-INF/lib/ 复制 Confluence-5.4.4-language-pack-zh_CN.jar 到“ /opt/atlassian/confluence/confluence/WEB-INF/lib/” #就可以显示中文了cp Confluence-5.4.4-language-pack-zh_CN.jar /opt/atlassian/confluence/confluence/WEB-INF/lib/ 4.2 启动confluence服务进行配置输入得到的key，按照下面的图完成安装4.3 破解所需软件清单：jre-7u67-linux-x64.rpm atlassian-confluence-5.4.4-x64.bin mysql-connector-java-5.1.32-bin.jar confluence5.1-crack.zip Confluence-5.4.4-language-pack-zh_CN.jar 软件下载地址：http://pan.baidu.com/s/1i3D5rU1参考:http://www.cnblogs.com/wspblog/p/4750128.html]]></content>
      <categories>
        <category>Linux</category>
        <category>confluence</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[企业内网漏洞快速应急、巡航扫描系统]]></title>
    <url>%2F2017%2F06%2F20%2F%E4%BC%81%E4%B8%9A%E5%86%85%E7%BD%91%E6%BC%8F%E6%B4%9E%E5%BF%AB%E9%80%9F%E5%BA%94%E6%80%A5%E3%80%81%E5%B7%A1%E8%88%AA%E6%89%AB%E6%8F%8F%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[一、巡风系统简介巡风是一款适用于企业内网的漏洞快速应急、巡航扫描系统，通过搜索功能可清晰的了解内部网络资产分布情况，并且可指定漏洞插件对搜索结果进行快速漏洞检测并输出结果报表。其主体分为两部分：网络资产识别引擎，漏洞检测引擎。网络资产识别引擎会通过用户配置的IP范围定期自动的进行端口探测（支持调用MASSCAN），并进行指纹识别，识别内容包括：服务类型、组件容器、脚本语言、CMS。漏洞检测引擎会根据用户指定的任务规则进行定期或者一次性的漏洞检测，其支持2种插件类型、标示符与脚本，均可通过web控制台进行添加。1.1 文件结构介绍│ Config.py # 配置文件 │ README.md # 说明文档 │ Run.bat # Windows启动服务 │ Run.py # webserver │ Run.sh # Linux启动服务，重新启动前需把进程先结束掉 │ ├─aider │ Aider.py # 辅助验证脚本 │ ├─db # 初始数据库结构 │ ├─masscan # 内置编译好的Masscan程序，若无法使用请自行编译安装 │ ├─nascan │ │ NAScan.py # 网络资产信息抓取引擎 │ │ │ ├─lib │ │ common.py 其他方法 │ │ icmp.py # ICMP发送类 │ │ log.py # 日志输出 │ │ mongo.py # 数据库连接 │ │ scan.py # 扫描与识别 │ │ start.py # 线程控制 │ │ │ └─plugin │ masscan.py # 调用Masscan脚本 │ ├─views │ │ View.py # web请求处理 │ │ │ ├─lib │ │ Conn.py # 数据库公共类 │ │ CreateExcel.py # 表格处理 │ │ Login.py # 权限验证 │ │ QueryLogic.py # 查询语句解析 │ │ │ ├─static #静态资源目录 │ │ │ └─templates #模板文件目录 │ └─vulscan │ VulScan.py # 漏洞检测引擎 │ └─vuldb # 漏洞库目录 二、安装指南2.1 第一部分环境需求python2.7 mongodb3.0升级系统，安装依赖包使用yum -y update命令进行系统更新，如果不想升级系统版本，可以忽略这一步（系统更新快慢根据更新包和网速决定）安装扩展包yum install git gcc libffi-devel python-devel openssl-devel libpcap-devel -y 2.2 更新python2.2.1 下载一个2.7的python可以使用下面两个URL进行下载wget http://down.hx99.net/Other/Python-2.7.6.tar.xz wget http://down.hx99.net/Other/Python-2.7.6.tar.xz 2.2.2 解压文件cd Python-2.7.6 #进入安装文件目录 ./configure #进行安装，默认安装在/usr/local目录下 2.2.3 make &amp;&amp; make altinstall #编译安装2.3 解决yum命令不支持python2.7的问题2.3.1 将老的python2.6进行备份mv /usr/bin/python /usr/bin/python2.6.6 2.3.2 建立新的python链接ln -s /usr/local/bin/python2.7 /usr/bin/python 2.3.3 修改 /usr/bin/yum文件将第一行的 #!/usr/bin/python 改为 #!/usr/bin/python2.6.62.4 安装pip，建议使用豆瓣的pip源，否则可能会因为超时导致报错（自己可以选择合适pip源）2.4.1 下载pipwget https://sec.ly.com/mirror/get-pip.py --no-check-certificate 2.4.2 安装python get-pip.py 2.4.3 更新pip到最新版本pip install -U pip 2.4.4 安装依赖程序pip install pymongo Flask xlwt paramiko 2.5 安装Masscan扫描软件2.5.1 下载软件git clone https://github.com/robertdavidgraham/masscan 2.5.2 安装masscanchmod +x /opt/masscan/bin/masscan #给masscan脚本执行权限2.5.3检测是否安装成功三、mongo配置3.1 克隆程序及mongoDB数据库软件git clone https://code.aliyun.com/ysrc/xunfeng.git wget https://sec.ly.com/mirror/mongodb-linux-x86_64-3.4.0.tgz 3.1.1 解压文件tar -zxvf mongodb-linux-x86_64-3.4.0.tgz mv mongodb-linux-x86_64-3.4.0 mongodb #将mongodb-linux-x86_64-3.4.0改名为mongondb3.1.2 创建数据库目录mkdir /opt/mongodb/DBData 后台启动mongodb nohup /opt/mongodb/bin/mongod --port 65521 --dbpath=/opt/mongodb/DBData &amp; 如果启动成功，就可以看到65521处于监听状态3.1.3 导入巡风的初始数据库3.1.4 增加数据库连接认证/opt/mongodb/bin/mongo --port 65521 db.createUser({user:&apos;scan&apos;,pwd:&apos;你的密码&apos;,roles:[{role:&apos;dbOwner&apos;,db:&apos;xunfeng&apos;}]}) exit 四、修改配置、启动4.1 修改配置文件vim /opt/xunfeng/Config.py vim /opt/xunfeng/Run.sh4.2 启动程序批量启动 sh /opt/xunfeng/Run.sh 如果没有启动成功，检查80、8088和65521端口是否存在打开web页面（默认端口80） #默认账号密码：admin/xunfeng321http://IP4.2.1 在首页-&gt;配置-&gt;启用填上完整路径4.2.2 在网络资产探测列表位置填上探测范围4.2.3 几分钟后会在首页位置显示探测的数据4.2.4 使用巡风系统进行弱密码探测点击“搜索”项添加目标IP和端口使用封号隔开新增任务保存任务点击“任务”项，找到弱口令2打开后即可看到扫描结果]]></content>
      <categories>
        <category>安全</category>
      </categories>
      <tags>
        <tag>安全</tag>
      </tags>
  </entry>
</search>
