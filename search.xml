<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[企业内网漏洞快速应急、巡航扫描系统]]></title>
    <url>%2F2019%2F07%2F20%2F%E4%BC%81%E4%B8%9A%E5%86%85%E7%BD%91%E6%BC%8F%E6%B4%9E%E5%BF%AB%E9%80%9F%E5%BA%94%E6%80%A5%E3%80%81%E5%B7%A1%E8%88%AA%E6%89%AB%E6%8F%8F%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[]]></content>
  </entry>
  <entry>
    <title><![CDATA[什么是wifi探针??]]></title>
    <url>%2F2019%2F07%2F17%2F%E4%BB%80%E4%B9%88%E6%98%AFwifi%E6%8E%A2%E9%92%88%2F</url>
    <content type="text"><![CDATA[1、什么是WIFI探针？？WIFI 探针是一种能够主动识别 Android 和 IOS 设备，感知用户行为轨迹的精准数据收集前端，基于 WIFI探测技术、移动互联网和云计算等先进技术自动识别探针附近的智能移动终端。、当一个设备给另外一个设备通过无线传输技术发送信息时，周围的其他同类设备都是能够收到无线信息，WiFi探针技术基于此原理。具体说，当WiFi设备在WiFi探针的侦听范围内，WiFi设备（无论是终端、路由器或者其他WiFi设备）发送任何一帧（Frame）时，不管是发给谁，探针都能截获，并分析出此帧MAC层与物理层的一些信息，比如发送与接收设备的MAC地址、帧类型、信号强度等。WiFi探针不需要与周围的设备有任何交互，其本身不发出任何WiFi信号，即实现了无感知获取MAC信息。2、WIFI 探针原理wifi探针实际上指的是probe帧。我们一般接入无线网络的时候，首先要选择对应的无线网路，即根据无线网络的名字进行选择（SSID）。那么知道这个名字有两种方式，主动扫描和被动扫描，其中probe帧即是用在主动扫描这种技术中。具体原理：节点会主动的发送probe request请求帧给AP（路由），AP然后反馈响应probe response，该probe response帧和Beacon的内容几乎是一致的，之后利用该帧中的一些信息，节点才会继续发起接入过程。所以狭义上而言，探针技术是一个帧，也是一种节点收集AP信息的方法。AP实际上也可以用来收集节点的信息，该信息并不是指节点（即用户的终端，比如手机）内部的一些信息，而是一些移动的痕迹。3、WIFI探针特点●用户无需连接，无需安装APP；●手机已经连接WiFi也可以探测；●自动实时探测区域内的WiFi终端标识MAC地址；●自动记录每个WiFi终端进入区域时间log_TIme、场强SNR；●兼容iOS苹果和Android系统，开启WiFi的智能手机、笔记本电脑、Pad等移动设备都能探测。4、WIFI 探针技术所使用的网络协议WIFI探针所采用的网络协议是IEEE802.11协议集，此协议集包含许多子协议。其中按照时间顺序发展，主要有：（1）802.11a（2）802.11b（3）802.11g（4）802.11n在网络通信中，数据被封装成了帧（通信中的一个数据块）。帧在数据链路层传输的时候是有固定格式的，不是随便的封装和打包就可以传输。大小有限制，最小46字节，最大1500字节。]]></content>
      <categories>
        <category>物联网</category>
      </categories>
      <tags>
        <tag>物联网</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker 仓库harbor搭建]]></title>
    <url>%2F2019%2F07%2F12%2Fdocker-%E4%BB%93%E5%BA%93harbor%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[一、初始化在正式安装harbor之前，需要对OS环境进行初始化1.1 升级OS内核，具体内核升级步骤可以自己了解下1.2 安装yum源因为需要安装相关的以来软件，所以需要安装yum源，安装前先将原先的yum备份[root@harbor yum.repos.d]# mv CentOS-Base.repo CentOS-Base.repo.bak [root@harbor yum.repos.d]# vim CentOS-Base.repo [base] name=CentOS-$releasever – Base – 163.com #mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=os baseurl=http://mirrors.163.com/centos/$releasever/os/$basearch/ gpgcheck=1 gpgkey=http://mirrors.163.com/centos/RPM-GPG-KEY-CentOS-7 #released updates [updates] name=CentOS-$releasever – Updates – 163.com #mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=updates baseurl=http://mirrors.163.com/centos/$releasever/updates/$basearch/ gpgcheck=1 gpgkey=http://mirrors.163.com/centos/RPM-GPG-KEY-CentOS-7 #additional packages that may be useful [extras] name=CentOS-$releasever – Extras – 163.com #mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=extras baseurl=http://mirrors.163.com/centos/$releasever/extras/$basearch/ gpgcheck=1 gpgkey=http://mirrors.163.com/centos/RPM-GPG-KEY-CentOS-7 #additional packages that extend functionality of existing packages [centosplus] name=CentOS-$releasever – Plus – 163.com baseurl=http://mirrors.163.com/centos/$releasever/centosplus/$basearch/ gpgcheck=1 enabled=0 gpgkey=http://mirrors.163.com/centos/RPM-GPG-KEY-CentOS-7 1.3 安装阿里云epel源wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo 1.4 安装dockeryum -y install docker 启动docker并查看docker版本1.5 安装docker-composeyum -y install certbot libevent-devel gcc libffi-devel python-devel openssl-devel python2-pip 使用pip的方式进行安装，命令如下pip install -U docker-compose 查看安装的版本docker-compose version 二、下载安装harbor，选择自己需要的版本官网地址：http://harbor.orientsoft.cn/2.1 修改Harbor配置文件，修改服务地址[root@harbor ~]# ls anaconda-ks.cfg harbor-offline-installer-v1.4.0.tgz [root@harbor ~]# tar xf harbor-offline-installer-v1.4.0.tgz [root@harbor ~]# ls anaconda-ks.cfg harbor harbor-offline-installer-v1.4.0.tgz [root@harbor ~]# mv harbor /usr/local/ [root@harbor ~]# vim harbor.cfg 修改hostname为主机的IP（没有域名的情况下）2.2 修改harbor的默认admin密码（默认密码为Harbor12345）2.3 安装harbor步骤一会下载相关的docker镜像，这个过程根据各自的网络情况不同花费的时间也不同，相关的docker镜像如下：docker images 2.4 查看容器，可以看到没有Notary与Clair相关服务；也可使用”docker ps”；“docker-compose ps”需要在”docker-compose.yml”文件所在目录执行相关操作[root@harbor harbor]# docker-compose ps 三、安装后配置3.1 访问harbor ui （注意服务器的防火墙和selinux，可以关闭或者放行相关端口）admin/默认密码harbor安装完成3.2 harbor 使用docker login报错的问题从harbor安装文档中可以看到https://github.com/vmware/harbor/blob/master/docs/installation_guide.md在Harbor主机和客户机都对这个文件进行设置/etc/docker/daemon.json：{ &quot;insecure-registries&quot;:[&quot;192.168.33.10&quot;] } 四、简单使用4.1 向harbor上推拉镜象给docker.io/tomcat这个镜像打上tag[root@harbor ~]# docker tag docker.io/tomcat 172.31.8.25/library/tomcat2 4.2 推送至harbor[root@harbor ~]# docker push 172.31.8.25/library/tomcat2]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo博客使用Next主题建立标签云]]></title>
    <url>%2F2019%2F07%2F10%2FHexo%E5%8D%9A%E5%AE%A2%E4%BD%BF%E7%94%A8Next%E4%B8%BB%E9%A2%98%E5%BB%BA%E7%AB%8B%E6%A0%87%E7%AD%BE%E4%BA%91%2F</url>
    <content type="text"><![CDATA[使用hexo-tag-cloud插件:github地址1、安装插件:进入到hexo的根目录，在在 package.json 中添加依赖: “hexo-tag-cloud”: “2.0.*” 操作如下：npm install hexo-tag-cloud@^2.0.* --save Git clone 下载使用命令行安装插件包的过程中可能会出现问题，安装失败，安装不完全。可以直接克隆插件到博客的插件文件夹blog/node_modules里。或者克隆到桌面然后复制到博客的插件目录blog\node_modules文件夹里git clone https://github.com/MikeCoder/hexo-tag-cloud 2、配置插件插件的配置需要对应的环境，可以在主题文件夹里找一下，有没有对应的渲染文件，然后根据渲染文件的类型，选择对应的插件配置方法。我这里使用的next主题，所以使用的是swig 配置方式（不仅next，还有其他主题的配置文件也是.swig格式）在主题文件夹找到文件 theme/next/layout/_macro/sidebar.swig, 然后写入如下代码跳转官网复制代码添加到合适的位置即可博客根目录找到 _config.yml配置文件,在最后添加以下的配置项# hexo-tag-cloud tag_cloud: textFont: Trebuchet MS, Helvetica textColor: &apos;#333&apos; textHeight: 25 outlineColor: &apos;#E2E1D1&apos; maxSpeed: 0.1 定义标签云的字体和颜色textColor: ‘#333’ 字体颜色 textHeight: 25 字体高度，根据部署的效果调整 maxSpeed: 0.1 文字滚动速度，根据自己喜好调整 重启博客，部署到线上hexo clean 清除缓存 hexo g 生成博客 hexo s 本地预览 hexo d 部署到线上 一定要注意清除缓存，不然的话容易出现功能效果不展示的问题，清除缓存即执行:hexo clean 实现效果]]></content>
      <categories>
        <category>hexo博客建站</category>
      </categories>
      <tags>
        <tag>HEXO博客建站</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux常用网络工具:fping主机扫描]]></title>
    <url>%2F2019%2F07%2F10%2FLinux%E5%B8%B8%E7%94%A8%E7%BD%91%E7%BB%9C%E5%B7%A5%E5%85%B7-fping%E4%B8%BB%E6%9C%BA%E6%89%AB%E6%8F%8F%2F</url>
    <content type="text"><![CDATA[fping 介绍Linux下有很多强大网络扫描工具，网络扫描工具可以分为：主机扫描、主机服务扫描、路由扫描等。fping是一个主机扫描工具，相比于ping工具它可以批量扫描主机。fping完全不同于ping，因为您可以在命令行上定义任意数量的主机，或者指定包含要ping的IP地址或主机列表的文件。例如，使用fping，我们可以指定完整的网络范围（ 192.168.0.1/24 ）。它会向主机发送Fping请求，并以循环方式移动到另一个目标主机。 与ping不同，Fping基本上用于编写脚本。访问fping 官方网站：http://fping.org下载最新版安装程序一、编译及安装安装可以使用yum安装或者源码安装yum 安装命令:yum install fping 非root用户可使用sudo或者切换到root用户安装 sudo yum install fping 源码安装[root@node1 ~]# wget http://fping.org/dist/fping-4.2.tar.gz [root@node1 ~]# ll fping-4.2.tar.gz -rw-r--r--. 1 root root 171409 2月 20 05:05 fping-4.2.tar.gz [root@node1 ~]# tar xf fping-4.2.tar.gz &amp;&amp; cd fping-4.2 [root@node1 fping-4.2]# ./configure &amp;&amp; make &amp;&amp; make install 查看安装版本fping -v 二、使用示例2.1 ping多个主机[root@node1 fping-4.2]# fping 172.31.8.13 172.31.8.107 172.31.8.75 172.31.8.3 172.31.8.13 is alive ---主机活动 172.31.8.107 is alive 172.31.8.75 is alive 172.31.8.75 is unreachable --- 主机不可用 [root@node1 fping-4.2]# 2.2 ping IP地址范围以下命令将接收ping的IP范围并输出以下内容，我们将响应请求发送到该范围内的IP并获得我们想要信息。结束后还显示累积结果[root@node1 fping-4.2]# fping -s -g 172.31.8.1 172.31.8.10 172.31.8.1 is alive 172.31.8.3 is alive 172.31.8.5 is alive 172.31.8.8 is alive ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.2 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.2 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.2 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.2 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.4 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.4 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.4 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.4 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.6 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.6 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.6 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.6 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.7 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.7 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.7 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.7 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.9 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.9 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.9 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.9 172.31.8.2 is unreachable 172.31.8.4 is unreachable 172.31.8.6 is unreachable 172.31.8.7 is unreachable 172.31.8.9 is unreachable 172.31.8.10 is unreachable 10 targets 4 alive 6 unreachable 0 unknown addresses 6 timeouts (waiting for response) 28 ICMP Echos sent 4 ICMP Echo Replies received 20 other ICMP received 0.04 ms (min round trip time) 0.73 ms (avg round trip time) 1.15 ms (max round trip time) 4.164 sec (elapsed real time) [root@node1 fping-4.2]# 2.3 ping整个IP段，并重复一次2.4 从文件中读取IP信息，执行ping三、查看帮助信息[root@node1 fping-4.2]# fping -help Usage: fping [options] [targets...] 用法：fping [选项] [ping的目标] -a show targets that are alive 显示可ping通的目标 -A show targets by address 将目标以ip地址的形式显示 -b n amount of ping data to send, in bytes (default 56) ping 数据包的大小。（默认为56） -B f set exponential backoff factor to f 设置指数反馈因子到f -c n count of pings to send to each target (default 1) ping每个目标的次数 (默认为1) -C n same as -c, report results in verbose format 同-c, 返回的结果为冗长格式 -e show elapsed time on return packets 显示返回数据包所费时间 -f file read list of targets from a file ( - means stdin) (only if no -g specified) 从文件获取目标列表( - 表示从标准输入)(不能与 -g 同时使用) -g generate target list (only if no -f specified) 生成目标列表(不能与 -f 同时使用) (specify the start and end IP in the target list, or supply a IP netmask) (ex. fping -g 192.168.1.0 192.168.1.255 or fping -g 192.168.1.0/24) (可指定目标的开始和结束IP， 或者提供ip的子网掩码) (例：fping -g 192.168.1.0 192.168.1.255 或 fping -g 192.168.1.0/24) -H n Set the IP TTL value (Time To Live hops) 设置ip的TTL值 (生存时间) -i n interval between sending ping packets (in millisec) (default 25) ping包之间的间隔(单位：毫秒)(默认25) -l loop sending pings forever 循环发送ping -m ping multiple interfaces on target host ping目标主机的多个网口 -n show targets by name (-d is equivalent) 将目标以主机名或域名显示(等价于 -d ) -p n interval between ping packets to one target (in millisec) 对同一个目标的ping包间隔(毫秒) (in looping and counting modes, default 1000) (在循环和统计模式中，默认为1000) -q quiet (don&apos;t show per-target/per-ping results) 安静模式(不显示每个目标或每个ping的结果) -Q n same as -q, but show summary every n seconds 同-q, 但是每n秒显示信息概要 -r n number of retries (default 3) 当ping失败时，最大重试次数(默认为3次) -s print final stats 打印最后的统计数据 -I if bind to a particular interface 绑定到特定的网卡 -S addr set source address 设置源ip地址 -t n individual target initial timeout (in millisec) (default 500) 单个目标的超时时间(毫秒)(默认500) -T n ignored (for compatibility with fping 2.4) 请忽略(为兼容fping 2.4) -u show targets that are unreachable 显示不可到达的目标 -O n set the type of service (tos) flag on the ICMP packets 在icmp包中设置tos（服务类型） -v show version 显示版本号 targets list of targets to check (if no -f specified) 需要ping的目标列表(不能和 -f 同时使用) -h show this page 显示本帮助页]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat 入门(安装配置篇)]]></title>
    <url>%2F2019%2F07%2F09%2Ftomcat-%E5%85%A5%E9%97%A8(%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%E7%AF%87)%2F</url>
    <content type="text"><![CDATA[tomcat简介Tomcat 服务器是一个免费的开放源代码的Web 应用服务器，Tomcat是Apache 软件基金会（Apache Software Foundation）的Jakarta 项目中的一个核心项目，它早期的名称为catalina，后来由Apache、Sun 和其他一些公司及个人共同开发而成，并更名为Tomcat。Tomcat 是一个小型的轻量级应用服务器，在中小型系统和并发访问用户不是很多的场合下被普遍使用，是开发和调试JSP 程序的首选，因为Tomcat 技术先进、性能稳定，成为目前比较流行的Web 应用服务器。Tomcat是应用（java）服务器，它只是一个servlet容器，是Apache的扩展，但它是独立运行的。目前最新的版本为Tomcat 8.0.24 Released。Tomcat不是一个完整意义上的Jave EE服务器，它甚至都没有提供对哪怕是一个主要Java EE API的实现；但由于遵守apache开源协议，tomcat却又为众多的java应用程序服务器嵌入自己的产品中构建商业的java应用程序服务器，如JBoss和JOnAS。尽管Tomcat对Jave EE API的实现并不完整，然而很企业也在渐渐抛弃使用传统的Java EE技术（如EJB）转而采用一些开源组件来构建复杂的应用。这些开源组件如Structs、Spring和Hibernate，而Tomcat能够对这些组件实现完美的支持。详细请参考-运维生存时间1、安装环境:Centos 7 tomcat版本: apache-tomcat-8.5.42.tar java版本: java8官方网站下载tomcat82、安装上传至Linux 服务器创建tomcat安装目录mkdir /tomcat 解压tomcat、jdk[root@node1 tomcat]# ll 总用量 178712 -rw-r--r--. 1 root root 9711748 7月 9 10:55 apache-tomcat-8.5.42.tar.gz -rw-r--r--. 1 root root 173281904 7月 9 10:55 jdk-8u51-linux-x64.tar.gz [root@node1 tomcat]# tar xf jdk-8u51-linux-x64.tar.gz [root@node1 tomcat]# tar xf apache-tomcat-8.5.42.tar.gz [root@node1 tomcat]# 3、启动脚本配置#!/bin/bash source /etc/sysconfig/i18n export JAVA_HOME=/tomcat/jdk1.8.0_51 export PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$PATH --配置启动java export CLASSPATH=.$CLASSPATH:$JAVA_HOME/lib:$JAVA_HOME/jre/lib:$JAVA_HOME/lib/tools.jar export TOMCAT_HOME=/tomcat/apache-tomcat-8.5.42/ export PATH=$PATH:$TOMCAT_HOME/bin #export JAVA_OPTS=&quot;$JAVA_OPTS -Xms10000m -Xmx10000m -Xmn4000m -XX:PermSize=256m -XX:MaxPermSize=512m&quot; -配置程序内存 PROG=&quot;tomcat&quot; IP_ADDR=$(/sbin/ifconfig eth0 | grep &quot;inet addr&quot; | awk &apos;{print $2}&apos; | awk -F &quot;:&quot; &apos;{print $2}&apos;) tomcat_start() ---启动tomcat { rm -fr /tomcat/apache-tomcat-8.5.42/work/* ----删除缓存 rm -fr /tomcat/apache-tomcat-8.5.42/temp/* ----删除临时缓存 echo $&quot;Starting $IP_ADDR $PROG: &quot; cd /tomcat/apache-tomcat-8.5.42/bin/ ./startup.sh echo &quot;tomcat 8 starting......&quot; } tomcat_log() ---查看程序日志 { echo -n $&quot;ShowLoging $IP_ADDR $PROG log: &quot; tail -n200 -f /tomcat/apache-tomcat-8.5.42/logs/catalina.out } tomcat_stop() ---停止tomcat { echo $&quot;Stopping $IP_ADDR $PROG: &quot; kill $(ps -ef | grep java | grep -v &quot;grep&quot; | grep &quot;apache-tomcat&quot; |awk -F &apos; &apos; &apos;{print $2}&apos;) sleep 12 TOMCAT_STATUS1=$(ps -ef | grep java | grep -v &quot;grep&quot;| grep &quot;apache-tomcat&quot;) if [ -n &quot;$TOMCAT_STATUS1&quot; ];then echo &quot;Run Kill -9&quot; kill -9 $(ps -ef | grep java | grep -v &quot;grep&quot; | grep &quot;apache-tomcat&quot; |awk -F &quot; &quot; &apos;{print $2}&apos;) sleep 2 fi TOMCAT_STATUS2=$(ps -ef | grep java | grep -v &quot;grep&quot;| grep &quot;apache-tomcat&quot; ) if [ -z &quot;$TOMCAT_STATUS2&quot; ];then echo &quot;Tomcat Stop ok&quot; else exit 1 fi } tomcat_status() ---查看tomcat程序状态 { ps -ef | grep java | grep -v &quot;grep&quot;| grep &quot;tomcat&quot; } case &quot;$1&quot; in start) tomcat_start; ;; stop) tomcat_stop; ;; restart) tomcat_stop; tomcat_start; ;; status) tomcat_status; ;; log) tomcat_log; ;; *) echo $&quot;Usage: $prog {start | stop | restart | log | status}&quot; exit 1 esac tomcat 需要jdk才能运行，上面解压以后我是在tomcat启动脚本里面配置的jdk目录，也可以定义在系统全局变量里面，但是我不会这么做，因为我们的环境经常是运行多个实例且JDK版本要求不同，如果安装多个jdk会造成全局冲突全局变量定义方式:vim /etc/profile 写入以下内容: export JAVA_HOME=/jboss/jdk1.8.0_51 export CLASSPATH=$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar export JRE_HOME=$JAVA_HOME/jre export PATH=$PATH:$JAVA_HOME/bin source /etc/profile -- 生效配置 验证java [root@node1 ~]# java -version java version &quot;1.8.0_51&quot; Java(TM) SE Runtime Environment (build 1.8.0_51-b16) Java HotSpot(TM) 64-Bit Server VM (build 25.51-b03, mixed mode) [root@node1 ~]# 4、启动tomcat[root@node1 ~]# ./tomcat.sh start ---启动服务 Starting tomcat: Using CATALINA_BASE: /tomcat/apache-tomcat-8.5.42 Using CATALINA_HOME: /tomcat/apache-tomcat-8.5.42 Using CATALINA_TMPDIR: /tomcat/apache-tomcat-8.5.42/temp Using JRE_HOME: /jboss/jdk1.8.0_51/jre Using CLASSPATH: /tomcat/apache-tomcat-8.5.42/bin/bootstrap.jar:/tomcat/apache-tomcat-8.5.42/bin/tomcat-juli.jar Tomcat started. tomcat 8 starting...... [root@node1 ~]# ./tomcat.sh status root 24103 1 0 11:39 ? 00:00:04 /jboss/jdk1.8.0_51/jre/bin/java -Djava.util.logging.config.file=/tomcat/apache-tomcat-8.5.42/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Xms1000m -Xmx1000m -Xmn400m -XX:PermSize=256m -XX:MaxPermSize=512m -Djdk.tls.ephemeralDHKeySize=2048 -Djava.protocol.handler.pkgs=org.apache.catalina.webresources -Dorg.apache.catalina.security.SecurityListener.UMASK=0027 -Dignore.endorsed.dirs= -classpath /tomcat/apache-tomcat-8.5.42/bin/bootstrap.jar:/tomcat/apache-tomcat-8.5.42/bin/tomcat-juli.jar -Dcatalina.base=/tomcat/apache-tomcat-8.5.42 -Dcatalina.home=/tomcat/apache-tomcat-8.5.42 -Djava.io.tmpdir=/tomcat/apache-tomcat-8.5.42/temp org.apache.catalina.startup.Bootstrap start 09-Jul-2019 11:39:42.759 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Server version: Apache Tomcat/8.5.42 09-Jul-2019 11:39:42.763 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Server built: Jun 4 2019 20:29:04 UTC 09-Jul-2019 11:39:42.763 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Server number: 8.5.42.0 09-Jul-2019 11:39:42.763 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log OS Name: Linux 09-Jul-2019 11:39:42.763 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log OS Version: 3.10.0-327.el7.x86_64 09-Jul-2019 11:39:42.763 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Architecture: amd64 09-Jul-2019 11:39:42.763 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Java Home: /jboss/jdk1.8.0_51/jre 09-Jul-2019 11:39:42.763 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log JVM Version: 1.8.0_51-b16 09-Jul-2019 11:39:42.763 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log JVM Vendor: Oracle Corporation 09-Jul-2019 11:39:42.763 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log CATALINA_BASE: /tomcat/apache-tomcat-8.5.42 09-Jul-2019 11:39:42.764 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log CATALINA_HOME: /tomcat/apache-tomcat-8.5.42 09-Jul-2019 11:39:42.764 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Djava.util.logging.config.file=/tomcat/apache-tomcat-8.5.42/conf/logging.properties 09-Jul-2019 11:39:42.764 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager 09-Jul-2019 11:39:42.764 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Xms1000m 09-Jul-2019 11:39:42.764 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Xmx1000m 09-Jul-2019 11:39:42.764 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Xmn400m 09-Jul-2019 11:39:42.764 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -XX:PermSize=256m 09-Jul-2019 11:39:42.764 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -XX:MaxPermSize=512m 09-Jul-2019 11:39:42.764 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Djdk.tls.ephemeralDHKeySize=2048 09-Jul-2019 11:39:42.765 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Djava.protocol.handler.pkgs=org.apache.catalina.webresources 09-Jul-2019 11:39:42.765 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Dorg.apache.catalina.security.SecurityListener.UMASK=0027 09-Jul-2019 11:39:42.765 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Dignore.endorsed.dirs= 09-Jul-2019 11:39:42.765 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Dcatalina.base=/tomcat/apache-tomcat-8.5.42 09-Jul-2019 11:39:42.765 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Dcatalina.home=/tomcat/apache-tomcat-8.5.42 09-Jul-2019 11:39:42.765 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Djava.io.tmpdir=/tomcat/apache-tomcat-8.5.42/temp 09-Jul-2019 11:39:42.765 信息 [main] org.apache.catalina.core.AprLifecycleListener.lifecycleEvent The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib] 09-Jul-2019 11:39:43.048 信息 [main] org.apache.coyote.AbstractProtocol.init Initializing ProtocolHandler [&quot;http-nio-8080&quot;] 09-Jul-2019 11:39:43.071 信息 [main] org.apache.tomcat.util.net.NioSelectorPool.getSharedSelector Using a shared selector for servlet write/read 09-Jul-2019 11:39:43.095 信息 [main] org.apache.coyote.AbstractProtocol.init Initializing ProtocolHandler [&quot;ajp-nio-8009&quot;] 09-Jul-2019 11:39:43.113 信息 [main] org.apache.tomcat.util.net.NioSelectorPool.getSharedSelector Using a shared selector for servlet write/read 09-Jul-2019 11:39:43.124 信息 [main] org.apache.catalina.startup.Catalina.load Initialization processed in 1109 ms 09-Jul-2019 11:39:43.158 信息 [main] org.apache.catalina.core.StandardService.startInternal Starting service [Catalina] 09-Jul-2019 11:39:43.158 信息 [main] org.apache.catalina.core.StandardEngine.startInternal Starting Servlet Engine: Apache Tomcat/8.5.42 09-Jul-2019 11:39:43.207 信息 [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deploying web application directory [/tomcat/apache-tomcat-8.5.42/webapps/ROOT] 09-Jul-2019 11:44:19.656 警告 [localhost-startStop-1] org.apache.catalina.util.SessionIdGeneratorBase.createSecureRandom Creation of SecureRandom instance for session ID generation using [SHA1PRNG] took [276,003] milliseconds. 09-Jul-2019 11:44:19.697 信息 [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deployment of web application directory [/tomcat/apache-tomcat-8.5.42/webapps/ROOT] has finished in [276,491] ms 09-Jul-2019 11:44:19.697 信息 [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deploying web application directory [/tomcat/apache-tomcat-8.5.42/webapps/docs] 09-Jul-2019 11:44:19.739 信息 [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deployment of web application directory [/tomcat/apache-tomcat-8.5.42/webapps/docs] has finished in [42] ms 09-Jul-2019 11:44:19.739 信息 [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deploying web application directory [/tomcat/apache-tomcat-8.5.42/webapps/examples] 09-Jul-2019 11:44:20.212 信息 [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deployment of web application directory [/tomcat/apache-tomcat-8.5.42/webapps/examples] has finished in [473] ms 09-Jul-2019 11:44:20.213 信息 [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deploying web application directory [/tomcat/apache-tomcat-8.5.42/webapps/host-manager] 09-Jul-2019 11:44:20.266 信息 [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deployment of web application directory [/tomcat/apache-tomcat-8.5.42/webapps/host-manager] has finished in [53] ms 09-Jul-2019 11:44:20.266 信息 [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deploying web application directory [/tomcat/apache-tomcat-8.5.42/webapps/manager] 09-Jul-2019 11:44:20.293 信息 [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deployment of web application directory [/tomcat/apache-tomcat-8.5.42/webapps/manager] has finished in [27] ms 09-Jul-2019 11:44:20.314 信息 [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler [&quot;http-nio-8080&quot;] 09-Jul-2019 11:44:20.342 信息 [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler [&quot;ajp-nio-8009&quot;] 09-Jul-2019 11:44:20.344 信息 [main] org.apache.catalina.startup.Catalina.start Server startup in 277219 ms ----看到此输出，程序就已经正常启动 通过浏览器访问tomcat服务,tomcat 默认端口号为8080http://ipaddr:8080 tomcat端口可在/conf/server.xml文件中修改67 Define a non-SSL/TLS HTTP/1.1 Connector on port 8080 68 --&gt; 69 &lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; --将8080修改为80或其他需要的端口 70 connectionTimeout=&quot;20000&quot; 71 redirectPort=&quot;8443&quot; /&gt; 72 &lt;!-- A &quot;Connector&quot; using the shared thread pool--&gt; tomcat已安装完毕5、tomcat目录结构说明bin -- 程序启动目录 conf -- 配置文件目录 lib -- 库文件目录 logs -- 日志文件目录 temp -- 临时缓存目录 webapps -- web 应用家目录 work -- 工作缓存目录]]></content>
      <categories>
        <category>Linux</category>
        <category>Apache</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Apache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Rabbitmq 入门(集群安装篇)]]></title>
    <url>%2F2019%2F07%2F02%2FRabbitmq-%E5%85%A5%E9%97%A8(%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85%E7%AF%87)%2F</url>
    <content type="text"><![CDATA[简介:RabbitMQ是采用Erlang语言实现AMQP（Advanced Message Queuing Protocol，高级消息队列协议）的消息中间件，它最初起源于金融系统，用于在分布式系统中存储转发消息。MQ全称为Message Queue, 消息队列（MQ）是一种应用程序对应用程序的通信方法。应用程序通过读写出入队列的消息（针对应用程序的数据）来通信，而无需专用连接来链接它们。消息传递指的是程序之间通过在消息中发送数据进行通信，而不是通过直接调用彼此来通信，直接调用通常是用于诸如远程过程调用的技术。排队指的是应用程序通过 队列来通信。队列的使用除去了接收和发送应用程序同时执行的要求。其中较为成熟的MQ产品有IBM WEBSPHERE MQ等等。RabbitMQ是目前非常热门的一款消息中间件，很多行业都在使用这个消息中间件，RabbitMQ凭借其高可靠、易扩展、高可用及丰富的功能特性收到很多人的青睐。一、软件下载：下载Erlang 百度云提取码: 864m下载Rabbitmq 源码包 百度云提取码: qwih点击此处跳转到官方网站下载最新版本二、安装环境:node1 172.31.8.8 system Centos 7 —- node3 172.31.8.107 system Centos 7node2 172.31.8.13 system Centos 7 —- node4 172.31.8.75 system Centos 7软件版本：Erlang 21.3rabbitmq 3.7.7三、单点安装(以下操作需要在其他四个节点重复执行)1、分别编辑四台机器的/etc/hosts 文件，增加以下内容172.31.8.8 node1172.31.8.13 node2172.31.8.107 node3172.31.8.75 node42、安装依赖包yum install -y *epel* gcc-c++ unixODBC unixODBC-devel openssl-devel ncurses-devel 3、编译安装 Erlang[root@node1 ~]# tar xf otp_src_21.3.tar.gz [root@node1 ~]# cd otp_src_21.3 [root@node1 otp_src_21.3]# ./configure --prefix=/usr/local/bin/erlang --without-javac [root@node1 otp_src_21.3]# make &amp;&amp; make install [root@node1 otp_src_21.3]# echo &quot;export PATH=$PATH:/usr/local/bin/erlang/bin:/usr/local/bin/rabbitmq_server-3.6.5/sbin&quot; &gt;&gt; /etc/profile [root@node1 otp_src_21.3]# source /etc/profile 查看erlang 是否安装成功，出现以下输出即证明erlang已经安装成功4、安装Rabbitmq[root@node1 ~]# tar xf rabbitmq-server-generic-unix-3.7.7.tar [root@node2 ~]# mv rabbitmq_server-3.7.7 /usr/local/rabbitmq-3.7.7 [root@node2 ~]# cd /usr/local/rabbitmq-3.7.7/ [root@node1 ~]# echo &quot;export PATH=$PATH:/usr/local/rabbitmq-3.7.7/sbin&quot; &gt;&gt; /etc/profile [root@node1 ~]# source /etc/profile [root@node1 ~]# rabbitmq-plugins enable rabbitmq_management ---打开管理页面插件 [root@node1 ~]# rabbitmq-server -detached --后台启动服务 [root@node1 ~]# rabbitmqctl add_user admin 123456 --增加用户名admin，密码123456 [root@node1 ~]# rabbitmqctl set_permissions -p &quot;/&quot; admin &quot;.*&quot; &quot;.*&quot; &quot;.*&quot; [root@node1 ~]# rabbitmqctl set_user_tags admin administrator --设置用户admin为管理员 打开web页面，出现以下页面即安装成功node1node2四、部署集群:1、 修改 .erlang.cookie文件，node1、node4节点内容改为一致[root@node1 ~]# chmod 400 .erlang.cookie --设置.erlang.cookie文件权限,为了防止添加集群失败四个节点均需要调整为一致 [root@node1 ~]# scp .erlang.cookie root@172.31.8.13:/root/ [root@node1 ~]# scp .erlang.cookie root@172.31.8.107:/root/ [root@node1 ~]# scp .erlang.cookie root@172.31.8.75:/root/ 添加集群失败报错示例: 出现此信息可根据提示进行排查2、 替换完.erlang.cookie文件，需要重启各个节点的rabbitmq服务node1 [root@node1 ~]# kill -9 PID [root@node1 ~]# rabbitmq-server -detached node2 [root@node2 ~]# kill -9 PID [root@node2 ~]# rabbitmq-server -detached node3 [root@node3 ~]# kill -9 PID [root@node3 ~]# rabbitmq-server -detached node4 [root@node4 ~]# kill -9 PID [root@node5 ~]# rabbitmq-server -detached 3、添加节点到集群，将node1节点作为主节点在 node2 节点执行以下命令：[root@node2 ~]# rabbitmqctl stop_app [root@node4 ~]# rabbitmqctl join_cluster rabbit@node1 --默认为disc节点，如果需要指定节点角色，可以添加--ram/--disc参数 [root@node4 ~]# rabbitmqctl start_app [root@node4 ~]# rabbitmqctl cluster_status 以上命令在node3、4节点重复执行执行结果:打开web管理页面查看状态到此Rabbitmq集群已经安装完毕，四个节点均已正常运行五、集群管理1、假设Rabbitmq-node2节点需要退出集群在node2节点执行：rabbitmqctl stop_app --停止rabbitmq服务 rabbitmqctl reset --将RabbitMQ node还原到最初状态.包括从所在群集中删除此node,从管理数据库中删除所有配置数据，如已配置的用户和虚拟主机，以及删除所有持久化消息. rabbitmqctl start_app 在主节点（node1）执行rabbitmqctl forget_cluster_node rabbit@node2 --此命令会从集群中删除rabbit@node2节点. 2、修改node2、node4节点为内存节点，在node2、4节点执行:[root@node2 ~]# rabbitmqctl stop_app --停止rabbitmq服务 [root@node2 ~]# rabbitmqctl change_cluster_node_type ram --修改节点为内存节点 [root@node2 ~]# rabbitmqctl start_app --启动服务 [root@node2 ~]# rabbitmqctl cluster_status --查看集群状态 执行结果可以看到node2节点已经修改为RAM节点，disc节点为node1、3、4再修改node4节点：node2、node4节点已经成功修改为内存节点，现在集群就是双内存、双硬盘节点，从控制台查看更为直观:更多管理命令可参考文档:https://blog.csdn.net/wulex/article/details/64127224点击此处查看官方文档]]></content>
      <categories>
        <category>Linux</category>
        <category>Rabbitmq</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Rabbitmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DDOS网络攻击测试工具LOIC]]></title>
    <url>%2F2019%2F06%2F10%2FDDOS%E7%BD%91%E7%BB%9C%E6%94%BB%E5%87%BB%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7LOIC%2F</url>
    <content type="text"><![CDATA[1、简介DoS(Denial Of Service)攻击是指故意的攻击网络协议实现的缺陷或直接通过野蛮手段残忍地耗尽被攻击对象的资源，目的是让目标计算机或网络无法提供正常的服务或资源访问，使目标系统服务系统停止响应甚至崩溃。然而随着网络上免费的可用DDOS工具增多，Dos攻击也日益增长，下面介绍一款Hacker常用的Dos攻击工具LOIC（卢卡）特别提示: 此款工具仅限于教学测试、攻防演练用途，禁止用于非法途径LOIC（卢卡）（Low Orbit Ion Canon）LOTC是一个最受欢迎的DOS攻击工具。 这个工具被去年流行的黑客集团“匿名者”用于对许多大公司的网络攻击。它可以通过使用单个用户执行DOS攻击小型服务器，工具非常易于使用，即便你是一个初学者。 这个工具执行DOS攻击通过发送UDP,TCP或HTTP请求到受害者服务器。 你只需要知道服务器的IP地址或URL.还有其他类似的工具如：XOIC、HULK等等下载地址2、使用方法LOIC 可用于内外网压力测试，下载打开即可直接使用LOIC 应用界面:温馨提示：珍爱生命，远离网络攻击。]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>网络</tag>
        <tag>安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jira(安装篇)]]></title>
    <url>%2F2019%2F05%2F21%2Fjira(%E5%AE%89%E8%A3%85%E7%AF%87)%2F</url>
    <content type="text"><![CDATA[一、jira环境需求system： Linuxmemory： 2GBMysql数据库Jdk jdk-8u92-linux-x64.rpmJira atlassian-jira-6.4.12-x64Jira + 数据库连接插件mysql-connector-java-5.1.36-bin部署前机器的内存至少为2GB.否则会出现如下错误：二、安装部署部署前配置 关闭iptables和selinuxservice iptables stop &amp;&amp; setenforce 02.1 jdk安装查看版本号 jdk安装完毕2.2 安装mysql数据库（如果有的可以跳过安装这一步）采用的是yum安装yum install http://www.percona.com/downloads/percona-release/redhat/0.1-3/percona-release-0.1-3.noarch.rpmyum install Percona-Server-server-56初始化mysql数据库，创建账户并赋予链接权限创建jira库和jira用户create database jiradb character set utf8; grant select,insert,update,delete,create,drop,alter,index on jiradb.* to &apos;jira&apos;@&apos;localhost&apos; identified by &apos;jira&apos;; flush privileges; 退出，使用jira账户进行登陆测试mysql –ujira –p 下载mysql-connector-java-5.1.39.tar.gz 连接2.3 安装jira上传jira文件Chmod +x./Jira web访问端口为8080由于jira默认是不支持使用mysql数据库的，如果用mysql的话就得把链接插件放到以下目录，并重启jira上传mysql – jira 连接插件cd /opt/atlassian/jira/atlassian-jira/WEB-INF/lib/上传文件cd /opt/atlassian/jira/atlassian-jira/WEB-INF/lib/上传中文语言包删除 cd /var/atlassian/application-data/jira/打开浏览器，开始设置向导连接数据库选择模式装的过程中需要在官网获取试用序列号，然后进行破解！！]]></content>
      <categories>
        <category>Linux</category>
        <category>jira</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>jira</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix 缓存数据清理]]></title>
    <url>%2F2019%2F05%2F20%2FZabbix-%E7%BC%93%E5%AD%98%E6%95%B0%E6%8D%AE%E6%B8%85%E7%90%86%2F</url>
    <content type="text"><![CDATA[zabbix监控运行一段时间以后，会留下大量的历史监控数据，zabbix数据库一直在增大；可能会造成系统性能下降，查看历史数据室查询速度缓慢。zabbix里面最大的表就是history和history_uint两个表，而且zabbix里面的时间是使用的时间戳方式记录，所以可以根据时间戳来删除历史数据一、关闭zabbix、http服务pkill -9 zabbix service httpd stop 二、清理zabbix历史数据1、查看数据库目录文件[root@zabbix-server zabbix]# cd /var/lib/mysql/zabbix/ [root@zabbix-server zabbix]# ls -lh | grep G total 177G -rw-r----- 1 mysql mysql 1.7G Dec 24 13:49 events.ibd -rw-r----- 1 mysql mysql 60G Dec 24 13:49 history.ibd -rw-r----- 1 mysql mysql 2.4G Dec 24 13:49 history_str.ibd -rw-r----- 1 mysql mysql 99G Dec 24 13:49 history_uint.ibd -rw-r----- 1 mysql mysql 4.6G Dec 24 13:02 trends.ibd -rw-r----- 1 mysql mysql 9.5G Dec 24 13:49 trends_uint.ibd [root@zabbix-server zabbix]# 生成Unix时间戳。时间定为2018年2月1日（暂定是保存18年2月以后的监控数据）[root@zabbix-server zabbix]# date +%s -d &quot;Feb 1, 2018 00:00:00&quot; #执行此命令以后会生成一个ID 1517414400 #这是生成的ID 2、数据备份[root@zabbix-server zabbix]#mysql -uroot -p zabbix &gt; /root/mysqlback/zabbix.sql #需要创建mysqlback目录 3、 登录数据库[root@zabbix-server zabbix]# mysql -uroot -p Enter password: Welcome to the MariaDB monitor. Commands end with ; or \g. Your MariaDB connection id is 7 Server version: 5.5.60-MariaDB MariaDB Server Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others. Type &apos;help;&apos; or &apos;\h&apos; for help. Type &apos;\c&apos; to clear the current input statement. MariaDB [(none)]&gt; use zabbix; #选择zabbix数据库 执行sql查看指定日期之前的数据大小：SELECT table_schema as `Database`,table_name AS `Table`,round(((data_length + index_length) / 1024 / 1024 / 1024), 2) `Size in MB`FROM information_schema.TABLES where CREATE_TIME &lt; &apos;2018-02-01 00:00:00&apos; and table_name=&apos;history.ibd&apos;; 根据需要修改日期和查询的表名称(如果查询出来的结果是0.0，需要将sql中的三个1024删除一个，以G为单位显示)4、 执行以下命令，清理指定时间之前的数据、对zabbix数据库执行以下sqldelete from history where clock &lt; 1517414400; optimize table history; delete from history_uint where clock &lt; 1517414400; optimize table history_uint; delete from trends where clock &lt; 1517414400; optimize table trends; delete from trends_uint where clock &lt; 1517414400; optimize table trends_uint; 注意：sql中的ID是生成Unix时间戳的ID号,需要改为自己生成的ID号三、启动服务/usr/sbin/zabbix_server -c /etc/zabbix/zabbix_server.conf #zabbix server /usr/sbin/zabbix_agentd -c /etc/zabbix/zabbix_agentd.conf #zabbix agent service httpd start ===============================分===========隔==========符===================================1、使用truncate命令清空zabbix 所有监控数据------------------------------------------------------- truncate table history; optimize table history; ------------------------------------------------------- truncate table history_str; optimize table history_str; ------------------------------------------------------- truncate table history_uint; optimize table history_uint; ------------------------------------------------------- truncate table trends; optimize table trends; ------------------------------------------------------- truncate table trends_uint; optimize table trends_uint; ------------------------------------------------------- truncate table events; optimize table events; ------------------------------------------------------- 注意：这些命令会把zabbix所有的监控数据清空，操作前注意备份数据库truncate是删除了表，然后根据表结构重新建立，delete删除的是记录的数据没有修改表truncate执行删除比较快，但是在事务处理安全性方面不如delete,如果我们执行truncat的表正在处理事务，这个命令退出并会产生错误信息]]></content>
      <categories>
        <category>Linux</category>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis 故障恢复]]></title>
    <url>%2F2019%2F05%2F10%2FRedis-%E6%95%85%E9%9A%9C%E6%81%A2%E5%A4%8D%2F</url>
    <content type="text"><![CDATA[案例一、ResponseError: MISCONF Redis is configured to save RDB snapshots, but is currently not able to persist on disk.Commands that may modify the data set are disabled. Please check Redis logs for details about the error.Redis被配置为保存数据库快照，但它目前不能持久化到硬盘。用来修改集合数据的命令不能用。请查看Redis日志的详细错误信息。原因：强制关闭redis快照导致不能持久化解决方案：将：stop-writes-on-bgsave-error 设置为 no]]></content>
      <categories>
        <category>Linux</category>
        <category>redis</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Python统计nginx日志前十个IP的访问量，并以柱状图显示]]></title>
    <url>%2F2018%2F12%2F28%2F%E4%BD%BF%E7%94%A8Python%E7%BB%9F%E8%AE%A1nginx%E6%97%A5%E5%BF%97%E5%89%8D%E5%8D%81%E4%B8%AAIP%E7%9A%84%E8%AE%BF%E9%97%AE%E9%87%8F%EF%BC%8C%E5%B9%B6%E4%BB%A5%E6%9F%B1%E7%8A%B6%E5%9B%BE%E6%98%BE%E7%A4%BA%2F</url>
    <content type="text"><![CDATA[1、脚本代码可参考本人博客园文章import matplotlib.pyplot as plt nginx_file = &apos;&apos; --填写nginx日志文件名，需在同一目录 ip = {} #筛选nginx日志文件中的IP with open(nginx_file) as f: for i in f.readlines(): s = i.strip().split()[0] lengh = len(ip.keys()) #统计每个IP的访问以字典存储 if s in ip.keys(): ip[s] = ip[s] + 1 else: ip[s] = 1 #以IP出现的次数排序返回对象为list ip = sorted(ip.items(), key=lambda e:e[1], reverse=True) #取列表前十 newip = ip[0:20:1] tu = dict(newip) x = [] y = [] for k in tu: x.append(k) y.append(tu[k]) plt.title(&apos;ip access&apos;) plt.xlabel(&apos;ip address&apos;) plt.ylabel(&apos;pv&apos;) #X 轴项的翻转角度 plt.xticks(rotation=70) #显示每个柱状图的值 for a,b in zip(x,y): plt.text(a, b, &apos;%.0f&apos; % b, ha=&apos;center&apos;, va= &apos;bottom&apos;,fontsize=7) plt.bar(x,y) plt.legend() plt.show() 2、效果图:]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PTES渗透测试执行标准]]></title>
    <url>%2F2018%2F09%2F17%2FPTES%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E6%89%A7%E8%A1%8C%E6%A0%87%E5%87%86%2F</url>
    <content type="text"><![CDATA[渗透测试注意事项：1、不要进行恶意攻击2、不要做傻事3、在没有获得书面授权时，不要攻击任何目标4、考虑清楚攻击将会带来的后果4、如果干了非法的事情，记得天网恢恢疏而不漏参考官方对于渗透测试执行标准描述（PTES）一：前期交互阶段在前期交互阶段，渗透测试团队与客户组织进行交互讨论，最重要的是确定渗透测试的范围、目标、限制条件以及合同细节该阶段通常涉及收集客户需求，准备测试计划、定义测试范围与边界、定义业务目标、项目管理与规划等活动二：情报收集阶段在目标范围确定之后，将进入情报搜集（Information Gathering）阶段，渗透团队可以利用各种信息来源与搜集技术方法，尝试更多关于组织网络拓扑、系统配置与安全防御措施的信息。渗透测试者可以使用情报搜集方法包括公开来源信息查询、google Hacking 、社会工程学、网络踩点、扫描探测、被动监听、服务查点等。而对目标系统的情报探查能力是渗透者一项非常重要的技能，情报搜集是否充分在很大程度上决定了渗透测的成败，因为如果你遗漏关键的情报信息，你将可能在后面的阶段一无所获。三：威胁建模阶段在搜集到充分的情报信息之后，渗透测试团队的成员们停下敲击键盘，大家聚到一起针对获取的信息进行威胁建模（Threat Modeling）与攻击规划。这是渗透测试过程中非常重要，但很容易被忽视的一个关键点。通过团队共同的缜密情报分析与攻击思路头脑风暴，可以从大量的信息情报中理清头绪，确定出最可行的攻击通道。四：漏洞分析阶段在确定出最可行的攻击通道之后，接下来需要考虑该如何取得目标系统的访问控制权，即漏洞分析（Vulnerability Analysis）阶段。在该阶段，渗透测试者需要综合分析前几个阶段获取并汇总的情报信息，特别是安全漏洞扫描结果、服务查点信息等，通过搜索可获取的渗透代码资源，找出可以实施渗透攻击的攻击点，并在实验环境中进行验证。在该阶段，高水平的渗透测试团队还会针对攻击通道上的一些关键系统与服务进行安全漏洞探测与挖掘，期望找出可被利用的未知安全漏洞，并开发出渗透代码，从而打开攻击通道上的关键路径。五：渗透攻击阶段渗透攻击（Exploitation）是渗透测试过程中最具有魅力的环节。在此环节中，渗透测试团队需要利用他们所找出的目标系统安全漏洞，来真正入侵系统当中，获得访问控制权。渗透攻击可以利用公开渠道可获取的渗透代码，但一般在实际应用场景中，渗透测试者还需要充分地考虑目标系统特性来定制渗透攻击，并需要挫败目标网络与系统中实施的安全防御措施，才能成功达成渗透目的。在黑盒测试中，渗透测试者还需要考虑对目标系统检测机制的逃逸，从而避免造成目标组织安全响应团队的警觉和发现六：后渗透攻击阶段后渗透攻击（Post Exploitation）是整个渗透测试过程中最能够体现渗透测试团队创造力与技术能力的环节。前面的环节可以说都是在按部就班地完成非常普遍的目标，而在这个环节中，需要渗透测试团队根据目标组织的业务经营模式、保护资产形式与安全防御计划的不同特点，自主设计出攻击目标，识别关键基础设施，并寻找客户组织最具价值和尝试安全保护的信息和资产，最终达成能够对客户组织造成最重要业务影响的攻击途径。在不同的渗透测试场景中，这些攻击目标与途径可能是千变万化的，而设置是否准确并且可行，也取决于团队自身的创新意识、知识范畴、实际经验和技术能力。七：报告阶段渗透测试过程最终向客户组织提交，取得认可并成功获得合同付款的就是一份渗透测试报告（Reporting）。这份报告凝聚了之前所有阶段之中渗透测试团队所获取的关键情报信息、探测和发掘出的系统安全漏洞、成功渗透攻击的过程，以及造成业务影响后果的攻击途径，同时还要站在防御者的角度上，帮助他们分析安全防御体系中的薄弱环节、存在的问题，以及修补与升级技术方案。八：渗透术语：渗透攻击（Exploit）攻击者利用安全漏洞，所进行的攻击行为，常见的渗透攻击技术包括缓冲区溢出、web应用程序漏洞攻击（SQL注入）、利用配置错误等攻击载荷（Payload）目标系统在被渗透攻击之后执行的代码Shellcode在渗透攻击时作为攻击载荷运行的一组机器指令，通常用汇编语言编写模块（Module）一段软件代码组件监听器（Listener）用来等待连入网络链接的组件]]></content>
      <categories>
        <category>安全</category>
        <category>渗透测试</category>
      </categories>
      <tags>
        <tag>安全</tag>
        <tag>渗透测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[(二)、Ansible在使用过程中出现的错误解决方法]]></title>
    <url>%2F2018%2F09%2F02%2F%E4%BA%8C-%E3%80%81Ansible%E5%9C%A8%E4%BD%BF%E7%94%A8%E8%BF%87%E7%A8%8B%E4%B8%AD%E5%87%BA%E7%8E%B0%E7%9A%84%E9%94%99%E8%AF%AF%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[1.安装完成后允许命令出错Traceback (most recent call last): File &quot;/usr/bin/ansible&quot;, line 197, in &lt;module&gt; (runner, results) = cli.run(options, args) File &quot;/usr/bin/ansible&quot;, line 163, in run extra_vars=extra_vars, File &quot;/usr/lib/python2.6/site-packages/ansible/runner/__init__.py&quot;, line 233, in __init__ cmd = subprocess.Popen([&apos;ssh&apos;,&apos;-o&apos;,&apos;ControlPersist&apos;], stdout=subprocess.PIPE, stderr=subprocess.PIPE) File &quot;/usr/lib64/python2.6/subprocess.py&quot;, line 639, in __init__ errread, errwrite) File &quot;/usr/lib64/python2.6/subprocess.py&quot;, line 1228, in _execute_child raise child_exception OSError: [Errno 2] No such file or directory 解决办法yum -y install openssh-clients2.出现Error: ansible requires a json module, none found!SSH password: 10.0.1.110 | FAILED &gt;&gt; { &quot;failed&quot;: true, &quot;msg&quot;: &quot;Error: ansible requires a json module, nonefound!&quot;, &quot;parsed&quot;: false } 解决办法python版本过低，可以升级python或者python-simplejson3.安装完成后链接客户端报错（配图为我在使用ansible推送文件到客户端的时候遇到的，这个客户端是第一次推送）FAILED =&gt; Using a SSH password insteadof a key is not possible because Host Key checking is enabled and sshpass doesnot support this. Please add this host&apos;sfingerprint to your known_hosts file to manage this host. 解决办法：在ansible 服务器上使用ssh 登陆下/etc/ansible/hosts 里面配置的服务器。然后再次使用ansible 去管理就不会报上面的错误了！但这样大批量登陆就麻烦来。因为默认ansible是使用key验证的，如果使用密码登陆的服务器，使用ansible的话，要不修改ansible.cfg配置文件的ask_pass = True给取消注释，要不就在运行命令时候加上-k，这个意思是-k, –ask-pass ask for SSH password。再修改：host_key_checking= False即可4.如果客户端不在know_hosts里将会报错paramiko: The authenticity of host &apos;192.168.24.15&apos;can&apos;t be established. The ssh-rsa key fingerprint is397c139fd4b0d763fcffaee346a4bf6b. Are you sure you want to continueconnecting (yes/no)? 解决办法需要修改ansible.cfg的#host_key_checking= False取消注释5.出现FAILED =&gt; FAILED: not a valid DSA private key file解决办法：需要你在最后命令内添加参数-k6.openssh升级后无法登录报错PAM unable todlopen(/lib64/security/pam_stack.so): /lib64/security/pam_stack.so: cannot openshared object file: No such file or directory 解决方法：sshrpm 升级后会修改/etc/pam.d/sshd 文件。需要升级前备份此文件最后还原即可登录。7.第一次系统初始化运行生成本机ansible用户key时报错failed: [127.0.0.1] =&gt;{&quot;checksum&quot;: &quot;f5f2f20fc0774be961fffb951a50023e31abe920&quot;,&quot;failed&quot;: true} msg: Aborting, target uses selinux but pythonbindings (libselinux-python) aren&apos;t installed! FATAL: all hosts have already failed –aborting 解决办法yum -y install libselinux-python参考: http://blog.csdn.net/longxibendi/article/details/46989735]]></content>
      <categories>
        <category>自动化</category>
      </categories>
      <tags>
        <tag>自动化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible]]></title>
    <url>%2F2018%2F09%2F01%2FAnsible%2F</url>
    <content type="text"><![CDATA[1、ansible介绍：Ansible是一款基于Python开发的自动化运维工具，主要是实现批量系统配置、批量程序部署、批量运行命令、批量执行任务等等诸多功能。Ansible是一款灵活的开源工具，能够很大程度简化运维中的配置管理与流程控制方式，它利用推送方式对客户系统加以配置，这样所有工作都可在主服务器端完成。Asible是基于模块工作的，其本身没有批量部署的能力，Ansible~一款运维自动化的软件！1.1特性(1)、no agents：不需要在被管控主机上安装任何客户端；(2)、no server：无服务器端，使用时直接运行命令即可；(3)、modules in any languages：基于模块工作，可使用任意语言开发模块；(4)、yaml，not code：使用yaml语言定制剧本playbook；(5)、ssh by default：基于SSH工作；(6)、strong multi-tier solution：可实现多级指挥。1.1 优点(1)、轻量级，无需在客户端安装agent，更新时，只需在操作机上进行一次更新即可；(2)、批量任务执行可以写成脚本，而且不用分发到远程就可以执行；(3)、使用python编写，维护更简单，ruby语法过于复杂；(4)、支持sudo。2、ansible安装安装epel 源：rpm -ivh https://dl.fedoraproject.org/pub/epel/epel-release-latest-6.noarch.rpm安装ansible ：yum install ansible -yssh-keygen 生成秘钥文件,如果不想输入密码可以一直回车ssh-keygen -t rsacd /root/.ssh/ &amp;&amp; ll ./*配置ansible 的hosts 文件：vim /etc/ansible/hosts]]></content>
      <categories>
        <category>自动化</category>
      </categories>
      <tags>
        <tag>自动化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[solr6+tomcat8+zookeeper 环境部署]]></title>
    <url>%2F2018%2F08%2F22%2Fsolr6%2Btomcat8%2Bzookeeper%20%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[安装概述：以下是部署环境：系统环境为：三台系统为Centos 6.8 的服务器主机IP：10.6.11.19 10.6.11.23 10.6.11.22软件环境为：tomcat 8.5.24jdk1.8.0_162solr6.6.3zookeepr-3.4.10tomcat安装不多说，配置java环境即可启动，出现以下画面就说明tomcat服务已经部署完成将solr6部署到tomcat 8 容器内（仅以单节点安装为例，三个节点的安装步骤是一样的）cp -r /home/tomcat/software/solr-6.6.3/server/solr-webapp/webapp /home/tomcat/apache-tomcat-8.5.24-solr/webapps/solr cp -r /home/tomcat/software/solr-6.6.3/server/lib/metrics* /home/tomcat/apache-tomcat-8.5.24-solr/webapps/solr/WEB-INF/lib/ rm -f /home/tomcat/apache-tomcat-8.5.24-solr/webapps/solr/WEB-INF/lib/metrics-jetty9-3.2.2.jar cp -r /home/tomcat/software/solr-6.6.3/server/lib/ext/* /home/tomcat/apache-tomcat-8.5.24-solr/webapps/solr/WEB-INF/lib/ cp -r /home/tomcat/software/solr-6.6.3/dist/solr-dataimporthandler-* /home/tomcat/apache-tomcat-8.5.24-solr/webapps/solr/WEB-INF/lib cp -r /home/tomcat/software/solr-6.6.3/dist/solr-clustering-6.6.3.jar /home/tomcat/apache-tomcat-8.5.24-solr/webapps/solr/WEB-INF/lib mkdir /home/tomcat/apache-tomcat-8.5.24-solr/webapps/solr/WEB-INF/classes cp -r /home/tomcat/software/solr-6.6.3/server/resources/log4j.properties /home/tomcat/apache-tomcat-8.5.24-solr/webapps/solr/WEB-INF/classes 创建solrhome目录mkdir /home/tomcat/apache-tomcat-8.5.24-solr/solrhomecp -r /home/tomcat/software/solr-6.6.3/server/solr/* /home/tomcat/apache-tomcat-8.5.24-solr/solrhome/修改web.xml文件，配置solrhome目录和solr访问权限vim /home/tomcat/apache-tomcat-8.5.24-solr/webapps/solr/WEB-INF/web.xml找到solr/home 根据自己的实际情况配置solr路径&lt;env-entry&gt; &lt;env-entry-name&gt;solr/home&lt;/env-entry-name&gt; &lt;env-entry-value&gt;/home/tomcat/apache-tomcat-8.5.24-solr/solrhome&lt;/env-entry-value&gt; &lt;env-entry-type&gt;java.lang.String&lt;/env-entry-type&gt; &lt;/env-entry&gt; 配置访问权限，注释下图红圈部分内容修改tomcat server.xml文件，配置服务访问端口vim /home/tomcat/apache-tomcat-8.5.24-solr/conf/server.xml&lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; maxHttpHeaderSize=&quot;8192&quot; connectionTimeout=&quot;20000&quot; maxThreads=&quot;150&quot; maxSpareThreads=&quot;75&quot; redirectPort=&quot;8443&quot; /&gt; &lt;!-- A &quot;Connector&quot; using the shared thread pool--&gt; 修改solr配置文件 host设置为本机IP，port设置和tomcat端口一致，均为8080vim /home/tomcat/apache-tomcat-8.5.24-solr/solrhome/solr.xml&lt;solr&gt; &lt;solrcloud&gt; &lt;str name=&quot;host&quot;&gt;${host:10.6.11.19}&lt;/str&gt; &lt;int name=&quot;hostPort&quot;&gt;${jetty.port:8080}&lt;/int&gt; &lt;str name=&quot;hostContext&quot;&gt;${hostContext:solr}&lt;/str&gt; &lt;bool name=&quot;genericCoreNodeNames&quot;&gt;${genericCoreNodeNames:true}&lt;/bool&gt; &lt;int name=&quot;zkClientTimeout&quot;&gt;${zkClientTimeout:30000}&lt;/int&gt; &lt;int name=&quot;distribUpdateSoTimeout&quot;&gt;${distribUpdateSoTimeout:600000}&lt;/int&gt; &lt;int name=&quot;distribUpdateConnTimeout&quot;&gt;${distribUpdateConnTimeout:60000}&lt;/int&gt; &lt;str name=&quot;zkCredentialsProvider&quot;&gt;${zkCredentialsProvider:org.apache.solr.common.cloud.DefaultZkCredentialsProvider}&lt;/str&gt; &lt;str name=&quot;zkACLProvider&quot;&gt;${zkACLProvider:org.apache.solr.common.cloud.DefaultZkACLProvider}&lt;/str&gt; &lt;/solrcloud&gt; &lt;shardHandlerFactory name=&quot;shardHandlerFactory&quot; class=&quot;HttpShardHandlerFactory&quot;&gt; &lt;int name=&quot;socketTimeout&quot;&gt;${socketTimeout:600000}&lt;/int&gt; &lt;int name=&quot;connTimeout&quot;&gt;${connTimeout:60000}&lt;/int&gt; &lt;/shardHandlerFactory&gt; &lt;/solr&gt; 重启tomcat 服务，验证安装访问地址：http://IP:8080/solr/#/出现以上页面，solr就已成功部署到tomcat容器内创建根据需求创建分片,使用以下命令进行创建：http://IP:8080/solr/admin/collections?action=CREATE&amp;name=分片名称&amp;numShards=分片数&amp;replicationFactor=副本数&amp;maxShardsPerNode=节点数&amp;collection.configName=conf目录名称 例如：http://10.6.11.19:8080/solr/admin/collections?action=CREATE&amp;name=user&amp;numShards=2&amp;replicationFactor=3&amp;maxShardsPerNode=3&amp;collection.configName=user 出现以下参数即说明分片创建成功访问http://IP:8080/solr/#/~cloud 验证分片使用此命令创建了两个分片，三个副本一般只可以创建两个副本，增加&amp;maxShardsPerNode=3&amp;collection.configName=user 参数突破副本创建限制]]></content>
      <categories>
        <category>Linux</category>
        <category>搜索</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>solr</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[clamav Linux杀毒软件]]></title>
    <url>%2F2018%2F06%2F10%2Fclamav%20Linux-%E6%9D%80%E6%AF%92%E8%BD%AF%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[一、clamav简介ClamAV是一个C语言开发的开源病毒扫描工具用于检测木马/病毒/恶意软件等。可以在线更新病毒库，Linux系统的病毒较少，但是并不意味着病毒免疫，尤其是对于诸如邮件或者归档文件中夹杂的病毒往往更加难以防范，而ClamAV则能起到不少作用。官网上关于clamav的解释很简单，就是一款用于木马、病毒、恶意软件以及其他恶意威胁的杀毒软件(点击此处跳转到官网)官网下载地址更能特性：1、主要用途 邮件网关的病毒扫描，内建支持多种邮件格式2、高性能 提供多线程的扫描进程3、命令行 提供密令行扫描方式4、扫描对象 可以对要发送的邮件或者文件进行扫描5、文件格式 支持多种文件格式6、病毒库更新频度 一天多次病毒库的更新7、归档文件 支持扫描多种归档文件,比如Zip, RAR, Dmg, Tar, Gzip, Bzip2, OLE2, Cabinet, CHM, BinHex, SIS等8、文档 支持流行的文档文件，比如： MS Office文件，MacOffice文件, HTML, Flash, RTF，PDF安装方式CENTOS/RHELyum -y install clamav Ubuntu/Debianapt-get install clamav 二、安装杀毒软件yum -y install clamav 更新数据库freshclam 病毒库文件/var/lib/clamav/daily.cvd /var/lib/clamav/main.cvd 添加定时任务，设置自动更新:每两个小时自动更新crontab -e 0 */2 * * * root /usr/share/clamav/freshclam-sleep 三、使用clamscan是病毒扫描命令，以下是一些常用参数： clamscan ---不加参数的使用：扫描当前目录下的文件 clamscan -V ---查看clamAV的版本 clamscan -r ---递归扫描子文件夹 clamscan -i ---仅仅显示被感染的文件 clamscan -o ---跳过显示状态ok的文件 clamscan --remove ---检测到有病毒时，直接删除 clamscan --no-summary ---不显示统计信息 clamscan -l scan.log ---将扫描日志写入scan.log文件 ---以上命令都可以在末尾添加文件夹，来扫描指定目录，如 clamscan -r -i /home --remove -l scan.log ---递归扫描/home/目录下的所有文件，只显示病毒文件，并同时删除 示例：clamscan -l scan.log 执行完以后会有详细的扫描信息]]></content>
      <categories>
        <category>安全</category>
        <category>系统病毒扫描</category>
      </categories>
      <tags>
        <tag>安全</tag>
        <tag>Linux</tag>
        <tag>系统杀毒</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 系统安全检查（shell）]]></title>
    <url>%2F2018%2F04%2F22%2FLinux%20%E7%B3%BB%E7%BB%9F%E5%AE%89%E5%85%A8%E6%A3%80%E6%9F%A5%EF%BC%88shell%EF%BC%89%2F</url>
    <content type="text"><![CDATA[脚本内容:#!/bin/bash echo &quot; (__)&quot; echo &quot; (oo)&quot; echo &quot; /------\/ &quot; echo &quot; / | || &quot; echo &quot; * /\---/\ &quot; echo &quot; ~~ ~~ &quot; echo &quot;Are You Ready?&quot; read key echo &quot;警告：本脚本只作为日常巡检使用，不会对服务器做任何修改，管理员可以根据此报告进行相应的设置。&quot; echo ------------------------------------------------------------------------ echo &quot;查看系统时间&quot; DATE=`date` echo &quot;Date is $DATE&quot; echo ------------------------------------------------------------------------ echo &quot;进行系统时间同步&quot; ntpdate time.nist.gov echo ------------------------开始进行检查---------------------- echo &quot;检查时间为&quot; DATE=`date` echo &quot;Date is $DATE&quot; echo ------------------------主机基本信息检查----------------------- echo &quot;系统版本（Centos或Rehead）&quot; cat /etc/redhat-release echo -------------------------------------------------------------------------- echo &quot;系统位数（32位或64位）&quot; getconf LONG_BIT echo -------------------------检查IP信息----------------------------------------- echo &quot;本机的ip地址是：&quot; ifconfig | grep --color &quot;\([0-9]\{1,3\}\.\)\{3\}[0-9]\{1,3\}&quot; echo -------------------------检查系统用户信息--------------------------------------- awk -F&quot;:&quot; &apos;{if($2!~/^!|^*/){print &quot;(&quot;$1&quot;)&quot; &quot; 是一个未被锁定的账户，请管理员检查是否需要锁定它或者删除它。&quot;}}&apos; /etc/shadow echo -------------------------------------------------------------------------- more /etc/login.defs | grep -E &quot;PASS_MAX_DAYS&quot; | grep -v &quot;#&quot; |awk -F&apos; &apos; &apos;{if($2!=90){print &quot;/etc/login.defs里面的&quot;$1 &quot;设置的是&quot;$2&quot;天，请管理员改成90天。&quot;}}&apos; echo -------------------------------------------------------------------------- more /etc/login.defs | grep -E &quot;PASS_MIN_LEN&quot; | grep -v &quot;#&quot; |awk -F&apos; &apos; &apos;{if($2!=6){print &quot;/etc/login.defs里面的&quot;$1 &quot;设置的是&quot;$2&quot;个字符，请管理员改成6个字符。&quot;}}&apos; echo -------------------------------------------------------------------------- more /etc/login.defs | grep -E &quot;PASS_WARN_AGE&quot; | grep -v &quot;#&quot; |awk -F&apos; &apos; &apos;{if($2!=10){print &quot;/etc/login.defs里面的&quot;$1 &quot;设置的是&quot;$2&quot;天，请管理员将口令到期警告天数改成10天。&quot;}}&apos; echo -------------------------------------------------------------------------- grep TMOUT /etc/profile /etc/bashrc &gt; /dev/null|| echo &quot;未设置登录超时限制，请设置之，设置方法：在/etc/profile或者/etc/bashrc里面添加TMOUT=600参数&quot; echo ------------------------检查服务运行情况----------------------------------- if ps -elf |grep xinet |grep -v &quot;grep xinet&quot;;then echo &quot;xinetd 服务正在运行，请检查是否可以把xinnetd服务关闭&quot; else echo &quot;xinetd 服务未开启&quot; fi echo -------------------------------------------------------------------------- echo &quot;查看系统密码文件修改时间&quot; ls -ltr /etc/passwd echo -------------------------------------------------------------------------- echo &quot;查看是否开启了ssh服务&quot; if service sshd status | grep -E &quot;listening on|active \(running\)&quot;; then echo &quot;SSH服务已开启&quot; else echo &quot;SSH服务未开启&quot; fi echo -------------------------------------------------------------------------- echo &quot;查看是否开启了TELNET服务&quot; if more /etc/xinetd.d/telnetd 2&gt;&amp;1|grep -E &quot;disable=no&quot;; then echo &quot;TELNET服务已开启 &quot; else echo &quot;TELNET服务未开启 &quot; fi echo -------------------------------------------------------------------------- echo &quot;查看系统SSH远程访问设置策略(host.deny拒绝列表)&quot; if more /etc/hosts.deny | grep -E &quot;sshd: &quot;;more /etc/hosts.deny | grep -E &quot;sshd&quot;; then echo &quot;远程访问策略已设置 &quot; else echo &quot;远程访问策略未设置 &quot; fi echo -------------------------------------------------------------------------- echo &quot;查看系统SSH远程访问设置策略(hosts.allow允许列表)&quot; if more /etc/hosts.allow | grep -E &quot;sshd: &quot;;more /etc/hosts.allow | grep -E &quot;sshd&quot;; then echo &quot;远程访问策略已设置 &quot; else echo &quot;远程访问策略未设置 &quot; fi echo &quot;当hosts.allow和 host.deny相冲突时，以hosts.allow设置为准。&quot; echo ------------------------------------------------------------------------- echo &quot;查看shell是否设置超时锁定策略&quot; if more /etc/profile | grep -E &quot;TIMEOUT= &quot;; then echo &quot;系统设置了超时锁定策略 &quot; else echo &quot;未设置超时锁定策略 &quot; fi echo ------------------------------------------------------------------------- echo &quot;查看syslog日志审计服务是否开启&quot; if service syslog status | egrep &quot; active \(running&quot;;then echo &quot;syslog服务已开启&quot; else echo &quot;syslog服务未开启，建议通过service syslog start开启日志审计功能&quot; fi echo ------------------------------------------------------------------------- echo &quot;查看syslog日志是否开启外发&quot; if more /etc/rsyslog.conf | egrep &quot;@...\.|@..\.|@.\.|\*.\* @...\.|\*\.\* @..\.|\*\.\* @.\.&quot;;then echo &quot;客户端syslog日志已开启外发&quot; else echo &quot;客户端syslog日志未开启外发&quot; fi echo ------------------------------------------------------------------------- echo &quot;查看passwd文件中有哪些特权用户&quot; awk -F: &apos;$3==0 {print $1}&apos; /etc/passwd echo ------------------------------------------------------------------------ echo &quot;查看系统中是否存在空口令账户&quot; awk -F: &apos;($2==&quot;!!&quot;) {print $1}&apos; /etc/shadow echo &quot;该结果不适用于Ubuntu系统&quot; echo ------------------------------------------------------------------------ echo &quot;查看系统中root用户外连情况&quot; lsof -u root |egrep &quot;ESTABLISHED|SYN_SENT|LISTENING&quot; echo ----------------------------状态解释------------------------------ echo &quot;ESTABLISHED的意思是建立连接。表示两台机器正在通信。&quot; echo &quot;LISTENING的&quot; echo &quot;SYN_SENT状态表示请求连接&quot; echo ------------------------------------------------------------------------ echo &quot;查看系统中root用户TCP连接情况&quot; lsof -u root |egrep &quot;TCP&quot; echo ------------------------------------------------------------------------ echo &quot;查看系统中存在哪些非系统默认用户&quot; echo &quot;root:x:“该值大于500为新创建用户，小于或等于500为系统初始用户”&quot; more /etc/passwd |awk -F &quot;:&quot; &apos;{if($3&gt;500){print &quot;/etc/passwd里面的&quot;$1 &quot;的值为&quot;$3&quot;，请管理员确认该账户是否正常。&quot;}}&apos; echo ------------------------------------------------------------------------ echo &quot;检查系统守护进程&quot; more /etc/xinetd.d/rsync | grep -v &quot;^#&quot; echo ------------------------------------------------------------------------ echo &quot;检查系统是否存在入侵行为&quot; more /var/log/secure |grep refused echo ------------------------------------------------------------------------ echo &quot;-----------------------检查系统是否存在PHP脚本后门---------------------&quot; if find / -type f -name *.php | xargs egrep -l &quot;mysql_query\($query, $dbconn\)|专用网马|udf.dll|class PHPzip\{|ZIP压缩程序 荒野无灯修改版|$writabledb|AnonymousUserName|eval\(|Root_CSS\(\)|黑狼PHP木马|eval\(gzuncompress\(base64_decode|if\(empty\($_SESSION|$shellname|$work_dir |PHP木马|Array\(&quot;$filename&quot;| eval\($_POST\[|class packdir|disk_total_space|wscript.shell|cmd.exe|shell.application|documents and settings|system32|serv-u|提权|phpspy|后门&quot; |sort -n|uniq -c |sort -rn 1&gt;/dev/null 2&gt;&amp;1;then echo &quot;检测到PHP脚本后门&quot; find / -type f -name *.php | xargs egrep -l &quot;mysql_query\($query, $dbconn\)|专用网马|udf.dll|class PHPzip\{|ZIP压缩程序 荒野无灯修改版|$writabledb|AnonymousUserName|eval\(|Root_CSS\(\)|黑狼PHP木马|eval\(gzuncompress\(base64_decode|if\(empty\($_SESSION|$shellname|$work_dir |PHP木马|Array\(&quot;$filename&quot;| eval\($_POST\[|class packdir|disk_total_space|wscript.shell|cmd.exe|shell.application|documents and settings|system32|serv-u|提权|phpspy|后门&quot; |sort -n|uniq -c |sort -rn find / -type f -name *.php | xargs egrep -l &quot;mysql_query\($query, $dbconn\)|专用网马|udf.dll|class PHPzip\{|ZIP压缩程序 荒野无灯修改版|$writabledb|AnonymousUserName|eval\(|Root_CSS\(\)|黑狼PHP木马|eval\(gzuncompress\(base64_decode|if\(empty\($_SESSION|$shellname|$work_dir |PHP木马|Array\(&quot;$filename&quot;| eval\($_POST\[|class packdir|disk_total_space|wscript.shell|cmd.exe|shell.application|documents and settings|system32|serv-u|提权|phpspy|后门&quot; |sort -n|uniq -c |sort -rn |awk &apos;{print $2}&apos; | xargs -I{} cp {} /tmp/ echo &quot;后门样本已拷贝到/tmp/目录&quot; else echo &quot;未检测到PHP脚本后门&quot; fi echo ------------------------------------------------------------------------ echo &quot;-----------------------检查系统是否存在JSP脚本后门---------------------&quot; find / -type f -name *.jsp | xargs egrep -l &quot;InputStreamReader\(this.is\)|W_SESSION_ATTRIBUTE|strFileManag|getHostAddress|wscript.shell|gethostbyname|cmd.exe|documents and settings|system32|serv-u|提权|jspspy|后门&quot; |sort -n|uniq -c |sort -rn 2&gt;&amp;1 find / -type f -name *.jsp | xargs egrep -l &quot;InputStreamReader\(this.is\)|W_SESSION_ATTRIBUTE|strFileManag|getHostAddress|wscript.shell|gethostbyname|cmd.exe|documents and settings|system32|serv-u|提权|jspspy|后门&quot; |sort -n|uniq -c |sort -rn| awk &apos;{print $2}&apos; | xargs -I{} cp {} /tmp/ 2&gt;&amp;1 echo ------------------------------------------------------------------------ echo &quot;----------------------检查系统是否存在HTML恶意代码---------------------&quot; if find / -type f -name *.html | xargs egrep -l &quot;WriteData|svchost.exe|DropPath|wsh.Run|WindowBomb|a1.createInstance|CurrentVersion|myEncString|DropFileName|a = prototype;|204.351.440.495.232.315.444.550.64.330&quot; 1&gt;/dev/null 2&gt;&amp;1;then echo &quot;发现HTML恶意代码&quot; find / -type f -name *.html | xargs egrep -l &quot;WriteData|svchost.exe|DropPath|wsh.Run|WindowBomb|a1.createInstance|CurrentVersion|myEncString|DropFileName|a = prototype;|204.351.440.495.232.315.444.550.64.330&quot; |sort -n|uniq -c |sort -rn find / -type f -name *.html | xargs egrep -l &quot;WriteData|svchost.exe|DropPath|wsh.Run|WindowBomb|a1.createInstance|CurrentVersion|myEncString|DropFileName|a = prototype;|204.351.440.495.232.315.444.550.64.330&quot; |sort -n|uniq -c |sort -rn| awk &apos;{print $2}&apos; | xargs -I{} cp {} /tmp/ echo &quot;后门样本已拷贝到/tmp/目录&quot; else echo &quot;未检测到HTML恶意代码&quot; fi echo &quot;----------------------检查系统是否存在perl恶意程序----------------------&quot; if find / -type f -name *.pl | xargs egrep -l &quot;SHELLPASSWORD|shcmd|backdoor|setsockopt|IO::Socket::INET;&quot; 1&gt;/dev/null 2&gt;&amp;1;then echo &quot;发现perl恶意程序&quot; find / -type f -name *.pl | xargs egrep -l &quot;SHELLPASSWORD|shcmd|backdoor|setsockopt|IO::Socket::INET;&quot;|sort -n|uniq -c |sort -rn find / -type f -name *.pl | xargs egrep -l &quot;SHELLPASSWORD|shcmd|backdoor|setsockopt|IO::Socket::INET;&quot;|sort -n|uniq -c |sort -rn| awk &apos;{print $2}&apos; | xargs -I{} cp {} /tmp/ echo &quot;可疑样本已拷贝到/tmp/目录&quot; else echo &quot;未检测到perl恶意程序&quot; fi echo &quot;----------------------检查系统是否存在Python恶意程序----------------------&quot; find / -type f -name *.py | xargs egrep -l &quot;execCmd|cat /etc/issue|getAppProc|exploitdb&quot; |sort -n|uniq -c |sort -rn find / -type f -name *.py | xargs egrep -l &quot;execCmd|cat /etc/issue|getAppProc|exploitdb&quot; |sort -n|uniq -c |sort -rn| awk &apos;{print $2}&apos; | xargs -I{} cp {} /tmp/ echo ------------------------------------------------------------------------ echo &quot;-----------------------检查系统是否存在恶意程序---------------------&quot; find / -type f -perm -111 |xargs egrep &quot;UpdateProcessER12CUpdateGatesE6C|CmdMsg\.cpp|MiniHttpHelper.cpp|y4&apos;r3 1uCky k1d\!|execve@@GLIBC_2.0|initfini.c|ptmalloc_unlock_all2|_IO_wide_data_2|system@@GLIBC_2.0|socket@@GLIBC_2.0|gettimeofday@@GLIBC_2.0|execl@@GLIBC_2.2.5|WwW.SoQoR.NeT|2.6.17-2.6.24.1.c|Local Root Exploit|close@@GLIBC_2.0|syscall\(\__NR\_vmsplice,|Linux vmsplice Local Root Exploit|It looks like the exploit failed|getting root shell&quot; 2&gt;/dev/null echo ------------------------------------------------------------------------ echo &quot;检查网络连接和监听端口&quot; netstat -an echo &quot;--------------------------路由表、网络连接、接口信息--------------&quot; netstat -rn echo &quot;------------------------查看网卡详细信息--------------------------&quot; ifconfig -a echo ------------------------------------------------------------------------ echo &quot;查看正常情况下登录到本机的所有用户的历史记录&quot; last echo ------------------------------------------------------------------------ echo &quot;检查系统中core文件是否开启&quot; ulimit -c echo &quot;core是unix系统的内核。当你的程序出现内存越界的时候,操作系统会中止你的进程,并将当前内存状态倒出到core文件中,以便进一步分析，如果返回结果为0，则是关闭了此功能，系统不会生成core文件&quot; echo ------------------------------------------------------------------------ echo &quot;检查系统中关键文件修改时间&quot; ls -ltr /bin/ls /bin/login /etc/passwd /bin/ps /usr/bin/top /etc/shadow|awk &apos;{print &quot;文件名：&quot;$8&quot; &quot;&quot;最后修改时间：&quot;$6&quot; &quot;$7}&apos; echo &quot;ls文件：是存储ls命令的功能函数，被删除以后，就无法执行ls命令，黑客可利用篡改ls文件来执行后门或其他程序。 login文件：login是控制用户登录的文件，一旦被篡改或删除，系统将无法切换用户或登陆用户 user/bin/passwd是一个命令，可以为用户添加、更改密码，但是，用户的密码并不保存在/etc/passwd当中，而是保存在了/etc/shadow当中 etc/passwd是一个文件，主要是保存用户信息。 sbin/portmap是文件转换服务，缺少该文件后，无法使用磁盘挂载、转换类型等功能。 bin/ps 进程查看命令功能支持文件，文件损坏或被更改后，无法正常使用ps命令。 usr/bin/top top命令支持文件，是Linux下常用的性能分析工具,能够实时显示系统中各个进程的资源占用状况。 etc/shadow shadow 是 /etc/passwd 的影子文件，密码存放在该文件当中，并且只有root用户可读。&quot; echo -------------------------------------------------------------------------- echo &quot;-------------------查看系统日志文件是否存在--------------------&quot; log=/var/log/syslog log2=/var/log/messages if [ -e &quot;$log&quot; ]; then echo &quot;syslog日志文件存在！ &quot; else echo &quot;/var/log/syslog日志文件不存在！ &quot; fi if [ -e &quot;$log2&quot; ]; then echo &quot;/var/log/messages日志文件存在！ &quot; else echo &quot;/var/log/messages日志文件不存在！ &quot; fi echo -------------------------------------------------------------------------- echo &quot;检查系统文件完整性2(MD5检查)&quot; echo &quot;该项会获取部分关键文件的MD5值并入库，默认保存在/etc/md5db中&quot; echo &quot;如果第一次执行，则会提示md5sum: /sbin/portmap: 没有那个文件或目录&quot; echo &quot;第二次重复检查时，则会对MD5DB中的MD5值进行匹配，来判断文件是否被更改过&quot; file=&quot;/etc/md5db&quot; if [ -e &quot;$file&quot; ]; then md5sum -c /etc/md5db 2&gt;&amp;1; else md5sum /etc/passwd &gt;&gt;/etc/md5db md5sum /etc/shadow &gt;&gt;/etc/md5db md5sum /etc/group &gt;&gt;/etc/md5db md5sum /usr/bin/passwd &gt;&gt;/etc/md5db md5sum /sbin/portmap&gt;&gt;/etc/md5db md5sum /bin/login &gt;&gt;/etc/md5db md5sum /bin/ls &gt;&gt;/etc/md5db md5sum /bin/ps &gt;&gt;/etc/md5db md5sum /usr/bin/top &gt;&gt;/etc/md5db; fi echo ---------------------------------------------------------------------- echo &quot;------------------------主机性能检查--------------------------------&quot; echo &quot;CPU检查&quot; dmesg | grep -i cpu echo ----------------------------------------------------------------------- more /proc/cpuinfo echo ----------------------------------------------------------------------- echo &quot;内存状态检查&quot; vmstat 2 5 echo ----------------------------------------------------------------------- more /proc/meminfo echo ----------------------------------------------------------------------- free -m echo ----------------------------------------------------------------------- echo &quot;文件系统使用情况&quot; df -h echo ----------------------------------------------------------------------- echo &quot;网卡使用情况&quot; lspci -tv echo ---------------------------------------------------------------------- echo &quot;查看僵尸进程&quot; ps -ef | grep zombie echo ---------------------------------------------------------------------- echo &quot;耗CPU最多的进程&quot; ps auxf |sort -nr -k 3 |head -5 echo ---------------------------------------------------------------------- echo &quot;耗内存最多的进程&quot; ps auxf |sort -nr -k 4 |head -5 echo ---------------------------------------------------------------------- echo --------------------------------------------------------------------- echo &quot;COPY RIGHT &quot; echo &quot;QQ：&quot; echo ----------------------结束时间为------------------------------------- DATE=`date` echo &quot;Date is $DATE&quot; echo ----------------------------------------------------------------------]]></content>
      <categories>
        <category>Linux</category>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nmap简单使用的技巧]]></title>
    <url>%2F2018%2F04%2F19%2FNmap%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[nmap支持很多扫描技术，例如：UDP、TCP connect()、TCP SYN(半开扫描)、ftp代理(bounce攻击)、反向标志、ICMP、FIN、ACK扫描、圣诞树(Xmas Tree)、null扫描。nmap还提供了一些高级的特征，例如：通过TCP/IP协议栈特征探测操作系统类型，秘密扫描，动态延时和重传计算，并行扫描，通过并行ping扫描探测关闭的主机，诱饵扫描，避开端口过滤检测，直接RPC扫描(无须端口影射)，碎片扫描，以及灵活的目标和端口设定.nmap总会给出well known端口的服务名(如果可能)、端口号、状态和协议等信息。每个端口的状态有：open、filtered、 unfiltered。open状态意味着目标主机能够在这个端口使用accept()系统调用接受连接。filtered状态表示：防火墙、包过滤和其 它的网络安全软件掩盖了这个端口，禁止 nmap探测其是否打开。unfiltered表示：这个端口关闭，并且没有防火墙/包过滤软件来隔离nmap的探测企图。通常情况下，端口的状态基本都 是unfiltered状态，只有在大多数被扫描的端口处于filtered状态下，才会显示处于unfiltered状态的端口。根据使用的功能选 项，nmap也可以报告远程主机的下列特征：使用的操作系统、TCP序列、运行绑定到每个端口上的应用程序的用户名、DNS名、主机地址是否是欺骗地址、 以及其它一些东西。可以使用nmap -h快速列出功能选项的列表。[root@node1 ~]# nmap -h Nmap 6.40 ( http://nmap.org ) Usage: nmap [Scan Type(s)] [Options] {target specification} TARGET SPECIFICATION: Can pass hostnames, IP addresses, networks, etc. Ex: scanme.nmap.org, microsoft.com/24, 192.168.0.1; 10.0.0-255.1-254 -iL &lt;inputfilename&gt;: Input from list of hosts/networks -iR &lt;num hosts&gt;: Choose random targets --exclude &lt;host1[,host2][,host3],...&gt;: Exclude hosts/networks --excludefile &lt;exclude_file&gt;: Exclude list from file HOST DISCOVERY: -sL: List Scan - simply list targets to scan -sn: Ping Scan - disable port scan -Pn: Treat all hosts as online -- skip host discovery -PS/PA/PU/PY[portlist]: TCP SYN/ACK, UDP or SCTP discovery to given ports -PE/PP/PM: ICMP echo, timestamp, and netmask request discovery probes -PO[protocol list]: IP Protocol Ping -n/-R: Never do DNS resolution/Always resolve [default: sometimes] --dns-servers &lt;serv1[,serv2],...&gt;: Specify custom DNS servers --system-dns: Use OS&apos;s DNS resolver --traceroute: Trace hop path to each host SCAN TECHNIQUES: -sS/sT/sA/sW/sM: TCP SYN/Connect()/ACK/Window/Maimon scans -sU: UDP Scan -sN/sF/sX: TCP Null, FIN, and Xmas scans --scanflags &lt;flags&gt;: Customize TCP scan flags -sI &lt;zombie host[:probeport]&gt;: Idle scan -sY/sZ: SCTP INIT/COOKIE-ECHO scans -sO: IP protocol scan -b &lt;FTP relay host&gt;: FTP bounce scan PORT SPECIFICATION AND SCAN ORDER: -p &lt;port ranges&gt;: Only scan specified ports Ex: -p22; -p1-65535; -p U:53,111,137,T:21-25,80,139,8080,S:9 -F: Fast mode - Scan fewer ports than the default scan -r: Scan ports consecutively - don&apos;t randomize --top-ports &lt;number&gt;: Scan &lt;number&gt; most common ports --port-ratio &lt;ratio&gt;: Scan ports more common than &lt;ratio&gt; SERVICE/VERSION DETECTION: -sV: Probe open ports to determine service/version info --version-intensity &lt;level&gt;: Set from 0 (light) to 9 (try all probes) --version-light: Limit to most likely probes (intensity 2) --version-all: Try every single probe (intensity 9) --version-trace: Show detailed version scan activity (for debugging) SCRIPT SCAN: -sC: equivalent to --script=default --script=&lt;Lua scripts&gt;: &lt;Lua scripts&gt; is a comma separated list of directories, script-files or script-categories --script-args=&lt;n1=v1,[n2=v2,...]&gt;: provide arguments to scripts --script-args-file=filename: provide NSE script args in a file --script-trace: Show all data sent and received --script-updatedb: Update the script database. --script-help=&lt;Lua scripts&gt;: Show help about scripts. &lt;Lua scripts&gt; is a comma separted list of script-files or script-categories. OS DETECTION: -O: Enable OS detection --osscan-limit: Limit OS detection to promising targets --osscan-guess: Guess OS more aggressively TIMING AND PERFORMANCE: Options which take &lt;time&gt; are in seconds, or append &apos;ms&apos; (milliseconds), &apos;s&apos; (seconds), &apos;m&apos; (minutes), or &apos;h&apos; (hours) to the value (e.g. 30m). -T&lt;0-5&gt;: Set timing template (higher is faster) --min-hostgroup/max-hostgroup &lt;size&gt;: Parallel host scan group sizes --min-parallelism/max-parallelism &lt;numprobes&gt;: Probe parallelization --min-rtt-timeout/max-rtt-timeout/initial-rtt-timeout &lt;time&gt;: Specifies probe round trip time. --max-retries &lt;tries&gt;: Caps number of port scan probe retransmissions. --host-timeout &lt;time&gt;: Give up on target after this long --scan-delay/--max-scan-delay &lt;time&gt;: Adjust delay between probes --min-rate &lt;number&gt;: Send packets no slower than &lt;number&gt; per second --max-rate &lt;number&gt;: Send packets no faster than &lt;number&gt; per second FIREWALL/IDS EVASION AND SPOOFING: -f; --mtu &lt;val&gt;: fragment packets (optionally w/given MTU) -D &lt;decoy1,decoy2[,ME],...&gt;: Cloak a scan with decoys -S &lt;IP_Address&gt;: Spoof source address -e &lt;iface&gt;: Use specified interface -g/--source-port &lt;portnum&gt;: Use given port number --data-length &lt;num&gt;: Append random data to sent packets --ip-options &lt;options&gt;: Send packets with specified ip options --ttl &lt;val&gt;: Set IP time-to-live field --spoof-mac &lt;mac address/prefix/vendor name&gt;: Spoof your MAC address --badsum: Send packets with a bogus TCP/UDP/SCTP checksum OUTPUT: -oN/-oX/-oS/-oG &lt;file&gt;: Output scan in normal, XML, s|&lt;rIpt kIddi3, and Grepable format, respectively, to the given filename. -oA &lt;basename&gt;: Output in the three major formats at once -v: Increase verbosity level (use -vv or more for greater effect) -d: Increase debugging level (use -dd or more for greater effect) --reason: Display the reason a port is in a particular state --open: Only show open (or possibly open) ports --packet-trace: Show all packets sent and received --iflist: Print host interfaces and routes (for debugging) --log-errors: Log errors/warnings to the normal-format output file --append-output: Append to rather than clobber specified output files --resume &lt;filename&gt;: Resume an aborted scan --stylesheet &lt;path/URL&gt;: XSL stylesheet to transform XML output to HTML --webxml: Reference stylesheet from Nmap.Org for more portable XML --no-stylesheet: Prevent associating of XSL stylesheet w/XML output MISC: -6: Enable IPv6 scanning -A: Enable OS detection, version detection, script scanning, and traceroute --datadir &lt;dirname&gt;: Specify custom Nmap data file location --send-eth/--send-ip: Send using raw ethernet frames or IP packets --privileged: Assume that the user is fully privileged --unprivileged: Assume the user lacks raw socket privileges -V: Print version number -h: Print this help summary page. EXAMPLES: nmap -v -A scanme.nmap.org nmap -v -sn 192.168.0.0/16 10.0.0.0/8 nmap -v -iR 10000 -Pn -p 80 SEE THE MAN PAGE (http://nmap.org/book/man.html) FOR MORE OPTIONS AND EXAMPLES [root@node1 ~]# 参考nmap中文网一、nmap安装1.1 Centos 系统安装nmapyum -y install nmap 1.2 查看安装版本[root@node1 ~]# nmap -version Nmap version 6.40 ( http://nmap.org ) Platform: x86_64-redhat-linux-gnu Compiled with: nmap-liblua-5.2.2 openssl-1.0.2k libpcre-8.32 libpcap-1.5.3 nmap-libdnet-1.12 ipv6 Compiled without: Available nsock engines: epoll poll select [root@node1 ~]# 二、nmap常用命令2.1 基础命令nmap 172.31.8.8 ---扫描单个主机 nmap 172.31.8.0/24 ---扫描整个子网 nmap 172.31.8.8 172.31.8.13 ---扫描多个目标 nmap 172.31.8.8-20 ---扫描一个指定范围内的目标 nmap -iL pinglist.txt ---如果有一个IP地址列表，将这些IP保存在一个pinglist.txt文件内，使用nmap -iL iplist.txt 扫描指定文件内的目标 list 例： [root@node1 ~]# cat pinglist.txt 172.31.8.2 172.31.8.3 172.31.8.75 172.31.8.107 [root@node1 ~]# nmap -iL pinglist.txt Starting Nmap 6.40 ( http://nmap.org ) at 2019-07-20 17:13 CST Nmap scan report for 172.31.8.3 Host is up (0.0034s latency). Not shown: 995 filtered ports PORT STATE SERVICE 135/tcp open msrpc 139/tcp open netbios-ssn 445/tcp open microsoft-ds 3389/tcp open ms-wbt-server 5357/tcp open wsdapi MAC Address: 50:7B:9D:99:AA:D9 (Unknown) Nmap scan report for node4 (172.31.8.75) Host is up (0.000022s latency). Not shown: 999 closed ports PORT STATE SERVICE 22/tcp open ssh MAC Address: 00:0C:29:E3:5F:D2 (VMware) Nmap scan report for node3 (172.31.8.107) Host is up (0.000066s latency). Not shown: 999 closed ports PORT STATE SERVICE 22/tcp open ssh MAC Address: 00:0C:29:9A:43:BC (VMware) Nmap done: 4 IP addresses (3 hosts up) scanned in 5.15 seconds [root@node1 ~]# nmap 172.31.8.0/24 -exclude 172.31.8.8 ---扫描172.31.8.0/24 这个子网除172.31.8.8以外的所有IP nmap 172.31.8/0/24 -exclude iplist.txt ---扫描172.31.8.0/24 这个子网所有的IP，排除iplist.txt这个文件内列出的IP nmap -p8080,22 172.31.8.8 ---扫描特定主机上的8080，22端口 2.2 深入探究nmap -sS 172.31.8.8 ---SYN扫描，指定IP/IP范围指定扫描端口:nmap -sS 172.31.8.8 -p 8080 nmap -sP 172.31.8.0/24 ---扫描存活主机,可以添加 | grep up 参数过滤存活主机:nmap -sP 172.31.8.0/24 | grep up nmap -sV 172.31.8.8 -p 8080 ---扫描主机的8080端口的服务和服务版本 nmap -O 172.31.8.8 ---扫描目标主机的系统版本 nmap -A 172.31.8.8 ---扫描目标主机，-A参数包括:-sV、-O 系统全面检测、启动脚本检测、扫描等操作 nmap -PO 172.31.8.8 ---扫描之前不使用ping操作，适用于禁ping的系统和设备 nmap -v 172.31.8.8 ---显示目标主机上详细信息 例： [root@node1 ~]# nmap -v 172.31.8.8 Starting Nmap 6.40 ( http://nmap.org ) at 2019-07-20 17:15 CST Initiating SYN Stealth Scan at 17:15 Scanning node1 (172.31.8.8) [1000 ports] Discovered open port 8080/tcp on 172.31.8.8 adjust_timeouts2: packet supposedly had rtt of 1428142253061189 microseconds. Ignoring time. adjust_timeouts2: packet supposedly had rtt of 1428142253061189 microseconds. Ignoring time. Discovered open port 22/tcp on 172.31.8.8 adjust_timeouts2: packet supposedly had rtt of 1428142253061166 microseconds. Ignoring time. adjust_timeouts2: packet supposedly had rtt of 1428142253061166 microseconds. Ignoring time. Discovered open port 8009/tcp on 172.31.8.8 adjust_timeouts2: packet supposedly had rtt of 1428142274531622 microseconds. Ignoring time. adjust_timeouts2: packet supposedly had rtt of 1428142274531622 microseconds. Ignoring time. Completed SYN Stealth Scan at 17:15, 0.01s elapsed (1000 total ports) Nmap scan report for node1 (172.31.8.8) Host is up (0.0000010s latency). Not shown: 997 closed ports PORT STATE SERVICE 22/tcp open ssh 8009/tcp open ajp13 8080/tcp open http-proxy Read data files from: /usr/bin/../share/nmap Nmap done: 1 IP address (1 host up) scanned in 0.03 seconds Raw packets sent: 1000 (44.000KB) | Rcvd: 2003 (84.132KB) [root@node1 ~]# nmap -T4 -sP 172.31.8.0/24 &amp;&amp; egrep &quot;00:00:00:00:00:00&quot; /proc/net/arp | grep Unknown ---扫描子网上未使用的IP nmap -PN -T4 -p139,445 -n -v --script=smb-check-vulns --script-args safe=1 172.31.8.0/24 ---在子网中探测Conficker 蠕虫病毒 nmap -F -O 172.31.8.0/24 | grep &quot;Running: &quot; &gt; /tmp/os; echo &quot;$(cat /tmp/os | grep Linux | wc -l) Linux device(s)&quot;; echo &quot;$(cat /tmp/os | grep Windows | wc -l) Window(s) device&quot; ---扫描子网中存在的Linux、windows设备数量 nmap是一款非常强大的扫描工具，以上的命令基本都是比较常用的命令，如果想深入了解nmap的功能，可以自己去研究一下。]]></content>
      <categories>
        <category>安全</category>
        <category>Nmap</category>
      </categories>
      <tags>
        <tag>安全</tag>
        <tag>Nmap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[memcache服务器搭建]]></title>
    <url>%2F2018%2F02%2F19%2Fmemcache%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[一、memcache简介Memcache是什么Memcache是danga.com的一个项目，最早是为 LiveJournal 服务的，目前全世界不少人使用这个缓存项目来构建自己大负载的网站，来分担数据库的压力。它可以应对任意多个连接，使用非阻塞的网络IO。由于它的工作机制是在内存中开辟一块空间，然后建立一个HashTable，Memcached自管理这些HashTable。Memcache官方网站,更多详细的信息可以来这里了解为什么会有Memcache和memcached两种名称？其实Memcache是这个项目的名称，而memcached是它服务器端的主程序文件名。一个是项目名称，一个是主程序文件名，不要混用了。二、Memcache的安装安装分为两个过程：memcache服务器端的安装和memcached客户端的安装。所谓服务器端的安装就是在服务器（一般都是linux系统）上安装Memcache实现数据的存储所谓客户端的安装就是指php（或者其他程序，Memcache还有其他不错的api接口提供）去使用服务器端的Memcache提供的函数，需要php添加扩展。2.1、memcache服务器的安装这里安装memcache需要指定libevent，查看系统是否已经安装libeventrpm -qa | grep libevent 如果已经有，先进行升级yum -y install libevent 测试libevent是否已经安装成功ll /usr/share/doc/ | grep libevent 可以看到有已经安装类包进行安装memchache （到官网下载自己需要的软件版本）解压文件并将文件移动到 /usr/local/ 目录下进入memcache目录进行安装可能会有一个报错因为libevent这个包是系统默认安装的，没有安装相应的开发所用的头文件，所以需要使用以下命令进行安装再次编译即可通过，编译通过后执行 make &amp;&amp; make install命令进行安装启动memcache/usr/local/memcached/bin/memcached -d -m 128 -l 172.31.8.50 -p 11211 -u root 进行连接测试telnet 172.31.8.50 11211 #出现以下内容即为安装成功 输出数据的格式如下：set foo 0 0 3 bar 如果保存成功，控制台会输出STORED获取数据的命令格式如下get foo 在控制台的输出信息如下链接到memcache后输入stats可以获得包括资源利用率在内的个种信息此外输入”stats items”可以获得关于缓存记录的信息，推出程序输入“quit”这些参数的具体含义可以参考下面的列表]]></content>
      <categories>
        <category>Linux</category>
        <category>memcache</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>memcache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis集群构建（伪集群）]]></title>
    <url>%2F2018%2F02%2F13%2Fredis%E9%9B%86%E7%BE%A4%E6%9E%84%E5%BB%BA%EF%BC%88%E4%BC%AA%E9%9B%86%E7%BE%A4%EF%BC%89%2F</url>
    <content type="text"><![CDATA[简介：用两个虚拟机模拟6个redis节点，一台机器三个节点，创建3个master、3个salve节点。redis采用3.2.4两台机器都是centos6.8，分别为172.31.8.102、172.31.8.24一、安装过程1、下载并解压[root@localhost ~]# mkdir /software [root@localhost software]#wget http://download.redis.io/releases/redis-3.2.4.tar.gz [root@localhost software]# tar -zxvf redis-3.2.4.tar.gz 2、编译安装[root@localhost software]# cd redis-3.2.4 [root@localhost redis-3.2.4]# make &amp;&amp; make install 3、将redis-trib.rb 复制到/usr/local/bin/[root@localhost redis-3.2.4]# ll src/redis-trib.rb -rwxrwxr-x. 1 root root 60852 9月 26 2016 src/redis-trib.rb [root@localhost redis-3.2.4]# cp src/redis-trib.rb /usr/local/bin/ 4、创建redis节点首先在172.31.8.102节点上/software/redis-3.2.4目录下创建redis_cluster目录[root@localhost redis-3.2.4]# mkdir redis_cluster 在redis_cluster目录下创建7000、7001、7002目录，并把redis.conf文件copy到这三个目录中[root@localhost redis_cluster]# mkdir 7000 7001 7002 [root@localhost redis-3.2.4]# cp redis.conf redis_cluster/7000/ [root@localhost redis-3.2.4]# cp redis.conf redis_cluster/7001/ [root@localhost redis-3.2.4]# cp redis.conf redis_cluster/7002/ 分别修改三个文件port 7000 //端口7000,7002,7003 bind 本机ip //默认ip为127.0.0.1 需要改为其他节点机器可访问的ip 否则创建集群时无法访问对应的端口，无法创建集群 daemonize yes //redis后台运行 pidfile /var/run/redis_7000.pid //pidfile文件对应7000,7001,7002 cluster-enabled yes //开启集群 把注释#去掉 cluster-config-file nodes_7000.conf //集群的配置 配置文件首次启动自动生成 7000,7001,7002 cluster-node-timeout 15000 //请求超时 默认15秒，可自行设置 appendonly yes //aof日志开启 有需要就开启，它会每次写操作都记录一条日志 接着在另一台机器上（172.31.8.24）重复操作以上四步，只是把目录改为7003、7004、7005，对应的配置文件也按照相应的规则修改即可5、启动各个节点在第一台机器上操作[root@localhost redis-3.2.4]# redis-server redis_cluster/7000/redis.conf [root@localhost redis-3.2.4]# redis-server redis_cluster/7001/redis.conf [root@localhost redis-3.2.4]# redis-server redis_cluster/7002/redis.conf 在第二台机器上操作[root@localhost redis-3.2.4]# redis-server redis_cluster/7003/redis.conf [root@localhost redis-3.2.4]# redis-server redis_cluster/7004/redis.conf [root@localhost redis-3.2.4]# redis-server redis_cluster/7005/redis.conf 6、检查redis启动情况第一台机器第二台机器7、创建集群redis官方提供了redis-trib.rb工具，就在已解压的src目录中，第三步已经将它拷贝到了/usr/local/bin/目录中，可以在命令行中使用了，使用以下命令创建集群：使用这个工具需要ruby，使用yum安装即可：yum -y install ruby ruby-devel rubygems rpm-build [root@localhost redis-3.2.4]# redis-trib.rb create --replicas 1 172.31.8.102:7000 172.31.8.102:7001 172.31.8.102:7002 172.31.8.24:7003 172.31.8.24:7004 172.31.8.24:7005 前三个IP:port为第一个节点，后面三个为第二个节点可能会出现的报错：这是因为ruby版本较低。yum安装的版本是1.8.7，但是redis需要的是1.9.3或者更高[root@localhost bin]# gem sources -a https://ruby.taobao.org/ [root@localhost bin]# gem install redis --version 3.0.0 之后再运行redis-trib.rb，会出现如下提示：输入“yes”回车即可，然后出现如下内容，说明安装成功二、集群验证在第一台机器上连接集群的7002端口的节点，在另外一台连接7005节点，连接方式为 redis-cli -h 172.31.8.102 -c -p 7002,加参数 -c 可连接到集群，因为上面 redis.conf 将 bind 改为了ip地址，所以 -h 参数不可以省略。在7005节点执行命令：然后在另外一台7002端口,查看key为hello的内容,get hello,执行结果如下：说明集群运作正常三、原理简介：redis cluster在设计的时候，就考虑到了去中心化,去中间件,也就是说,集群中的每个节点都是平等的关系,都是对等的,每个节点都保存各自的数据和整个集群的状态,每个节点都和其他所有节点连接而且这些连接保持活跃这样就保证了我们只需要连接集群中的任意一个节点,就可以获取到其他节点的数据.Redis 集群没有并使用传统的一致性哈希来分配数据，而是采用另外一种叫做哈希槽(hash slot)方式来分配的。rediscluster默认分配了16384个slot,当我们set一个key时,会用CRC16算法来取模得到所属的slot,然后将这个key 分到哈希槽区间的节点上,具体算法就是：CRC16(key) % 16384,所以我们在测试的时候看到set 和 get 的时候，直接跳转到了7000端口的节点.Redis集群会把数据存在一个master节点,然后在这个master和其对应的salve之间进行数据同步.当读取数据时,也根据一致性哈希算法到对应的master节点获取数据,只有当一个master 挂掉之后，才会启动一个对应的salve节点,充当 master.需要注意的是：必须要3个或以上的主节点，否则在创建集群时会失败，并且当存活的主节点数小于总节点数的一半时，整个集群就无法提供服务了。]]></content>
      <categories>
        <category>Linux</category>
        <category>redis</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[批量ping存活主机]]></title>
    <url>%2F2017%2F11%2F17%2F%E6%89%B9%E9%87%8Fping%E5%AD%98%E6%B4%BB%E4%B8%BB%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[创建一个ip.txt文件，把需要测试IP地址写入文档创建一个ping.sh 的shell 脚本，并修改ip.txt 文件路径#!/bin/bash for ips in `cat /root/manager/script/ip.txt` do result=`ping -w 2 -c 3 ${ips} | grep packet | awk -F&quot; &quot; &apos;{print $6}&apos;| awk -F&quot;%&quot; &apos;{print $1}&apos;| awk -F&apos; &apos; &apos;{print $1}&apos;` if [ $result -eq 0 ]; then echo &quot;&quot;${ips}&quot; is ok !&quot; else echo &quot;&quot;${ips}&quot; is not connected .....&quot; fi done 给脚本执行权限 chmod +x ping.sh执行脚本[root@k8s-node1 script]# ./ping.sh 172.31.8.101 is ok ! 172.31.8.192 is ok ! 172.31.8.42 is ok ! 172.31.8.176 is ok ! 172.31.8.45 is ok ! [root@k8s-node1 script]#]]></content>
      <categories>
        <category>Linux</category>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql性能的检查和调优方法]]></title>
    <url>%2F2017%2F08%2F20%2Fmysql%E6%80%A7%E8%83%BD%E7%9A%84%E6%A3%80%E6%9F%A5%E5%92%8C%E8%B0%83%E4%BC%98%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[我一直是使用mysql这个数据库软件，它工作比较稳定，效率也很高。在遇到严重性能问题时，一般都有这么几种可能：1、索引没有建好；2、sql写法过于复杂；3、配置错误；4、机器实在负荷不了；1、索引没有建好如果看到mysql消耗的cpu很大，可以用mysql的client工具来检查。在linux下执行/usr/local/mysql/bin/mysql -hlocalhost -uroot -p 输入密码，如果没有密码，则不用-p参数就可以进到客户端界面中。看看当前的运行情况show full processlist 可以多运行几次这个命令可以看到当前正在执行的sql语句，它会告知执行的sql、数据库名、执行的状态、来自的客户端ip、所使用的帐号、运行时间等信息在我的cache后端，这里面大部分时间是看不到显示任何sql语句的，我认为这样才算比较正常。如果看到有很多sql语句，那么这台mysql就一定会有性能问题如果出现了性能问题，则可以进行分析：1、是不是有sql语句卡住了？这是出现比较多的情况，如果数据库是采用myisam，那么有可能有一个写入的线程会把数据表给锁定了，如果这条语句不结束，则其它语句也无法运行。查看processlist里的time这一项，看看有没有执行时间很长的语句，要留意这些语句。2、大量相同的sql语句正在执行如果出现这种情况，则有可能是该sql语句执行的效率低下，同样要留意这些语句。然后把你所怀疑的语句统统集合一下，用desc（explain）来检查这些语句。首先看看一个正常的desc输出：mysql&gt; desc select * from imgs where imgid=1651768337; +—-+————-+——-+——-+—————+———+———+——-+——+——-+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +—-+————-+——-+——-+—————+———+———+——-+——+——-+ | 1 | SIMPLE | imgs | const | PRIMARY | PRIMARY | 8 | const | 1 | | +—-+————-+——-+——-+—————+———+———+——-+——+——-+ 1 row in set (0.00 sec) 注意key、rows和Extra这三项，这条语句返回的结果说明了该sql会使用PRIMARY主键索引来查询，结果集数量为1条，Extra没有显 示，证明没有用到排序或其他操作。由此结果可以推断，mysql会从索引中查询imgid=1651768337这条记录，然后再到真实表中取出所有字 段，是很简单的操作。key是指明当前sql会使用的索引，mysql执行一条简单语句时只能使用到一条索引，注意这个限制；rows是返回的结果集大小，结果集就是使用该索引进行一次搜索的所有匹配结果；Extra一般会显示查询和排序的方式，。如果没有使用到key，或者rows很大而用到了filesort排序，一般都会影响到效率，例如：mysql&gt; desc select * from imgs where userid=”7mini” order by clicks desc limit 10; +—-+————-+——-+——+—————+——+———+——+——-+—————————–+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +—-+————-+——-+——+—————+——+———+——+——-+—————————–+ | 1 | SIMPLE | imgs | ALL | NULL | NULL | NULL | NULL | 12506 | Using where; Using filesort | +—-+————-+——-+——+—————+——+———+——+——-+—————————–+ 1 row in set (0.00 sec) 这条sql结果集会有12506条，用到了filesort，所以执行起来会非常消耗效率的。这时mysql执行时会把整个表扫描一遍，一条一条去找到匹 配userid=”7mini”的记录，然后还要对这些记录的clicks进行一次排序，效率可想而知。真实执行时如果发现还比较快的话，那是因为服务器 内存还足够将12506条比较短小的记录全部读入内存，所以还比较快，但是并发多起来或者表大起来的话，效率问题就严重了。这时我把userid加入索引：create index userid on imgs (userid); 然后再检查：mysql&gt; desc select * from imgs where userid=”7mini” order by clicks desc limit 10; +—-+————-+——-+——+—————+——–+———+——-+——+—————————–+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +—-+————-+——-+——+—————+——–+———+——-+——+—————————–+ | 1 | SIMPLE | imgs | ref | userid | userid | 51 | const | 8 | Using where; Using filesort | +—-+————-+——-+——+—————+——–+———+——-+——+—————————–+ 1 row in set (0.00 sec) 嗯，这时可以看到mysql使用了userid这个索引搜索了，用userid索引一次搜索后，结果集有8条。然后虽然使用了filesort一条一条排序，但是因为结果集只有区区8条，效率问题得以缓解。但是，如果我用别的userid查询，结果又会有所不同：mysql&gt; desc select * from imgs where userid=”admin” order by clicks desc limit 10; +—-+————-+——-+——+—————+——–+———+——-+——+—————————–+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +—-+————-+——-+——+—————+——–+———+——-+——+—————————–+ | 1 | SIMPLE | imgs | ref | userid | userid | 51 | const | 2944 | Using where; Using filesort | +—-+————-+——-+——+—————+——–+———+——-+——+—————————–+ 1 row in set (0.00 sec) 这个结果和userid=”7mini”的结果基本相同，但是mysql用userid索引一次搜索后结果集的大小达到2944条，这2944条记录都会 加入内存进行filesort，效率比起7mini那次来说就差很多了。这时可以有两种办法可以解决，第一种办法是再加一个索引和判断条件，因为我只需要 根据点击量取最大的10条数据，所以有很多数据我根本不需要加进来排序，比如点击量小于10的，这些数据可能占了很大部分。我对clicks加一个索引，然后加入一个where条件再查询：create index clicks on imgs(clicks); mysql&gt; desc select * from imgs where userid=”admin” order by clicks desc limit 10; +—-+————-+——-+——+—————+——–+———+——-+——+—————————–+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +—-+————-+——-+——+—————+——–+———+——-+——+—————————–+ | 1 | SIMPLE | imgs | ref | userid,clicks | userid | 51 | const | 2944 | Using where; Using filesort | +—-+————-+——-+——+—————+——–+———+——-+——+—————————–+ 1 row in set (0.00 sec) 这时可以看到possible_keys变成了userid,clicks，possible_keys是可以匹配的所有索引，mysql会从 possible_keys中自己判断并取用其中一个索引来执行语句，值得注意的是，mysql取用的这个索引未必是最优化的。这次查询mysql还是使 用userid这个索引来查询的，并没有按照我的意愿，所以结果还是没有什么变化。改一下sql加上use index强制mysql使用clicks索引：mysql&gt; desc select * from imgs use index (clicks) where userid=’admin’ and clicks&gt;10 order by clicks desc limit 10 +—-+————-+——-+——-+—————+——–+———+——+——+————-+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +—-+————-+——-+——-+—————+——–+———+——+——+————-+ | 1 | SIMPLE | imgs | range | clicks | clicks | 4 | NULL | 5455 | Using where | +—-+————-+——-+——-+—————+——–+———+——+——+————-+ 1 row in set (0.00 sec) 这时mysql用到了clicks索引进行查询，但是结果集比userid还要大！看来还要再进行限制：mysql&gt; desc select * from imgs use index (clicks) where userid=’admin’ and clicks&gt;1000 order by clicks desc limit 10 +—-+————-+——-+——-+—————+——–+———+——+——+————-+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +—-+————-+——-+——-+—————+——–+———+——+——+————-+ | 1 | SIMPLE | imgs | range | clicks | clicks | 4 | NULL | 312 | Using where | +—-+————-+——-+——-+—————+——–+———+——+——+————-+ 1 row in set (0.00 sec) 加到1000的时候结果集变成了312条，排序效率应该是可以接受。不过，采用换索引这种优化方式需要取一个采样点，比如这个例子中的1000这个数字，这样，对userid的每个数值，都要去找一个采样点，这样对程序来 说是很难办的。如果按1000取样的话，那么userid=’7mini’这个例子中，取到的结果将不会是8条，而是2条，给用户造成了困惑。当然还有另一种办法，加入双索引：create index userid_clicks on imgs (userid, clicks) mysql&gt; desc select * from imgs where userid=”admin” order by clicks desc limit 10; +—-+————-+——-+——+———————-+—————+———+——-+——+————-+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +—-+————-+——-+——+———————-+—————+———+——-+——+————-+ | 1 | SIMPLE | imgs | ref | userid,userid_clicks | userid_clicks | 51 | const | 2944 | Using where | +—-+————-+——-+——+———————-+—————+———+——-+——+————-+ 1 row in set (0.00 sec) 这时可以看到，结果集还是2944条，但是Extra中的filesort不见了。这时mysql使用userid_clicks这个索引去查询，这不但 能快速查询到userid=”admin”的所有记录，并且结果是根据clicks排好序的！所以不用再把这个结果集读入内存一条一条排序了，效率上会高 很多。但是用多字段索引这种方式有个问题，如果查询的sql种类很多的话，就得好好规划一下了，否则索引会建得非常多，不但会影响到数据insert和update的效率，而且数据表也容易损坏。以上是对索引优化的办法，因为原因可能会比较复杂，所以写得比较的长，一般好好优化了索引之后，mysql的效率会提升n个档次，从而也不需要考虑增加机器来解决问题了。但是，mysql甚至所有数据库，可能都不好解决limit的问题。在mysql中，limit 0,10只要索引合适，是没有问题的，但是limit 100000,10就会很慢了，因为mysql会扫描排好序的结果，然后找到100000这个点，取出10条返回。要找到100000这个点，就要扫描 100000条记录，这个循环是比较耗时的。不知道会不会有什么好的算法可以优化这个扫描引擎，我冥思苦想也想不出有什么好办法。对于limit，目前直 至比较久远的将来，我想只能通过业务、程序和数据表的规划来优化，我想到的这些优化办法也都还没有一个是万全之策，往后再讨论。2、sql写法过于复杂sql写法假如用到一些特殊的功能，比如groupby、或者多表联合查询的话，mysql用到什么方式来查询也可以用desc来分析，我这边用复杂sql的情况还不算多，所以不常分析，暂时就没有好的建议。3、配置错误配置里主要参数是key_buffer、sort_buffer_size/myisam_sort_buffer_size，这两个参数意思是：key_buffer=128M：全部表的索引都会尽可能放在这块内存区域内，索引比较大的话就开稍大点都可以，我一般设为128M，有个好的建议是把很少用到并且比较大的表想办法移到别的地方去，这样可以显著减少mysql的内存占用。sort_buffer_size=1M：单个线程使用的用于排序的内存，查询结果集都会放进这内存里，如果比较小，mysql会多放几次，所以稍微开大一点就可以了，重要是优化好索引和查询语句，让他们不要生成太大的结果集。另外一些配置：thread_concurrency=8：这个配置标配=cpu数量x2interactive_timeout=30wait_timeout=30：这两个配置使用10-30秒就可以了，这样会尽快地释放内存资源，注意：一直在使用的连接是不会断掉的，这个配置只是断掉了长时间不动的连接。query_cache：这个功能不要使用，现在很多人看到cache这几个字母就像看到了宝贝，这是不唯物主义的。mysql的query_cache 在每次表数据有变化的时候都会重新清理连至该表的所有缓存，如果更新比较频繁，query_cache不但帮不上忙，而且还会对效率影响很大。这个参数只 适合只读型的数据库，如果非要用，也只能用query_cache_type=2自行用SQL_CACHE指定一些sql进行缓存。max_connections：默认为100，一般情况下是足够用的，但是一般要开大一点，开到400-600就可以了，能超过600的话一般就有效率问题，得另找对策，光靠增加这个数字不是办法。其它配置可以按默认就可以了，个人觉得问题还不是那么的大，提醒一下：1、配置虽然很重要，但是在绝大部分情况下都不是效率问题的罪魁祸首。2、mysql是一个数据库，对于数据库最重要考究的不应是效率，而是稳定性和数据准确性。4、机器实在负荷不了如果做了以上调整，服务器还是不能承受，那就只能通过架构级调整来优化了。1、mysql同步。通过mysql同步功能将数据同步到数台从数据库，由主数据库写入，从数据库提供读取。我个人不是那么乐意使用mysql同步，因为这个办法会增加程序的复杂性，并常常会引起数据方面的错误。在高负荷的服务中，死机了还可以快速重启，但数据错误的话要恢复就比较麻烦。2、加入缓存加入缓存之后，就可以解决并发的问题，效果很明显。如果是实时系统，可以考虑用刷新缓存方式使缓存保持最新。在前端加入squid的架构比较提倡使用，在命中率比较高的应用中，基本上可以解决问题。如果是在程序逻辑层里面进行缓存，会增加很多复杂性，问题会比较多而且难解决，不建议在这一层面进行调整。3、程序架构调整，支持同时连接多个数据库如果web加入缓存后问题还是比较严重，只能通过程序架构调整，把应用拆散，用多台的机器同时提供服务。如果拆散的话，对业务是有少许影响，如果业务当中有部分功能必须使用所有的数据，可以用一个完整库+n个分散库这样的架构，每次修改都在完整库和分散库各操作一次，或定期整理完整库。当然，还有一种最笨的，把数据库整个完完整整的做拷贝，然后程序每次都把完整的sql在这些库执行一遍，访问时轮询访问，我认为这样要比mysql同步的方式安全。4、使用 mysql proxy 代理mysql proxy 可以通过代理把数据库中的各个表分散到数台服务器，但是它的问题是没有能解决热门表的问题，如果热门内容散在多个表中，用这个办法是比较轻松就能解决问题。我没有用过这个软件也没有认真查过，不过我对它的功能有一点点怀疑，就是它怎么实现多个表之间的联合查询？如果能实现，那么效率如何呢？5、使用memcachedb数据库换用支持mysql的memcachedb，是可以一试的想法，从memcachedb的实现方式和层面来看对数据没有什么影响，不会对用户有什么困扰。为我现在因为数据库方面问题不多，没有试验过这个玩意。不过，只要它支持mysql的大部分主要的语法，而且本身稳定，可用性是无需置疑的。]]></content>
      <categories>
        <category>Linux</category>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[快速清除MySQL数据库的密码]]></title>
    <url>%2F2017%2F08%2F19%2F%E5%BF%AB%E9%80%9F%E6%B8%85%E9%99%A4MySQL%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%AF%86%E7%A0%81%2F</url>
    <content type="text"><![CDATA[关闭mysql数据库：service mysqld stop &amp; mysqladmin shutdown 跳过mysql服务器授权mysqld_safe --skip-grant-tables --skip-networking &amp; 登录数据库：mysql 打开mysql库：use mysql 更新数据库密码：update user set password=password (&quot;新密码&quot;) where user=&quot;root&quot;; 更新用户权限使其立即生效：flush privileges; 退出数据库：exit; 重新启动mysql数据库：service mysqld start]]></content>
      <categories>
        <category>Linux</category>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL索引管理]]></title>
    <url>%2F2017%2F08%2F13%2FMySQL%E7%B4%A2%E5%BC%95%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[1、重建索引命令mysql&amp;gt; REPAIR TABLE tbl_name QUICK; 2、查询数据表索引mysql&amp;gt; SHOW INDEX FROM tbl_name; 3、创建索引（PRIMARY KEY，INDEX，UNIQUE）支持创建主键索引，联合索引和普通索引命令mysql&amp;gt;ALTER TABLE tbl_name ADD INDEX index_name (column list);mysql&amp;gt;ALTER TABLE tbl_name ADD UNIQUE index_name (column list);mysql&amp;gt;ALTER TABLE tbl_name ADD PRIMARY KEY index_name (column list); 4、删除索引（PRIMARY KEY，INDEX，UNIQUE）支持删除主键索引，联合索引和普通索引命令mysql&amp;gt;ALTER TABLE tbl_name DROP INDEX index_name (column list);mysql&amp;gt;ALTER TABLE tbl_name DROP UNIQUE index_name (column list);mysql&amp;gt;ALTER TABLE tbl_name DROP PRIMARY KEY index_name (column list); 其中 tbl_name 表示数据表名，index_name 表示索引名，column list 表示字段列表]]></content>
      <categories>
        <category>Linux</category>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux服务器制定mysql数据库备份的计划任务]]></title>
    <url>%2F2017%2F08%2F11%2FLinux%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%88%B6%E5%AE%9Amysql%E6%95%B0%E6%8D%AE%E5%BA%93%E5%A4%87%E4%BB%BD%E7%9A%84%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[首先，创建一个shell脚本：#!/bin/bash mysql_pwd=&quot;1234567890&quot; mysql_dump=&quot;/usr/local/mysql/bin/mysqldump&quot; cur_year=$(date +&quot;%Y&quot;) cur_month=$(date +&quot;%m&quot;) cur_day=$(date +&quot;%d&quot;) #dump_path=&quot;/data0/mysql_backup/$cur_year-$cur_month/$cur_day&quot; arr_databases=( &quot;db1&quot; &quot;db2&quot; &quot;db3&quot; &quot;db4&quot; ) for cur_database in ${arr_databases[*]}; do #mkdir backup path dump_path=&quot;/data0/mysql_backup/$cur_database&quot; if [ ! -d &quot;$dump_path&quot; ]; then mkdir -p &quot;$dump_path&quot; fi #backup database $mysql_dump -uroot -p$mysql_pwd $cur_database | gzip &gt; $dump_path/$cur_database-$cur_year-$cur_month-$cur_day.sql.gz #Delete backup files 10 days ago cd $dump_path rm -rf `find . -name &apos;*.sql.gz&apos; -mtime 20` done 可以保存到路径：/data0/scripts/backup_database.sh设置可执行权限 cd /data0/scripts/ chmod +x * 添加计划任务vi /etc/crontab 添加命令： 01 1 * * * root /data0/scripts/backup_database.sh #每天的01点01分执行 20 2 * * 0 root /data0/scripts/backup_database.sh #每周星期天的02点20分执行 重启服务 /sbin/service crond restart]]></content>
      <categories>
        <category>Linux</category>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[查看MySQL运行状况]]></title>
    <url>%2F2017%2F08%2F06%2F%E6%9F%A5%E7%9C%8BMySQL%E8%BF%90%E8%A1%8C%E7%8A%B6%E5%86%B5%2F</url>
    <content type="text"><![CDATA[直接在命令行下登陆MySQL运行SHOW STATUS;查询语句，详细如下图SHOW STATUS SHOW VARIABLES SHOW VARIABLES --- 是查看MySQL的配置参数，还可以使用类似SHOW VARIABLES LIKE ‘Key%’ SHOW PROCESSLIST SHOW PROCESSLIST --- 是查看当前正在进行的进程，对于有锁表等情况的排查很有用处。一般情况下，打开MySQL的慢查询记录同样有利于排查。 SHOW OPEN TABLES SHOW OPEN TABLES --- 是显示当前已经被打开的表列表。 mysqladmin status 使用MySQL自带的mysqladmin 工具查看status，使用以下命令mysqladmin -uroot –password=’password’ status 显示的结果如下：Uptime: 87117 Threads: 1 Questions: 5481626 Slow queries: 16 Opens: 2211 Flush tables: 1 Open tables: 512 Queries per second avg: 62.923 另外可以添加 -i 5 参数，让其每五秒自动刷新之。mysqladmin -uroot –password=’password’ status -i 5 mysqladmin extended-status 同样的可以使用以下命令来查看更多的MySQL运行信息，这种方式和第一种查看的信息基本一样。mysqladmin -uroot –password=’password’ extended-status]]></content>
      <categories>
        <category>Linux</category>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL数据库备份命令]]></title>
    <url>%2F2017%2F08%2F06%2F%E5%A4%87%E4%BB%BDMySQL%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[备份MySQL数据库的命令mysqldump -hhostname -uusername -ppassword databasename &gt; backupfile.sql 备份MySQL数据库为带删除表的格式，能够让该备份覆盖已有数据库而不需要手动删除原有数据库。mysqldump -–dd-drop-table -uusername -ppassword databasename &gt; backupfile.sql 直接将MySQL数据库压缩备份mysqldump -hhostname -uusername -ppassword databasename | gzip &gt; backupfile.sql.gz 备份MySQL数据库某个（些）表mysqldump -hhostname -uusername -ppassword databasename specific_table specific_table2 &gt; backupfile.sql 同时备份多个MySQL数据库mysqldump -hhostname -uusername -ppassword -databases databasename databasename2 databasename3 &gt; multibackupfile.sql 仅仅备份数据库结构mysqldump –no-data – databases databasename databasename2 databasename3 &gt; structurebackupfile.sql 备份服务器上所有数据库mysqldump –all-databases &gt; allbackupfile.sql 还原MySQL数据库的命令mysql -hhostname -uusername -ppassword databasename &lt; backupfile.sql 还原压缩的MySQL数据库gunzip &lt; backupfile.sql.gz | mysql -uusername -ppassword databasename 将数据库转移到新服务器mysqldump -uusername -ppassword databasename | mysql –host=*.*.*.* -C databasename]]></content>
      <categories>
        <category>Linux</category>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 挂载新磁盘]]></title>
    <url>%2F2017%2F07%2F23%2FLinux-%E6%8C%82%E8%BD%BD%E6%96%B0%E7%A3%81%E7%9B%98%2F</url>
    <content type="text"><![CDATA[需求：新增加一块硬盘sdb，只分一个区，格式化挂载到/date1、查看现在已有的分区状态df -h图中显示没有看到sdb硬盘2、查看服务器安装的硬盘状态（包括格式化和未格式化的）fdisk -l图中显示，有sdb硬盘，但是没有分区3、添加新分区fdisk /dev/sdb按照以下红框输入：N 回车 P 回车 1 回车 两次回车 W 回车用以下命令查看分区fdisk -l图中红框显示已经多出了一个分区，但是没有格式化4、格式化分区mkfs -t ext4 -c /dev/sdb1-t 指定要把磁盘格式化成什么类型-c 在建立文件系统之前检查坏道，可能会很费时间，新硬盘一般不需要5、挂载新硬盘在根目录下建一个文件夹，待会将分区挂载在这个文件夹上，以后要往新硬盘存东西，就放在这个新建的文件夹里就可以mkdir /data挂载硬盘mount /dev/sdb1 /data6、让系统开机自动挂载这块硬盘echo “/dev/sdb1 /data ext4 defaults 0 0”&gt; /etc/fstab]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[防病毒体系规划]]></title>
    <url>%2F2017%2F07%2F03%2F%E9%98%B2%E7%97%85%E6%AF%92%E4%BD%93%E7%B3%BB%E8%A7%84%E5%88%92%2F</url>
    <content type="text"><![CDATA[计算机病毒形式及传播途径日趋多样化，网络防病毒工作已不再是简单的单台计算机病毒的检测及清除，需要建立多层次的、立体的病毒防护体系，而且要具备完善的管理系统来设置和维护病毒防护策略。这里的多层次病毒防护体系是指在企业的每台客户端计算机上安装防病毒系统，在服务器上安装基于服务器的防病毒系统，在Internet网关安装基于Internet网关的防病毒系统。对企业来说，防止病毒的攻击并不是保护某一台服务器或客户端计算机，而是从客户端计算机到服务器到网关以至于每台不同业务应用服务器的全面保护，这样才能保证整个网络不受计算机病毒的侵害。一、 防病毒系统总体规划防病毒系统不仅是检测和清除病毒，还应加强对病毒的防护工作，在网络中不仅要部署被动防御体系（防病毒系统）还要采用主动防御机制（防火墙、安全策略、漏洞修复等），将病毒隔离在网络大门之外。通过管理控制台统一部署防病毒系统，保证不出现防病毒漏洞。因此，远程安装、集中管理、统一防病毒策略成为企业级防病毒产品的重要需求。在跨区域的广域网内，要保证整个广域网安全无毒，首先要保证每一个局域网的安全无毒。也就是说，一个企业网的防病毒系统是建立在每个局域网的防病毒系统上的。应该根据每个局域网的防病毒要求，建立局域网防病毒控制系统，分别设置有针对性的防病毒策略。从总部到分支机构，由上到下，各个局域网的防病毒系统相结合，最终形成一个立体的、完整的企业网病毒防护体系。1. 构建控管中心集中管理架构保证网络中的所有客户端计算机、服务器可以从管理系统中及时得到更新，同时系统管理人员可以在任何时间、任何地点通过浏览器对整个防毒系统进行管理，使整个系统中任何一个节点都可以被系统管理人员随时管理，保证整个防毒系统有效、及时地拦截病毒。2. 构建全方位、多层次的防毒体系结合企业实际网络防毒需求，构建了多层次病毒防线，分别是网络层防毒、邮件网关防毒、Web网关防毒、群件防毒、应用服务器防毒、客户端防毒，保证斩断病毒可以传播、寄生的每一个节点，实现病毒的全面布控。3. 构建高效的网关防毒子系统网关防毒是最重要的一道防线，一方面消除外来邮件SMTP、POP3病毒的威胁，另一方面消除通过HTTP、FTP等应用的病毒风险，同时对邮件中的关键字、垃圾邮件进行阻挡，有效阻断病毒最主要传播途径。4. 构建高效的网络层防毒子系统企业中网络病毒的防范是最重要的防范工作，通过在网络接口和重要安全区域部署网络病毒系统，在网络层全面消除外来病毒的威胁，使得网络病毒不再肆意传播，同时结合病毒所利用的传播途径，结合安全策略进行主动防御。5. 构建覆盖病毒发作生命周期的控制体系当一个恶性病毒入侵时，防毒系统不仅仅使用病毒代码来防范病毒，而是具备完善的预警机制、清除机制、修复机制来实现病毒的高效处理，特别是对利用系统漏洞、端口攻击为手段瘫痪整个网络的新型病毒具有很好的防护手段。防毒系统在病毒代码到来之前，可以通过网关可疑信息过滤、端口屏蔽、共享控制、重要文件/文件夹写保护等多种手段来对病毒进行有效控制，使得新病毒未进来的进不来、进来后又没有扩散的途径。在清除与修复阶段又可以对发现的病毒高效清除，快速恢复系统至正常状态。6. 病毒防护能力防病毒能力要强、产品稳定、操作系统兼容性好、占用系统资源少、不影响应用程序的正常运行，减少误报的几率。7. 系统服务系统服务是整体防毒系统中极为重要的一环。防病毒体系建立起来之后，能否对病毒进行有效的防范，与病毒厂商能否提供及时、全面的服务有着极为重要的关系。这一方面要求软件提供商要有全球化的防毒体系为基础，另一方面也要求厂商能有精良的本地化技术人员作依托，不管是对系统使用中出现的问题，还是用户发现的可疑文件，都能进行快速的分析和方案提供。如果有新病毒爆发及其它网络安全事件，需要防病毒厂商具有较强的应急处理能力及售后服务保障，并且做出具体、详细的应急处理机制计划表和完善的售后服务保障体系。二、 防病毒系统具体需求在选择防病毒系统时，首先要考虑到整体性。企业级防病毒系统解决方案针对一个特定的网络环境，涉及不同的软硬件设备。与此同时，病毒的来源也远比单机环境复杂得多。因此所选择的防病毒系统不仅要能保护文件服务，同时也要对邮件服务器、客户端计算机、网关等所有设备进保护。同时，必须支持电子邮件、FTP文件、网页、软盘、光盘、U盘移动设备等所有可能带来病毒的信息源进行监控和病毒拦截。1. 病毒查杀能力病毒查杀能力是最容易引起用户注意的产品参数，可查杀病毒的种数固然是多多益善，但也要关注对实际流行病毒的查杀能力。因为用户是要用它查杀可能染上的病毒，有些病毒虽然曾流行过，但却是今后不会再遇上的。例如使用系统漏洞泛滥的病毒，当系统补丁成功更新后，该类病毒将不再生效。病毒查杀能力将体现在以下方面：· 病毒检测及清除能力：防病毒系统应具有对普通文件监控、内存监控、网页监控、引导区和注册表监控功能；具有间谍软件防护功能；可检测并清除隐藏于电子邮件、公共文件夹及数据库中的计算机病毒、恶性程序和垃圾邮件功能，能够自动隔离感染而暂时无法修复的文件；具有全网漏洞扫描和管理功能，可以通过扫描系统中存在的漏洞和不安全的设置，提供相应的解决方案，支持共享文件、OFFICE文档的病毒查杀、能够实现立体的多层面的病毒防御体系。· 电子邮件检测及清除能力：防病毒系统应具有对电子邮件接收/发送检测、邮件文件和邮箱的静态检测及清毒、至少同时支持Foxmail、Outlook、Outlook Express、等客户端邮件系统的防（杀）病毒、防止DDoS恶意攻击，保护重要的邮件服务器资源，不被大量散布的邮件病毒攻击，维护正常运作。· 未知病毒检测及清除能力：该杀毒软件应具有对未知病毒检测、清除能力、支持族群式变种病毒的查杀、能够对加壳的病毒文件进行病毒查杀、具有智能解包还原技术，能够对原始程序的入口进行检测。2. 对新病毒的反应能力对新病毒的反应能力是考察一个防病毒系统好坏的重要方面。这一点主要从三个方面衡量：软件供应商的病毒信息搜集网络、病毒代码的更新周期和供应商对用户发现的新病毒反应周期。通常，防病毒系统供应商都会在全国甚至全世界各地建立一个病毒信息的收集、分析和预测网络，使其软件能更加及时、有效地查杀新出现的病毒。因此，这一搜集网络多少反映了软件商对新病毒的反应能力。病毒代码的更新周期各个厂商也不尽相同，有的一个周更新一次，有的半个月。而供应商对用户发现的新病毒的反应周期不仅体现了厂商对新病毒的反应速度，实际上也反映了厂商对新病毒查杀的技术实力。3. 病毒实时监测能力按照统计，目前的病毒中最常见的是通过邮件系统来传输，另外还有一些病毒通过网页传播。这些传播途径都有一定的实时性，用户无法人为地了解可能感染的时间。因此，防病毒系统的实时监测能力显得相当重要。4. 快速、方便的升级企业级防病毒系统对更新的及时性需求尤其突出。多数防病毒系统采用Internet进行病毒代码和病毒查杀引擎的更新，并可以通过一定的设置自动进行，尽可能地减少人力的介入。升级信息需要和安装客户端计算机防病毒系统一样，能方便地“分发”到每台客户端计算机。5. 智能安装、远程识别由于局域网中，服务器、客户端承担的任务不同，在防病毒方面的要求也不同。因此在安装时需要能够自动区分服务器与客户端，并安装相应的软件。防病毒系统需要提供远程安装、远程设置、统一部署策略以及单台策略部署功能。该功能可以减轻管理员“奔波”于每台机器进行安装、设置的繁重工作，即可对全网的机器进行统一安装，又可以有针对性的设置。防病毒系统支持多种安装方式，包括：智能安装、远程客户端安装、WEB安装、E-mail安装、文件共享安装以及脚本登录安装等，通过这些多样化的安装方式，管理员可以轻松地在最短的时间内完成系统部署。6. 管理方便，易于操作系统的可管理性是衡量防病毒系统的重要指标。例如防病毒系统的参数设置。管理员从系统整体角度出发对各台计算机上的设置，如果各员工随意修改自己使用的计算机上防毒软件参数，可能会造成一些意想不到的漏洞，使病毒趁虚而入。管理者需要随时随地地了解各台计算机病毒感染的情况，并借此制定或调整防病毒策略。因此，生成病毒监控报告等辅助管理措施将会有助于防病毒系统应用更加得心应手。防病毒系统将支持以下管理功能：· 防病毒系统能够实现分级、分组管理，不同组及客户端执行不同病毒查杀策略，全网定时/定级查杀病毒、全网远程查杀策略设置、远程报警、移动式管理、集中式授权管理、全面监控主流邮件服务器、全面监控邮件客户端、 统一的管理界面，直接监视和操纵服务器端/客户端，根据实际需要，添加自定义任务（例如更新和扫描任务等），支持大型网络统一管理的多级中心系统等多种复杂的管理功能。· 防病毒系统支持“分布处理、集中控制”功能，以系统中心、控制台、服务器端、客房端为核心结构，控制台可支持跨网段使用，实现远程自动安装、远程集中控管、远程病毒报警、远程卸载、远程配置、智能升级、全网查杀、日志管理、病毒溯源等功能，将网络中的所有计算机有机地联系在一起，构筑成协调一致的立体防毒体系。· 防病毒系统具有病毒日志查询与统计功能，可以随时对网络中病毒发生的情况进行查询统计，能按时间（日、周或任意时间段）、按IP地址、机器名、按病毒名称、病毒类型进行统计查询；能将染毒机器进行排名，能将查询统计结果打印或导出，查询统计功能不需要借助其他数据库软件，减少用户总体成本。· 防病毒系统支持企业反病毒的统一管理和分布式管理。统一管理表现为由上级中心统一发送病毒命令、下达版本升级提示，并及时掌握整个网络的病毒分布情况等，分布管理表现为下级中心既可以对收到的上一级中心命令做出相应，也可以管理本级系统，并主动向上级中心请求和回报信息。7. 资源占用率防病毒系统进行实时监控或多或少地要占用部分系统资源，这就不可避免地要带来系统性能的降低。尤其是对邮件、网页和FTP文件的监控扫描，由于工作量相当大，因此对系统资源的占用较大。因此，防病毒系统占用系统资源要较低，不影响系统的正常运行。8. 系统兼容性防病毒系统要具备良好的兼容性，将支持以下操作系统：Windows NT、Windows2000、Windows 9X/Me、Windows XP/Vista、Windows 2000/2003 /2008 Server、 Unix、Linux等X86和X64架构的操作系统。9. 病毒库组件升级防病毒系统提供多种升级方式以及自动分发的功能，支持多种网络连接方式，具有升级方便、更新及时等特点，管理员可以十分轻松地按照预先设定的升级方式实现全网内的统一升级，减少病毒库增量升级对网络资源的占用，并且采用均衡流量的策略，尽快将新版本部署到全部计算机上，时刻保证病毒库都是最新的，且版本一致，杜绝因版本不一致而可能造成的安全漏洞和安全隐患。10. 软件商的企业实力软件商的实力一方面指它对现有产品的技术支持和服务能力，另一方面是指它的后续发展能力。因为企业级防毒软件实际是用户企业与防病毒厂商的长期合作，企业实力将会影响这种合作的持续性，从而影响到用户企业在此方面的投入成本三、 部署防病毒系统后的效果网络中部署防病毒系统后，将达到以下效果：· 在网络的网关处进行网络层病毒包扫描，及时清除蠕虫病毒攻击包，同时对控制病毒传播途径，对未安装防毒软件或未安装补丁的网络节点进行访问控制。· 对整个网络节点的脆弱性进行评估，及时阻挡不符合安全策略的节点的访问。· 对进出网关的邮件进行全面防毒扫描，发现病毒即时进行处理，并且给出管理员即时通知信息。· 采用数据库比对技术和智能性判断技术，对进出网关的邮件进行垃圾邮件过滤，在网关处将垃圾邮件有效删除掉。· 对进出网关的Web访问、FTP访问行全面防毒扫描，发现病毒即时进行处理，并且给出管理员即时的通知信息，同时对不良网站和URL地址进行过滤，阻挡恶意类型文件。· 对整个网络内的应用服务器进行全面防护，斩断病毒在服务器内的寄生及传播。· 对所有的客户机进行全面防护，彻底消除病毒对客户机的破坏，保证所有客户端计算机都有一个干净、安全的工作平台。· 所有防毒软件的升级、防毒策略的制定，将通过控管系统集中实现，一方面保证所有防毒软件得到即时更新，另一方面保证整个防毒策略的一致。同时生成整个网络统一的病毒报告日志，便于系统管理人员即时对病毒发现情况进行掌握，制定更加有效的网络平台安全使用策略。]]></content>
      <categories>
        <category>安全</category>
      </categories>
      <tags>
        <tag>安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[恶意代码相关术语解释]]></title>
    <url>%2F2017%2F06%2F29%2F%E6%81%B6%E6%84%8F%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3%E6%9C%AF%E8%AF%AD%E8%A7%A3%E9%87%8A%2F</url>
    <content type="text"><![CDATA[1. 什么是信息系统、漏洞、恶意代码?1.1 信息系统信息系统是指由计算机硬件、软件、网络和通信设备等组成的以处理信息和数据为目的的系统。1.2 漏洞漏洞是指信息系统中的软件、硬件或通信协议中存在缺陷或不适当的配置，从而可使攻击者在未授权的情况下访问或破坏系统，导致信息系统面临安全风险。1.3 恶意代码恶意代码是指在未经授权的情况下，在信息系统中安装、执行以达到不正当目的的程序。恶意代码分类说明如下：2. 特洛伊木马（Trojan Horse）特洛伊木马（简称木马）是以盗取用户个人信息，甚至是远程控制用户计算机为主要目的的恶意代码。由于它像间谍一样潜入用户的电脑，与战争中的“木马”战术十分相似，因而得名木马。按照功能，木马程序可进一步分为：盗号木马7、网银木马8、窃密木马9、远程控制木马10、流量劫持木马11、下载者木马12和其它木马六类。注：盗号木马是用于窃取用户电子邮箱、网络游戏等账号的木马。 注8：网银木马是用于窃取用户网银、证券等账号的木马。 注9：窃密木马是用于窃取用户主机中敏感文件或数据的木马。 注10：远程控制木马是以不正当手段获得主机管理员权限，并能够通过网络操控用户主机的木马。 注11：流量劫持木马是用于劫持用户网络浏览的流量到攻击者指定站点的木马。 注12：下载者木马是用于下载更多恶意代码到用户主机并运行，以进一步操控用户主机的木马。3. 僵尸程序（Bot）僵尸程序是用于构建大规模攻击平台的恶意代码。按照使用的通信协议，僵尸程序可进一步分为：IRC僵尸程序、Http僵尸程序、P2P僵尸程序和其它僵尸程序四类。4. 蠕虫（Worm）蠕虫是指能自我复制和广泛传播，以占用系统和网络资源为主要目的的恶意代码。按照传播途径，蠕虫可进一步分为：邮件蠕虫、即时消息蠕虫、U盘蠕虫、漏洞利用蠕虫和其它蠕虫五类。5. 病毒（Virus）病毒是通过感染计算机文件进行传播，以破坏或篡改用户数据，影响信息系统正常运行为主要目的恶意代码。6. 其它上述分类未包含的其它恶意代码。 随着黑客地下产业链的发展，互联网上出现的一些恶意代码还具有上述分类中的多重功能属性和技术特点，并不断发展。对此，我们将按照恶意代码的主要用途参照上述定义进行归类。6.1 僵尸网络僵尸网络是被黑客集中控制的计算机群，其核心特点是黑客能够通过一对多的命令与控制信道操纵感染木马或僵尸程序的主机执行相同的恶意行为，如可同时对某目标网站进行分布式拒绝服务攻击，或发送大量的垃圾邮件等。6.2 拒绝服务攻击拒绝服务攻击是向某一目标信息系统发送密集的攻击包，或执行特定攻击操作，以期致使目标系统停止提供服务。6.3 网页篡改网页篡改是恶意破坏或更改网页内容，使网站无法正常工作或出现黑客插入的非正常网页内容。6.4 网页仿冒网页仿冒是通过构造与某一目标网站高度相似的页面（俗称钓鱼网站），并通常以垃圾邮件、即时聊天、手机短信或网页虚假广告等方式发送声称来自于被仿冒机构的欺骗性消息，诱骗用户访问钓鱼网站，以获取用户个人秘密信息（如银行帐号和帐户密码）。6.5 网页挂马网页挂马是通过在网页中嵌入恶意代码或链接，致使用户计算机在访问该页面时被植入恶意代码。6.6 网站后门网站后门事件是指黑客在网站的特定目录中上传远程控制页面从而能够通过该页面秘密远程控制网站服务器的攻击事件。6.7 垃圾邮件垃圾邮件是将不需要的消息（通常是未经请求的广告）发送给众多收件人。包括：（一）收件人事先没有提出要求或者同意接收的广告、电子刊物、各种形式的宣传品等宣传性的电子邮件；（二）收件人无法拒收的电子邮件；（三）隐藏发件人身份、地址、标题等信息的电子邮件；（四）含有虚假的信息源、发件人、路由等信息的电子邮件。6.8 域名劫持域名劫持是通过拦截域名解析请求或篡改域名服务器上的数据，使得用户在访问相关域名时返回虚假IP地址或使用户的请求失败。6.9 非授权访问非授权访问是没有访问权限的用户以非正当的手段访问数据信息。非授权访问事件一般发生在存在漏洞的信息系统中，黑客利用专门的漏洞利用程序（Exploit）来获取信息系统访问权限。6.10 路由劫持路由劫持是通过欺骗方式更改路由信息，以导致用户无法访问正确的目标，或导致用户的访问流量绕行黑客设定的路径，以达到不正当的目的。]]></content>
      <categories>
        <category>安全</category>
        <category>代码审计</category>
      </categories>
      <tags>
        <tag>安全</tag>
        <tag>代码审计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zimbra 邮箱系统安装配置]]></title>
    <url>%2F2017%2F06%2F21%2Fzimbra%20%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[1、Zimbra介绍Zimbra与众不同的特点是其“Zimlet”网络服务提供了更多的电子邮件功能。例如，人们可以简单地用鼠标点击电子邮件程序中的航班信息以检查航班的状况。用户还可以在电子邮件中跟踪FedEx公司的投递情况并且获得地图、股票和其它信息。Zimbra的核心产品是Zimbra协作套件（Zimbra Collaboration Suite，简称ZCS）。除了它的核心功能是电子邮件和日程安排服务器，当然还包括许多其它的功能，就象是下一代的微软Exchange。在电子邮件和日程安排之外，它还提供文档存储和编辑、即时消息以及一个利用获奖技术开发的全功能的管理控制台。ZCS同时也提供移动设备的支持，以及与部署于Windows、Linux或apple操作系统中的桌面程序的同步功能。(来自百度百科)注:Zimbra安装时，须在linux系统上，系统内存至少一个GB，5G磁盘空间；否则安装过程会很长，且会因为内存和磁盘空间不够而导致安装失败2、安装配置DNS1、安装配置DNS配置vim /etc/named.conf #修改一下内容配置 vim /etc/named.rfc1912.zones #添加以下内容配置正向解析文件解析文件cd /var/namedcp named.localhost tzh.com.zonevim tzh.com.zone配置反向解析文件 #添加以下内容vim 10.90.10.zone启动bindservice named start解析nslookup www.tzh.comnslookup mail.tzh.com3、安装zimbra3.1、停止系统默认邮件服务Chkconfig postfix off &amp;&amp; /etc/init.d/postfix stop3.2、关闭iptables和selinuxsetenforce 0 &amp;&amp; service iptables stop &amp;&amp; chkconfig iptables off3.3、设置hosts文件 #添加以下内容3.4、 安装点击显/隐内容[root@tzh zcs-8.6.0_GA_1153.RHEL6_64.20141215151155]# ./install.shOperations logged to /tmp/install.log.29747Checking for existing installation…zimbra-ldap…NOT FOUNDzimbra-logger…NOT FOUNDzimbra-mta…NOT FOUNDzimbra-dnscache…NOT FOUNDzimbra-snmp…NOT FOUNDzimbra-store…NOT FOUNDzimbra-apache…NOT FOUNDzimbra-spell…NOT FOUNDzimbra-convertd…NOT FOUNDzimbra-memcached…NOT FOUNDzimbra-proxy…NOT FOUNDzimbra-archiving…NOT FOUNDzimbra-core…NOT FOUNDPLEASE READ THIS AGREEMENT CAREFULLY BEFORE USING THE SOFTWARE.ZIMBRA, INC. (“ZIMBRA”) WILL ONLY LICENSE THIS SOFTWARE TO YOU IF YOUFIRST ACCEPT THE TERMS OF THIS AGREEMENT. BY DOWNLOADING OR INSTALLINGTHE SOFTWARE, OR USING THE PRODUCT, YOU ARE CONSENTING TO BE BOUND BYTHIS AGREEMENT. IF YOU DO NOT AGREE TO ALL OF THE TERMS OF THISAGREEMENT, THEN DO NOT DOWNLOAD, INSTALL OR USE THE PRODUCT.License Terms for the Zimbra Collaboration Suite:http://www.zimbra.com/license/zimbra-public-eula-2-5.htmlDo you agree with the terms of the software license agreement? [N] yChecking for prerequisites…FOUND: NPTLFOUND: nc-1.84-24FOUND: sudo-1.8.6p3-19FOUND: libidn-1.18-2FOUND: gmp-4.3.1-7FOUND: libaio-0.3.107-10FOUND: libstdc++-4.4.7-16FOUND: unzip-6.0-2Checking for suggested prerequisites…FOUND: perl-5.10.1FOUND: sysstatFOUND: sqlitePrerequisite check complete.Checking for installable packagesFound zimbra-coreFound zimbra-ldapFound zimbra-loggerFound zimbra-mtaFound zimbra-dnscacheFound zimbra-snmpFound zimbra-storeFound zimbra-apacheFound zimbra-spellFound zimbra-memcachedFound zimbra-proxySelect the packages to installInstall zimbra-ldap [Y] yInstall zimbra-logger [Y] yInstall zimbra-mta [Y] yInstall zimbra-dnscache [Y] yInstall zimbra-snmp [Y] yInstall zimbra-store [Y] yInstall zimbra-apache [Y]Install zimbra-spell [Y] yInstall zimbra-memcached [Y] yInstall zimbra-proxy [Y] yChecking required space for zimbra-coreChecking space for zimbra-storeChecking required packages for zimbra-storezimbra-store package check complete.Installing:zimbra-corezimbra-ldapzimbra-loggerzimbra-mtazimbra-dnscachezimbra-snmpzimbra-storezimbra-apachezimbra-spellzimbra-memcachedzimbra-proxyThe system will be modified. Continue? [N] yRemoving /opt/zimbraRemoving zimbra crontab entry…done.Cleaning up zimbra init scripts…done.Cleaning up /etc/ld.so.conf…done.Cleaning up /etc/prelink.conf…done.Cleaning up /etc/security/limits.conf…done.Finished removing Zimbra Collaboration Server.Installing packageszimbra-core……zimbra-core-8.6.0_GA_1153.RHEL6_64-20141215151155.x86_64.rpm…zimbra-ldap……zimbra-ldap-8.6.0_GA_1153.RHEL6_64-20141215151155.x86_64.rpm…donezimbra-logger……zimbra-logger-8.6.0_GA_1153.RHEL6_64-20141215151155.x86_64.rpm…donezimbra-mta……zimbra-mta-8.6.0_GA_1153.RHEL6_64-20141215151155.x86_64.rpm…donezimbra-dnscache……zimbra-dnscache-8.6.0_GA_1153.RHEL6_64-20141215151155.x86_64.rpm…donezimbra-snmp……zimbra-snmp-8.6.0_GA_1153.RHEL6_64-20141215151155.x86_64.rpm…donezimbra-store……zimbra-store-8.6.0_GA_1153.RHEL6_64-20141215151155.x86_64.rpm…donezimbra-apache……zimbra-apache-8.6.0_GA_1153.RHEL6_64-20141215151155.x86_64.rpm…donezimbra-spell……zimbra-spell-8.6.0_GA_1153.RHEL6_64-20141215151155.x86_64.rpm…donezimbra-memcached……zimbra-memcached-8.6.0_GA_1153.RHEL6_64-20141215151155.x86_64.rpm…donezimbra-proxy……zimbra-proxy-8.6.0_GA_1153.RHEL6_64-20141215151155.x86_64.rpm…doneOperations logged to /tmp/zmsetup06292016-184521.logInstalling LDAP configuration database…done.Setting defaults… MX: mail.user-mail.net (54.227.254.216)MX: mail.user-mail.net (54.225.221.198)Interface: 10.90.10.190Interface: 127.0.0.1Interface: ::154.225.221.19854.227.254.21654.227.254.21654.225.221.19854.225.221.19854.227.254.216DNS ERROR - none of the MX records for mail.tzh.comresolve to this hostChange domain name? [Yes] ndone.Checking for port conflictsMain menu1) Common Configuration:2) zimbra-ldap: Enabled3) zimbra-logger: Enabled4) zimbra-mta: Enabled5) zimbra-dnscache: Enabled6) zimbra-snmp: Enabled7) zimbra-store: Enabled+Create Admin User: yes+Admin user to create: admin@mail.tzh.com*** +Admin Password UNSET+Anti-virus quarantine user: virus-quarantine.iv8_lcko@mail.tzh.com+Enable automated spam training: yes+Spam training user: spam.f8aglxrf@mail.tzh.com+Non-spam(Ham) training user: ham.ugur2xpeby@mail.tzh.com+SMTP host: mail.tzh.com+Web server HTTP port: 8080+Web server HTTPS port: 8443+Web server mode: https+IMAP server port: 7143+IMAP server SSL port: 7993+POP server port: 7110+POP server SSL port: 7995+Use spell check server: yes+Spell server URL: http://mail.tzh.com:7780/aspell.php+Enable version update checks: TRUE+Enable version update notifications: TRUE+Version update notification email: admin@mail.tzh.com+Version update source email: admin@mail.tzh.com+Install mailstore (service webapp): yes+Install UI (zimbra,zimbraAdmin webapps): yes8) zimbra-spell: Enabled9) zimbra-proxy: Enabled10) Default Class of Service Configuration:s) Save config to filex) Expand menuq) QuitAddress unconfigured () items (? - help) 7Store configuration1) Status: Enabled2) Create Admin User: yes3) Admin user to create: admin@mail.tzh.com 4) Admin Password UNSET5) Anti-virus quarantine user: virus-quarantine.iv8_lcko@mail.tzh.com6) Enable automated spam training: yes7) Spam training user: spam.f8aglxrf@mail.tzh.com8) Non-spam(Ham) training user: ham.ugur2xpeby@mail.tzh.com9) SMTP host: mail.tzh.com10) Web server HTTP port: 808011) Web server HTTPS port: 844312) Web server mode: https13) IMAP server port: 714314) IMAP server SSL port: 799315) POP server port: 711016) POP server SSL port: 799517) Use spell check server: yes18) Spell server URL: http://mail.tzh.com:7780/aspell.php19) Enable version update checks: TRUE20) Enable version update notifications: TRUE21) Version update notification email: admin@mail.tzh.com22) Version update source email: admin@mail.tzh.com23) Install mailstore (service webapp): yes24) Install UI (zimbra,zimbraAdmin webapps): yesSelect, or ‘r’ for previous menu [r] 4Password for admin@mail.tzh.com (min 6 characters): [1mrCHrfp] 558842Store configuration1) Status: Enabled2) Create Admin User: yes3) Admin user to create: admin@mail.tzh.com4) Admin Password set5) Anti-virus quarantine user: virus-quarantine.iv8_lcko@mail.tzh.com6) Enable automated spam training: yes7) Spam training user: spam.f8aglxrf@mail.tzh.com8) Non-spam(Ham) training user: ham.ugur2xpeby@mail.tzh.com9) SMTP host: mail.tzh.com10) Web server HTTP port: 808011) Web server HTTPS port: 844312) Web server mode: https13) IMAP server port: 714314) IMAP server SSL port: 799315) POP server port: 711016) POP server SSL port: 799517) Use spell check server: yes18) Spell server URL: http://mail.tzh.com:7780/aspell.php19) Enable version update checks: TRUE20) Enable version update notifications: TRUE21) Version update notification email: admin@mail.tzh.com22) Version update source email: admin@mail.tzh.com23) Install mailstore (service webapp): yes24) Install UI (zimbra,zimbraAdmin webapps): yesSelect, or ‘r’ for previous menu [r] rMain menu1) Common Configuration:2) zimbra-ldap: Enabled3) zimbra-logger: Disabled4) zimbra-mta: Enabled5) zimbra-dnscache: Enabled6) zimbra-snmp: Enabled7) zimbra-store: Enabled8) zimbra-spell: Enabled9) zimbra-proxy: Enabled10) Default Class of Service Configuration:s) Save config to filex) Expand menuq) QuitSelect from menu, or press ‘a’ to apply config (? - help) aSave configuration data to a file? [Yes] ySave config in file: [/opt/zimbra/config.39633]Saving config in /opt/zimbra/config.39633…done.The system will be modified - continue? [No] yOperations logged to /tmp/zmsetup06292016-184521.logSetting local config values…done.Initializing core config…Setting up CA…done.Deploying CA to /opt/zimbra/conf/ca …done.Creating SSL zimbra-store certificate…done.Creating new zimbra-ldap SSL certificate…done.Creating new zimbra-mta SSL certificate…done.Creating new zimbra-proxy SSL certificate…done.Installing mailboxd SSL certificates…done.Installing MTA SSL certificates…done.Installing LDAP SSL certificate…done.Installing Proxy SSL certificate…done.Initializing ldap…done.Setting replication password…done.Setting Postfix password…done.Setting amavis password…done.Setting nginx password…done.Setting BES searcher password…done.Creating server entry for mail.tzh.com…done.Setting Zimbra IP Mode…done.Saving CA in ldap …done.Saving SSL Certificate in ldap …done.Setting spell check URL…done.Setting service ports on mail.tzh.com…done.Setting zimbraFeatureTasksEnabled=TRUE…done.Setting zimbraFeatureBriefcasesEnabled=TRUE…done.Setting Master DNS IP address(es)…done.Setting DNS cache tcp lookup preference…done.Setting DNS cache udp lookup preference…done.Setting DNS tcp upstream preference…done.Setting TimeZone Preference…done.Initializing mta config…done.Setting services on mail.tzh.com…done.Adding mail.tzh.com to zimbraMailHostPool in default COS…done.Creating domain mail.tzh.com…done.Setting default domain name…done.Creating domain mail.tzh.com…already exists.Creating admin account admin@mail.tzh.com…done.Creating root alias…done.Creating postmaster alias…done.Creating user spam.f8aglxrf@mail.tzh.com…done.Creating user ham.ugur2xpeby@mail.tzh.com…done.Creating user virus-quarantine.iv8_lcko@mail.tzh.com…done.Setting spam training and Anti-virus quarantine accounts…done.Initializing store sql database…done.Setting zimbraSmtpHostname for mail.tzh.com…done.Configuring SNMP…done.Setting up syslog.conf…done.Starting servers…Installing common zimlets…com_zimbra_ymemoticons…done.com_zimbra_clientuploader…done.com_zimbra_webex…done.com_zimbra_proxy_config…done.com_zimbra_srchhighlighter…done.com_zimbra_bulkprovision…done.com_zimbra_viewmail…done.com_zimbra_date…done.com_zimbra_attachcontacts…done.com_zimbra_mailarchive…done.com_zimbra_cert_manager…done.com_zimbra_url…done.com_zimbra_adminversioncheck…done.com_zimbra_attachmail…done.com_zimbra_tooltip…done.com_zimbra_email…done.com_zimbra_phone…done.Finished installing common zimlets.Restarting mailboxd…done.Creating galsync account for default domain…done.You have the option of notifying Zimbra of your installation.This helps us to track the uptake of the Zimbra Collaboration Server.The only information that will be transmitted is:The VERSION of zcs installed (8.6.0_GA_1153_RHEL6_64)The ADMIN EMAIL ADDRESS created (admin@mail.tzh.com)Notify Zimbra of your installation? [Yes] yesNotifying Zimbra of installation via http://www.zimbra.com/cgi-bin/notify.cgi?VER=8.6.0_GA_1153_RHEL6_64&amp;MAIL=admin@mail.tzh.comNotification completeSetting up zimbra crontab…done.Moving /tmp/zmsetup06292016-184521.log to /opt/zimbra/logConfiguration complete - press return to exit3.5、重启zimbra点击显/隐内容[root@tzh zcs-8.6.0_GA_1153.RHEL6_64.20141215151155]# /etc/init.d/zimbra restartHost mail.tzh.comStopping vmware-ha…skipped./opt/zimbra/bin/zmhactl missing or not executable.Stopping zmconfigd…Done.Stopping zimlet webapp…Done.Stopping zimbraAdmin webapp…Done.Stopping zimbra webapp…Done.Stopping service webapp…Done.Stopping stats…Done.Stopping mta…Done.Stopping spell…Done.Stopping snmp…Done.Stopping cbpolicyd…Done.Stopping archiving…Done.Stopping opendkim…Done.Stopping amavis…Done.Stopping antivirus…Done.Stopping antispam…Done.Stopping proxy…Done.Stopping memcached…Done.Stopping mailbox…Done.Stopping logger…Done.Stopping dnscache…Done.Stopping ldap…Done.Host mail.tzh.comStarting ldap…Done.略~~~4、服务发件测试4.1 登陆测试创建一个账户，进行邮件发送测试账户创建登陆网页客户端进行邮件发送测试注：上图时间为周三（6月29）下午17：29是因为我在本地搭建的虚拟机，时间没有同步因为域名问题，以及DNS在内网的虚拟机上，收取邮件是无法收取的，需要做公网解析，所以暂不进行邮件收取测试]]></content>
      <categories>
        <category>Linux</category>
        <category>zimbra</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>zimbra</tag>
      </tags>
  </entry>
</search>
