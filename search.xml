<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Linux常用网络工具:fping主机扫描]]></title>
    <url>%2F2019%2F07%2F13%2FLinux%E5%B8%B8%E7%94%A8%E7%BD%91%E7%BB%9C%E5%B7%A5%E5%85%B7-fping%E4%B8%BB%E6%9C%BA%E6%89%AB%E6%8F%8F%2F</url>
    <content type="text"><![CDATA[fping 介绍Linux下有很多强大网络扫描工具，网络扫描工具可以分为：主机扫描、主机服务扫描、路由扫描等。fping是一个主机扫描工具，相比于ping工具它可以批量扫描主机。fping完全不同于ping，因为您可以在命令行上定义任意数量的主机，或者指定包含要ping的IP地址或主机列表的文件。例如，使用fping，我们可以指定完整的网络范围（ 192.168.0.1/24 ）。它会向主机发送Fping请求，并以循环方式移动到另一个目标主机。 与ping不同，Fping基本上用于编写脚本。访问fping 官方网站：http://fping.org下载最新版安装程序一、编译及安装安装可以使用yum安装或者源码安装yum 安装命令:yum install fping 非root用户可使用sudo或者切换到root用户安装 sudo yum install fping 源码安装[root@node1 ~]# wget http://fping.org/dist/fping-4.2.tar.gz [root@node1 ~]# ll fping-4.2.tar.gz -rw-r--r--. 1 root root 171409 2月 20 05:05 fping-4.2.tar.gz [root@node1 ~]# tar xf fping-4.2.tar.gz &amp;&amp; cd fping-4.2 [root@node1 fping-4.2]# ./configure &amp;&amp; make &amp;&amp; make install 查看安装版本fping -v 二、使用示例2.1 ping多个主机[root@node1 fping-4.2]# fping 172.31.8.13 172.31.8.107 172.31.8.75 172.31.8.3 172.31.8.13 is alive ---主机活动 172.31.8.107 is alive 172.31.8.75 is alive 172.31.8.75 is unreachable --- 主机不可用 [root@node1 fping-4.2]# 2.2 ping IP地址范围以下命令将接收ping的IP范围并输出以下内容，我们将响应请求发送到该范围内的IP并获得我们想要信息。结束后还显示累积结果[root@node1 fping-4.2]# fping -s -g 172.31.8.1 172.31.8.10 172.31.8.1 is alive 172.31.8.3 is alive 172.31.8.5 is alive 172.31.8.8 is alive ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.2 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.2 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.2 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.2 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.4 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.4 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.4 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.4 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.6 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.6 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.6 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.6 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.7 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.7 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.7 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.7 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.9 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.9 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.9 ICMP Host Unreachable from 172.31.8.8 for ICMP Echo sent to 172.31.8.9 172.31.8.2 is unreachable 172.31.8.4 is unreachable 172.31.8.6 is unreachable 172.31.8.7 is unreachable 172.31.8.9 is unreachable 172.31.8.10 is unreachable 10 targets 4 alive 6 unreachable 0 unknown addresses 6 timeouts (waiting for response) 28 ICMP Echos sent 4 ICMP Echo Replies received 20 other ICMP received 0.04 ms (min round trip time) 0.73 ms (avg round trip time) 1.15 ms (max round trip time) 4.164 sec (elapsed real time) [root@node1 fping-4.2]# 2.3 ping整个IP段，并重复一次2.4 从文件中读取IP信息，执行ping三、查看帮助信息[root@node1 fping-4.2]# fping -help Usage: fping [options] [targets...] 用法：fping [选项] [ping的目标] -a show targets that are alive 显示可ping通的目标 -A show targets by address 将目标以ip地址的形式显示 -b n amount of ping data to send, in bytes (default 56) ping 数据包的大小。（默认为56） -B f set exponential backoff factor to f 设置指数反馈因子到f -c n count of pings to send to each target (default 1) ping每个目标的次数 (默认为1) -C n same as -c, report results in verbose format 同-c, 返回的结果为冗长格式 -e show elapsed time on return packets 显示返回数据包所费时间 -f file read list of targets from a file ( - means stdin) (only if no -g specified) 从文件获取目标列表( - 表示从标准输入)(不能与 -g 同时使用) -g generate target list (only if no -f specified) 生成目标列表(不能与 -f 同时使用) (specify the start and end IP in the target list, or supply a IP netmask) (ex. fping -g 192.168.1.0 192.168.1.255 or fping -g 192.168.1.0/24) (可指定目标的开始和结束IP， 或者提供ip的子网掩码) (例：fping -g 192.168.1.0 192.168.1.255 或 fping -g 192.168.1.0/24) -H n Set the IP TTL value (Time To Live hops) 设置ip的TTL值 (生存时间) -i n interval between sending ping packets (in millisec) (default 25) ping包之间的间隔(单位：毫秒)(默认25) -l loop sending pings forever 循环发送ping -m ping multiple interfaces on target host ping目标主机的多个网口 -n show targets by name (-d is equivalent) 将目标以主机名或域名显示(等价于 -d ) -p n interval between ping packets to one target (in millisec) 对同一个目标的ping包间隔(毫秒) (in looping and counting modes, default 1000) (在循环和统计模式中，默认为1000) -q quiet (don&apos;t show per-target/per-ping results) 安静模式(不显示每个目标或每个ping的结果) -Q n same as -q, but show summary every n seconds 同-q, 但是每n秒显示信息概要 -r n number of retries (default 3) 当ping失败时，最大重试次数(默认为3次) -s print final stats 打印最后的统计数据 -I if bind to a particular interface 绑定到特定的网卡 -S addr set source address 设置源ip地址 -t n individual target initial timeout (in millisec) (default 500) 单个目标的超时时间(毫秒)(默认500) -T n ignored (for compatibility with fping 2.4) 请忽略(为兼容fping 2.4) -u show targets that are unreachable 显示不可到达的目标 -O n set the type of service (tos) flag on the ICMP packets 在icmp包中设置tos（服务类型） -v show version 显示版本号 targets list of targets to check (if no -f specified) 需要ping的目标列表(不能和 -f 同时使用) -h show this page 显示本帮助页]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker 仓库harbor搭建]]></title>
    <url>%2F2019%2F07%2F12%2Fdocker-%E4%BB%93%E5%BA%93harbor%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[一、初始化在正式安装harbor之前，需要对OS环境进行初始化1.1 升级OS内核，具体内核升级步骤可以自己了解下1.2 安装yum源因为需要安装相关的以来软件，所以需要安装yum源，安装前先将原先的yum备份[root@harbor yum.repos.d]# mv CentOS-Base.repo CentOS-Base.repo.bak [root@harbor yum.repos.d]# vim CentOS-Base.repo [base] name=CentOS-$releasever – Base – 163.com #mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=os baseurl=http://mirrors.163.com/centos/$releasever/os/$basearch/ gpgcheck=1 gpgkey=http://mirrors.163.com/centos/RPM-GPG-KEY-CentOS-7 #released updates [updates] name=CentOS-$releasever – Updates – 163.com #mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=updates baseurl=http://mirrors.163.com/centos/$releasever/updates/$basearch/ gpgcheck=1 gpgkey=http://mirrors.163.com/centos/RPM-GPG-KEY-CentOS-7 #additional packages that may be useful [extras] name=CentOS-$releasever – Extras – 163.com #mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=extras baseurl=http://mirrors.163.com/centos/$releasever/extras/$basearch/ gpgcheck=1 gpgkey=http://mirrors.163.com/centos/RPM-GPG-KEY-CentOS-7 #additional packages that extend functionality of existing packages [centosplus] name=CentOS-$releasever – Plus – 163.com baseurl=http://mirrors.163.com/centos/$releasever/centosplus/$basearch/ gpgcheck=1 enabled=0 gpgkey=http://mirrors.163.com/centos/RPM-GPG-KEY-CentOS-7 1.3 安装阿里云epel源wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo 1.4 安装dockeryum -y install docker 启动docker并查看docker版本1.5 安装docker-composeyum -y install certbot libevent-devel gcc libffi-devel python-devel openssl-devel python2-pip 使用pip的方式进行安装，命令如下pip install -U docker-compose 查看安装的版本docker-compose version 二、下载安装harbor，选择自己需要的版本官网地址：http://harbor.orientsoft.cn/2.1 修改Harbor配置文件，修改服务地址[root@harbor ~]# ls anaconda-ks.cfg harbor-offline-installer-v1.4.0.tgz [root@harbor ~]# tar xf harbor-offline-installer-v1.4.0.tgz [root@harbor ~]# ls anaconda-ks.cfg harbor harbor-offline-installer-v1.4.0.tgz [root@harbor ~]# mv harbor /usr/local/ [root@harbor ~]# vim harbor.cfg 修改hostname为主机的IP（没有域名的情况下）2.2 修改harbor的默认admin密码（默认密码为Harbor12345）2.3 安装harbor步骤一会下载相关的docker镜像，这个过程根据各自的网络情况不同花费的时间也不同，相关的docker镜像如下：docker images 2.4 查看容器，可以看到没有Notary与Clair相关服务；也可使用”docker ps”；“docker-compose ps”需要在”docker-compose.yml”文件所在目录执行相关操作[root@harbor harbor]# docker-compose ps 三、安装后配置3.1 访问harbor ui （注意服务器的防火墙和selinux，可以关闭或者放行相关端口）admin/默认密码harbor安装完成3.2 harbor 使用docker login报错的问题从harbor安装文档中可以看到https://github.com/vmware/harbor/blob/master/docs/installation_guide.md在Harbor主机和客户机都对这个文件进行设置/etc/docker/daemon.json：{ &quot;insecure-registries&quot;:[&quot;192.168.33.10&quot;] } 四、简单使用4.1 向harbor上推拉镜象给docker.io/tomcat这个镜像打上tag[root@harbor ~]# docker tag docker.io/tomcat 172.31.8.25/library/tomcat2 4.2 推送至harbor[root@harbor ~]# docker push 172.31.8.25/library/tomcat2]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo博客使用Next主题建立标签云]]></title>
    <url>%2F2019%2F07%2F10%2FHexo%E5%8D%9A%E5%AE%A2%E4%BD%BF%E7%94%A8Next%E4%B8%BB%E9%A2%98%E5%BB%BA%E7%AB%8B%E6%A0%87%E7%AD%BE%E4%BA%91%2F</url>
    <content type="text"><![CDATA[使用hexo-tag-cloud插件:github地址1、安装插件:进入到hexo的根目录，在在 package.json 中添加依赖: “hexo-tag-cloud”: “2.0.*” 操作如下：npm install hexo-tag-cloud@^2.0.* --save Git clone 下载使用命令行安装插件包的过程中可能会出现问题，安装失败，安装不完全。可以直接克隆插件到博客的插件文件夹blog/node_modules里。或者克隆到桌面然后复制到博客的插件目录blog\node_modules文件夹里git clone https://github.com/MikeCoder/hexo-tag-cloud 2、配置插件插件的配置需要对应的环境，可以在主题文件夹里找一下，有没有对应的渲染文件，然后根据渲染文件的类型，选择对应的插件配置方法。我这里使用的next主题，所以使用的是swig 配置方式（不仅next，还有其他主题的配置文件也是.swig格式）在主题文件夹找到文件 theme/next/layout/_macro/sidebar.swig, 然后写入如下代码跳转官网复制代码添加到合适的位置即可博客根目录找到 _config.yml配置文件,在最后添加以下的配置项# hexo-tag-cloud tag_cloud: textFont: Trebuchet MS, Helvetica textColor: &apos;#333&apos; textHeight: 25 outlineColor: &apos;#E2E1D1&apos; maxSpeed: 0.1 定义标签云的字体和颜色textColor: ‘#333’ 字体颜色 textHeight: 25 字体高度，根据部署的效果调整 maxSpeed: 0.1 文字滚动速度，根据自己喜好调整 重启博客，部署到线上hexo clean 清除缓存 hexo g 生成博客 hexo s 本地预览 hexo d 部署到线上 一定要注意清除缓存，不然的话容易出现功能效果不展示的问题，清除缓存即执行:hexo clean 实现效果]]></content>
      <categories>
        <category>hexo博客建站</category>
      </categories>
      <tags>
        <tag>HEXO博客建站</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat 入门(安装配置篇)]]></title>
    <url>%2F2019%2F07%2F09%2Ftomcat-%E5%85%A5%E9%97%A8(%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%E7%AF%87)%2F</url>
    <content type="text"><![CDATA[tomcat简介Tomcat 服务器是一个免费的开放源代码的Web 应用服务器，Tomcat是Apache 软件基金会（Apache Software Foundation）的Jakarta 项目中的一个核心项目，它早期的名称为catalina，后来由Apache、Sun 和其他一些公司及个人共同开发而成，并更名为Tomcat。Tomcat 是一个小型的轻量级应用服务器，在中小型系统和并发访问用户不是很多的场合下被普遍使用，是开发和调试JSP 程序的首选，因为Tomcat 技术先进、性能稳定，成为目前比较流行的Web 应用服务器。Tomcat是应用（java）服务器，它只是一个servlet容器，是Apache的扩展，但它是独立运行的。目前最新的版本为Tomcat 8.0.24 Released。Tomcat不是一个完整意义上的Jave EE服务器，它甚至都没有提供对哪怕是一个主要Java EE API的实现；但由于遵守apache开源协议，tomcat却又为众多的java应用程序服务器嵌入自己的产品中构建商业的java应用程序服务器，如JBoss和JOnAS。尽管Tomcat对Jave EE API的实现并不完整，然而很企业也在渐渐抛弃使用传统的Java EE技术（如EJB）转而采用一些开源组件来构建复杂的应用。这些开源组件如Structs、Spring和Hibernate，而Tomcat能够对这些组件实现完美的支持。详细请参考-运维生存时间1、安装环境:Centos 7 tomcat版本: apache-tomcat-8.5.42.tar java版本: java8官方网站下载tomcat82、安装上传至Linux 服务器创建tomcat安装目录mkdir /tomcat 解压tomcat、jdk[root@node1 tomcat]# ll 总用量 178712 -rw-r--r--. 1 root root 9711748 7月 9 10:55 apache-tomcat-8.5.42.tar.gz -rw-r--r--. 1 root root 173281904 7月 9 10:55 jdk-8u51-linux-x64.tar.gz [root@node1 tomcat]# tar xf jdk-8u51-linux-x64.tar.gz [root@node1 tomcat]# tar xf apache-tomcat-8.5.42.tar.gz [root@node1 tomcat]# 3、启动脚本配置#!/bin/bash source /etc/sysconfig/i18n export JAVA_HOME=/tomcat/jdk1.8.0_51 export PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$PATH --配置启动java export CLASSPATH=.$CLASSPATH:$JAVA_HOME/lib:$JAVA_HOME/jre/lib:$JAVA_HOME/lib/tools.jar export TOMCAT_HOME=/tomcat/apache-tomcat-8.5.42/ export PATH=$PATH:$TOMCAT_HOME/bin #export JAVA_OPTS=&quot;$JAVA_OPTS -Xms10000m -Xmx10000m -Xmn4000m -XX:PermSize=256m -XX:MaxPermSize=512m&quot; -配置程序内存 PROG=&quot;tomcat&quot; IP_ADDR=$(/sbin/ifconfig eth0 | grep &quot;inet addr&quot; | awk &apos;{print $2}&apos; | awk -F &quot;:&quot; &apos;{print $2}&apos;) tomcat_start() ---启动tomcat { rm -fr /tomcat/apache-tomcat-8.5.42/work/* ----删除缓存 rm -fr /tomcat/apache-tomcat-8.5.42/temp/* ----删除临时缓存 echo $&quot;Starting $IP_ADDR $PROG: &quot; cd /tomcat/apache-tomcat-8.5.42/bin/ ./startup.sh echo &quot;tomcat 8 starting......&quot; } tomcat_log() ---查看程序日志 { echo -n $&quot;ShowLoging $IP_ADDR $PROG log: &quot; tail -n200 -f /tomcat/apache-tomcat-8.5.42/logs/catalina.out } tomcat_stop() ---停止tomcat { echo $&quot;Stopping $IP_ADDR $PROG: &quot; kill $(ps -ef | grep java | grep -v &quot;grep&quot; | grep &quot;apache-tomcat&quot; |awk -F &apos; &apos; &apos;{print $2}&apos;) sleep 12 TOMCAT_STATUS1=$(ps -ef | grep java | grep -v &quot;grep&quot;| grep &quot;apache-tomcat&quot;) if [ -n &quot;$TOMCAT_STATUS1&quot; ];then echo &quot;Run Kill -9&quot; kill -9 $(ps -ef | grep java | grep -v &quot;grep&quot; | grep &quot;apache-tomcat&quot; |awk -F &quot; &quot; &apos;{print $2}&apos;) sleep 2 fi TOMCAT_STATUS2=$(ps -ef | grep java | grep -v &quot;grep&quot;| grep &quot;apache-tomcat&quot; ) if [ -z &quot;$TOMCAT_STATUS2&quot; ];then echo &quot;Tomcat Stop ok&quot; else exit 1 fi } tomcat_status() ---查看tomcat程序状态 { ps -ef | grep java | grep -v &quot;grep&quot;| grep &quot;tomcat&quot; } case &quot;$1&quot; in start) tomcat_start; ;; stop) tomcat_stop; ;; restart) tomcat_stop; tomcat_start; ;; status) tomcat_status; ;; log) tomcat_log; ;; *) echo $&quot;Usage: $prog {start | stop | restart | log | status}&quot; exit 1 esac tomcat 需要jdk才能运行，上面解压以后我是在tomcat启动脚本里面配置的jdk目录，也可以定义在系统全局变量里面，但是我不会这么做，因为我们的环境经常是运行多个实例且JDK版本要求不同，如果安装多个jdk会造成全局冲突全局变量定义方式:vim /etc/profile 写入以下内容: export JAVA_HOME=/jboss/jdk1.8.0_51 export CLASSPATH=$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar export JRE_HOME=$JAVA_HOME/jre export PATH=$PATH:$JAVA_HOME/bin source /etc/profile -- 生效配置 验证java [root@node1 ~]# java -version java version &quot;1.8.0_51&quot; Java(TM) SE Runtime Environment (build 1.8.0_51-b16) Java HotSpot(TM) 64-Bit Server VM (build 25.51-b03, mixed mode) [root@node1 ~]# 4、启动tomcat[root@node1 ~]# ./tomcat.sh start ---启动服务 Starting tomcat: Using CATALINA_BASE: /tomcat/apache-tomcat-8.5.42 Using CATALINA_HOME: /tomcat/apache-tomcat-8.5.42 Using CATALINA_TMPDIR: /tomcat/apache-tomcat-8.5.42/temp Using JRE_HOME: /jboss/jdk1.8.0_51/jre Using CLASSPATH: /tomcat/apache-tomcat-8.5.42/bin/bootstrap.jar:/tomcat/apache-tomcat-8.5.42/bin/tomcat-juli.jar Tomcat started. tomcat 8 starting...... [root@node1 ~]# ./tomcat.sh status root 24103 1 0 11:39 ? 00:00:04 /jboss/jdk1.8.0_51/jre/bin/java -Djava.util.logging.config.file=/tomcat/apache-tomcat-8.5.42/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Xms1000m -Xmx1000m -Xmn400m -XX:PermSize=256m -XX:MaxPermSize=512m -Djdk.tls.ephemeralDHKeySize=2048 -Djava.protocol.handler.pkgs=org.apache.catalina.webresources -Dorg.apache.catalina.security.SecurityListener.UMASK=0027 -Dignore.endorsed.dirs= -classpath /tomcat/apache-tomcat-8.5.42/bin/bootstrap.jar:/tomcat/apache-tomcat-8.5.42/bin/tomcat-juli.jar -Dcatalina.base=/tomcat/apache-tomcat-8.5.42 -Dcatalina.home=/tomcat/apache-tomcat-8.5.42 -Djava.io.tmpdir=/tomcat/apache-tomcat-8.5.42/temp org.apache.catalina.startup.Bootstrap start 09-Jul-2019 11:39:42.759 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Server version: Apache Tomcat/8.5.42 09-Jul-2019 11:39:42.763 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Server built: Jun 4 2019 20:29:04 UTC 09-Jul-2019 11:39:42.763 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Server number: 8.5.42.0 09-Jul-2019 11:39:42.763 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log OS Name: Linux 09-Jul-2019 11:39:42.763 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log OS Version: 3.10.0-327.el7.x86_64 09-Jul-2019 11:39:42.763 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Architecture: amd64 09-Jul-2019 11:39:42.763 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Java Home: /jboss/jdk1.8.0_51/jre 09-Jul-2019 11:39:42.763 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log JVM Version: 1.8.0_51-b16 09-Jul-2019 11:39:42.763 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log JVM Vendor: Oracle Corporation 09-Jul-2019 11:39:42.763 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log CATALINA_BASE: /tomcat/apache-tomcat-8.5.42 09-Jul-2019 11:39:42.764 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log CATALINA_HOME: /tomcat/apache-tomcat-8.5.42 09-Jul-2019 11:39:42.764 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Djava.util.logging.config.file=/tomcat/apache-tomcat-8.5.42/conf/logging.properties 09-Jul-2019 11:39:42.764 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager 09-Jul-2019 11:39:42.764 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Xms1000m 09-Jul-2019 11:39:42.764 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Xmx1000m 09-Jul-2019 11:39:42.764 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Xmn400m 09-Jul-2019 11:39:42.764 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -XX:PermSize=256m 09-Jul-2019 11:39:42.764 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -XX:MaxPermSize=512m 09-Jul-2019 11:39:42.764 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Djdk.tls.ephemeralDHKeySize=2048 09-Jul-2019 11:39:42.765 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Djava.protocol.handler.pkgs=org.apache.catalina.webresources 09-Jul-2019 11:39:42.765 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Dorg.apache.catalina.security.SecurityListener.UMASK=0027 09-Jul-2019 11:39:42.765 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Dignore.endorsed.dirs= 09-Jul-2019 11:39:42.765 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Dcatalina.base=/tomcat/apache-tomcat-8.5.42 09-Jul-2019 11:39:42.765 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Dcatalina.home=/tomcat/apache-tomcat-8.5.42 09-Jul-2019 11:39:42.765 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Djava.io.tmpdir=/tomcat/apache-tomcat-8.5.42/temp 09-Jul-2019 11:39:42.765 信息 [main] org.apache.catalina.core.AprLifecycleListener.lifecycleEvent The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib] 09-Jul-2019 11:39:43.048 信息 [main] org.apache.coyote.AbstractProtocol.init Initializing ProtocolHandler [&quot;http-nio-8080&quot;] 09-Jul-2019 11:39:43.071 信息 [main] org.apache.tomcat.util.net.NioSelectorPool.getSharedSelector Using a shared selector for servlet write/read 09-Jul-2019 11:39:43.095 信息 [main] org.apache.coyote.AbstractProtocol.init Initializing ProtocolHandler [&quot;ajp-nio-8009&quot;] 09-Jul-2019 11:39:43.113 信息 [main] org.apache.tomcat.util.net.NioSelectorPool.getSharedSelector Using a shared selector for servlet write/read 09-Jul-2019 11:39:43.124 信息 [main] org.apache.catalina.startup.Catalina.load Initialization processed in 1109 ms 09-Jul-2019 11:39:43.158 信息 [main] org.apache.catalina.core.StandardService.startInternal Starting service [Catalina] 09-Jul-2019 11:39:43.158 信息 [main] org.apache.catalina.core.StandardEngine.startInternal Starting Servlet Engine: Apache Tomcat/8.5.42 09-Jul-2019 11:39:43.207 信息 [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deploying web application directory [/tomcat/apache-tomcat-8.5.42/webapps/ROOT] 09-Jul-2019 11:44:19.656 警告 [localhost-startStop-1] org.apache.catalina.util.SessionIdGeneratorBase.createSecureRandom Creation of SecureRandom instance for session ID generation using [SHA1PRNG] took [276,003] milliseconds. 09-Jul-2019 11:44:19.697 信息 [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deployment of web application directory [/tomcat/apache-tomcat-8.5.42/webapps/ROOT] has finished in [276,491] ms 09-Jul-2019 11:44:19.697 信息 [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deploying web application directory [/tomcat/apache-tomcat-8.5.42/webapps/docs] 09-Jul-2019 11:44:19.739 信息 [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deployment of web application directory [/tomcat/apache-tomcat-8.5.42/webapps/docs] has finished in [42] ms 09-Jul-2019 11:44:19.739 信息 [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deploying web application directory [/tomcat/apache-tomcat-8.5.42/webapps/examples] 09-Jul-2019 11:44:20.212 信息 [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deployment of web application directory [/tomcat/apache-tomcat-8.5.42/webapps/examples] has finished in [473] ms 09-Jul-2019 11:44:20.213 信息 [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deploying web application directory [/tomcat/apache-tomcat-8.5.42/webapps/host-manager] 09-Jul-2019 11:44:20.266 信息 [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deployment of web application directory [/tomcat/apache-tomcat-8.5.42/webapps/host-manager] has finished in [53] ms 09-Jul-2019 11:44:20.266 信息 [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deploying web application directory [/tomcat/apache-tomcat-8.5.42/webapps/manager] 09-Jul-2019 11:44:20.293 信息 [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deployment of web application directory [/tomcat/apache-tomcat-8.5.42/webapps/manager] has finished in [27] ms 09-Jul-2019 11:44:20.314 信息 [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler [&quot;http-nio-8080&quot;] 09-Jul-2019 11:44:20.342 信息 [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler [&quot;ajp-nio-8009&quot;] 09-Jul-2019 11:44:20.344 信息 [main] org.apache.catalina.startup.Catalina.start Server startup in 277219 ms ----看到此输出，程序就已经正常启动 通过浏览器访问tomcat服务,tomcat 默认端口号为8080http://ipaddr:8080 tomcat端口可在/conf/server.xml文件中修改67 Define a non-SSL/TLS HTTP/1.1 Connector on port 8080 68 --&gt; 69 &lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; --将8080修改为80或其他需要的端口 70 connectionTimeout=&quot;20000&quot; 71 redirectPort=&quot;8443&quot; /&gt; 72 &lt;!-- A &quot;Connector&quot; using the shared thread pool--&gt; tomcat已安装完毕5、tomcat目录结构说明bin -- 程序启动目录 conf -- 配置文件目录 lib -- 库文件目录 logs -- 日志文件目录 temp -- 临时缓存目录 webapps -- web 应用家目录 work -- 工作缓存目录]]></content>
      <categories>
        <category>Linux</category>
        <category>Apache</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Apache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Rabbitmq 入门(集群安装篇)]]></title>
    <url>%2F2019%2F07%2F02%2FRabbitmq-%E5%85%A5%E9%97%A8(%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85%E7%AF%87)%2F</url>
    <content type="text"><![CDATA[简介:RabbitMQ是采用Erlang语言实现AMQP（Advanced Message Queuing Protocol，高级消息队列协议）的消息中间件，它最初起源于金融系统，用于在分布式系统中存储转发消息。MQ全称为Message Queue, 消息队列（MQ）是一种应用程序对应用程序的通信方法。应用程序通过读写出入队列的消息（针对应用程序的数据）来通信，而无需专用连接来链接它们。消息传递指的是程序之间通过在消息中发送数据进行通信，而不是通过直接调用彼此来通信，直接调用通常是用于诸如远程过程调用的技术。排队指的是应用程序通过 队列来通信。队列的使用除去了接收和发送应用程序同时执行的要求。其中较为成熟的MQ产品有IBM WEBSPHERE MQ等等。RabbitMQ是目前非常热门的一款消息中间件，很多行业都在使用这个消息中间件，RabbitMQ凭借其高可靠、易扩展、高可用及丰富的功能特性收到很多人的青睐。一、软件下载：下载Erlang 百度云提取码: 864m下载Rabbitmq 源码包 百度云提取码: qwih点击此处跳转到官方网站下载最新版本二、安装环境:node1 172.31.8.8 system Centos 7 —- node3 172.31.8.107 system Centos 7node2 172.31.8.13 system Centos 7 —- node4 172.31.8.75 system Centos 7软件版本：Erlang 21.3rabbitmq 3.7.7三、单点安装(以下操作需要在其他四个节点重复执行)1、分别编辑四台机器的/etc/hosts 文件，增加以下内容172.31.8.8 node1172.31.8.13 node2172.31.8.107 node3172.31.8.75 node42、安装依赖包yum install -y *epel* gcc-c++ unixODBC unixODBC-devel openssl-devel ncurses-devel 3、编译安装 Erlang[root@node1 ~]# tar xf otp_src_21.3.tar.gz [root@node1 ~]# cd otp_src_21.3 [root@node1 otp_src_21.3]# ./configure --prefix=/usr/local/bin/erlang --without-javac [root@node1 otp_src_21.3]# make &amp;&amp; make install [root@node1 otp_src_21.3]# echo &quot;export PATH=$PATH:/usr/local/bin/erlang/bin:/usr/local/bin/rabbitmq_server-3.6.5/sbin&quot; &gt;&gt; /etc/profile [root@node1 otp_src_21.3]# source /etc/profile 查看erlang 是否安装成功，出现以下输出即证明erlang已经安装成功4、安装Rabbitmq[root@node1 ~]# tar xf rabbitmq-server-generic-unix-3.7.7.tar [root@node2 ~]# mv rabbitmq_server-3.7.7 /usr/local/rabbitmq-3.7.7 [root@node2 ~]# cd /usr/local/rabbitmq-3.7.7/ [root@node1 ~]# echo &quot;export PATH=$PATH:/usr/local/rabbitmq-3.7.7/sbin&quot; &gt;&gt; /etc/profile [root@node1 ~]# source /etc/profile [root@node1 ~]# rabbitmq-plugins enable rabbitmq_management ---打开管理页面插件 [root@node1 ~]# rabbitmq-server -detached --后台启动服务 [root@node1 ~]# rabbitmqctl add_user admin 123456 --增加用户名admin，密码123456 [root@node1 ~]# rabbitmqctl set_permissions -p &quot;/&quot; admin &quot;.*&quot; &quot;.*&quot; &quot;.*&quot; [root@node1 ~]# rabbitmqctl set_user_tags admin administrator --设置用户admin为管理员 打开web页面，出现以下页面即安装成功node1node2四、部署集群:1、 修改 .erlang.cookie文件，node1、node4节点内容改为一致[root@node1 ~]# chmod 400 .erlang.cookie --设置.erlang.cookie文件权限,为了防止添加集群失败四个节点均需要调整为一致 [root@node1 ~]# scp .erlang.cookie root@172.31.8.13:/root/ [root@node1 ~]# scp .erlang.cookie root@172.31.8.107:/root/ [root@node1 ~]# scp .erlang.cookie root@172.31.8.75:/root/ 添加集群失败报错示例: 出现此信息可根据提示进行排查2、 替换完.erlang.cookie文件，需要重启各个节点的rabbitmq服务node1 [root@node1 ~]# kill -9 PID [root@node1 ~]# rabbitmq-server -detached node2 [root@node2 ~]# kill -9 PID [root@node2 ~]# rabbitmq-server -detached node3 [root@node3 ~]# kill -9 PID [root@node3 ~]# rabbitmq-server -detached node4 [root@node4 ~]# kill -9 PID [root@node5 ~]# rabbitmq-server -detached 3、添加节点到集群，将node1节点作为主节点在 node2 节点执行以下命令：[root@node2 ~]# rabbitmqctl stop_app [root@node4 ~]# rabbitmqctl join_cluster rabbit@node1 --默认为disc节点，如果需要指定节点角色，可以添加--ram/--disc参数 [root@node4 ~]# rabbitmqctl start_app [root@node4 ~]# rabbitmqctl cluster_status 以上命令在node3、4节点重复执行执行结果:打开web管理页面查看状态到此Rabbitmq集群已经安装完毕，四个节点均已正常运行五、集群管理1、假设Rabbitmq-node2节点需要退出集群在node2节点执行：rabbitmqctl stop_app --停止rabbitmq服务 rabbitmqctl reset --将RabbitMQ node还原到最初状态.包括从所在群集中删除此node,从管理数据库中删除所有配置数据，如已配置的用户和虚拟主机，以及删除所有持久化消息. rabbitmqctl start_app 在主节点（node1）执行rabbitmqctl forget_cluster_node rabbit@node2 --此命令会从集群中删除rabbit@node2节点. 2、修改node2、node4节点为内存节点，在node2、4节点执行:[root@node2 ~]# rabbitmqctl stop_app --停止rabbitmq服务 [root@node2 ~]# rabbitmqctl change_cluster_node_type ram --修改节点为内存节点 [root@node2 ~]# rabbitmqctl start_app --启动服务 [root@node2 ~]# rabbitmqctl cluster_status --查看集群状态 执行结果可以看到node2节点已经修改为RAM节点，disc节点为node1、3、4再修改node4节点：node2、node4节点已经成功修改为内存节点，现在集群就是双内存、双硬盘节点，从控制台查看更为直观:更多管理命令可参考文档:https://blog.csdn.net/wulex/article/details/64127224点击此处查看官方文档]]></content>
      <categories>
        <category>Linux</category>
        <category>Rabbitmq</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Rabbitmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[solr6+tomcat8+zookeeper 环境部署]]></title>
    <url>%2F2019%2F06%2F22%2Fsolr6%2Btomcat8%2Bzookeeper%20%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[安装概述：以下是部署环境：系统环境为：三台系统为Centos 6.8 的服务器主机IP：10.6.11.19 10.6.11.23 10.6.11.22软件环境为：tomcat 8.5.24jdk1.8.0_162solr6.6.3zookeepr-3.4.10tomcat安装不多说，配置java环境即可启动，出现以下画面就说明tomcat服务已经部署完成将solr6部署到tomcat 8 容器内（仅以单节点安装为例，三个节点的安装步骤是一样的）cp -r /home/tomcat/software/solr-6.6.3/server/solr-webapp/webapp /home/tomcat/apache-tomcat-8.5.24-solr/webapps/solr cp -r /home/tomcat/software/solr-6.6.3/server/lib/metrics* /home/tomcat/apache-tomcat-8.5.24-solr/webapps/solr/WEB-INF/lib/ rm -f /home/tomcat/apache-tomcat-8.5.24-solr/webapps/solr/WEB-INF/lib/metrics-jetty9-3.2.2.jar cp -r /home/tomcat/software/solr-6.6.3/server/lib/ext/* /home/tomcat/apache-tomcat-8.5.24-solr/webapps/solr/WEB-INF/lib/ cp -r /home/tomcat/software/solr-6.6.3/dist/solr-dataimporthandler-* /home/tomcat/apache-tomcat-8.5.24-solr/webapps/solr/WEB-INF/lib cp -r /home/tomcat/software/solr-6.6.3/dist/solr-clustering-6.6.3.jar /home/tomcat/apache-tomcat-8.5.24-solr/webapps/solr/WEB-INF/lib mkdir /home/tomcat/apache-tomcat-8.5.24-solr/webapps/solr/WEB-INF/classes cp -r /home/tomcat/software/solr-6.6.3/server/resources/log4j.properties /home/tomcat/apache-tomcat-8.5.24-solr/webapps/solr/WEB-INF/classes 创建solrhome目录mkdir /home/tomcat/apache-tomcat-8.5.24-solr/solrhomecp -r /home/tomcat/software/solr-6.6.3/server/solr/* /home/tomcat/apache-tomcat-8.5.24-solr/solrhome/修改web.xml文件，配置solrhome目录和solr访问权限vim /home/tomcat/apache-tomcat-8.5.24-solr/webapps/solr/WEB-INF/web.xml找到solr/home 根据自己的实际情况配置solr路径&lt;env-entry&gt; &lt;env-entry-name&gt;solr/home&lt;/env-entry-name&gt; &lt;env-entry-value&gt;/home/tomcat/apache-tomcat-8.5.24-solr/solrhome&lt;/env-entry-value&gt; &lt;env-entry-type&gt;java.lang.String&lt;/env-entry-type&gt; &lt;/env-entry&gt; 配置访问权限，注释下图红圈部分内容修改tomcat server.xml文件，配置服务访问端口vim /home/tomcat/apache-tomcat-8.5.24-solr/conf/server.xml&lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; maxHttpHeaderSize=&quot;8192&quot; connectionTimeout=&quot;20000&quot; maxThreads=&quot;150&quot; maxSpareThreads=&quot;75&quot; redirectPort=&quot;8443&quot; /&gt; &lt;!-- A &quot;Connector&quot; using the shared thread pool--&gt; 修改solr配置文件 host设置为本机IP，port设置和tomcat端口一致，均为8080vim /home/tomcat/apache-tomcat-8.5.24-solr/solrhome/solr.xml&lt;solr&gt; &lt;solrcloud&gt; &lt;str name=&quot;host&quot;&gt;${host:10.6.11.19}&lt;/str&gt; &lt;int name=&quot;hostPort&quot;&gt;${jetty.port:8080}&lt;/int&gt; &lt;str name=&quot;hostContext&quot;&gt;${hostContext:solr}&lt;/str&gt; &lt;bool name=&quot;genericCoreNodeNames&quot;&gt;${genericCoreNodeNames:true}&lt;/bool&gt; &lt;int name=&quot;zkClientTimeout&quot;&gt;${zkClientTimeout:30000}&lt;/int&gt; &lt;int name=&quot;distribUpdateSoTimeout&quot;&gt;${distribUpdateSoTimeout:600000}&lt;/int&gt; &lt;int name=&quot;distribUpdateConnTimeout&quot;&gt;${distribUpdateConnTimeout:60000}&lt;/int&gt; &lt;str name=&quot;zkCredentialsProvider&quot;&gt;${zkCredentialsProvider:org.apache.solr.common.cloud.DefaultZkCredentialsProvider}&lt;/str&gt; &lt;str name=&quot;zkACLProvider&quot;&gt;${zkACLProvider:org.apache.solr.common.cloud.DefaultZkACLProvider}&lt;/str&gt; &lt;/solrcloud&gt; &lt;shardHandlerFactory name=&quot;shardHandlerFactory&quot; class=&quot;HttpShardHandlerFactory&quot;&gt; &lt;int name=&quot;socketTimeout&quot;&gt;${socketTimeout:600000}&lt;/int&gt; &lt;int name=&quot;connTimeout&quot;&gt;${connTimeout:60000}&lt;/int&gt; &lt;/shardHandlerFactory&gt; &lt;/solr&gt; 重启tomcat 服务，验证安装访问地址：http://IP:8080/solr/#/出现以上页面，solr就已成功部署到tomcat容器内创建根据需求创建分片,使用以下命令进行创建：http://IP:8080/solr/admin/collections?action=CREATE&amp;name=分片名称&amp;numShards=分片数&amp;replicationFactor=副本数&amp;maxShardsPerNode=节点数&amp;collection.configName=conf目录名称 例如：http://10.6.11.19:8080/solr/admin/collections?action=CREATE&amp;name=user&amp;numShards=2&amp;replicationFactor=3&amp;maxShardsPerNode=3&amp;collection.configName=user 出现以下参数即说明分片创建成功访问http://IP:8080/solr/#/~cloud 验证分片使用此命令创建了两个分片，三个副本一般只可以创建两个副本，增加&amp;maxShardsPerNode=3&amp;collection.configName=user 参数突破副本创建限制]]></content>
      <categories>
        <category>Linux</category>
        <category>搜索</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>solr</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DDOS网络攻击测试工具LOIC]]></title>
    <url>%2F2019%2F06%2F10%2FDDOS%E7%BD%91%E7%BB%9C%E6%94%BB%E5%87%BB%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7LOIC%2F</url>
    <content type="text"><![CDATA[1、简介DoS(Denial Of Service)攻击是指故意的攻击网络协议实现的缺陷或直接通过野蛮手段残忍地耗尽被攻击对象的资源，目的是让目标计算机或网络无法提供正常的服务或资源访问，使目标系统服务系统停止响应甚至崩溃。然而随着网络上免费的可用DDOS工具增多，Dos攻击也日益增长，下面介绍一款Hacker常用的Dos攻击工具LOIC（卢卡）特别提示: 此款工具仅限于教学测试、攻防演练用途，禁止用于非法途径LOIC（卢卡）（Low Orbit Ion Canon）LOTC是一个最受欢迎的DOS攻击工具。 这个工具被去年流行的黑客集团“匿名者”用于对许多大公司的网络攻击。它可以通过使用单个用户执行DOS攻击小型服务器，工具非常易于使用，即便你是一个初学者。 这个工具执行DOS攻击通过发送UDP,TCP或HTTP请求到受害者服务器。 你只需要知道服务器的IP地址或URL.还有其他类似的工具如：XOIC、HULK等等下载地址2、使用方法LOIC 可用于内外网压力测试，下载打开即可直接使用LOIC 应用界面:温馨提示：珍爱生命，远离网络攻击。]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>网络</tag>
        <tag>网络安全</tag>
        <tag>DDOS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jira(安装篇)]]></title>
    <url>%2F2019%2F05%2F21%2Fjira(%E5%AE%89%E8%A3%85%E7%AF%87)%2F</url>
    <content type="text"><![CDATA[一、jira环境需求system： Linuxmemory： 2GBMysql数据库Jdk jdk-8u92-linux-x64.rpmJira atlassian-jira-6.4.12-x64Jira + 数据库连接插件mysql-connector-java-5.1.36-bin部署前机器的内存至少为2GB.否则会出现如下错误：二、安装部署部署前配置 关闭iptables和selinuxservice iptables stop &amp;&amp; setenforce 02.1 jdk安装查看版本号 jdk安装完毕2.2 安装mysql数据库（如果有的可以跳过安装这一步）采用的是yum安装yum install http://www.percona.com/downloads/percona-release/redhat/0.1-3/percona-release-0.1-3.noarch.rpmyum install Percona-Server-server-56初始化mysql数据库，创建账户并赋予链接权限创建jira库和jira用户create database jiradb character set utf8; grant select,insert,update,delete,create,drop,alter,index on jiradb.* to &apos;jira&apos;@&apos;localhost&apos; identified by &apos;jira&apos;; flush privileges; 退出，使用jira账户进行登陆测试mysql –ujira –p 下载mysql-connector-java-5.1.39.tar.gz 连接2.3 安装jira上传jira文件Chmod +x./Jira web访问端口为8080由于jira默认是不支持使用mysql数据库的，如果用mysql的话就得把链接插件放到以下目录，并重启jira上传mysql – jira 连接插件cd /opt/atlassian/jira/atlassian-jira/WEB-INF/lib/上传文件cd /opt/atlassian/jira/atlassian-jira/WEB-INF/lib/上传中文语言包删除 cd /var/atlassian/application-data/jira/打开浏览器，开始设置向导连接数据库选择模式装的过程中需要在官网获取试用序列号，然后进行破解！！]]></content>
      <categories>
        <category>Linux</category>
        <category>jira</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>jira</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix 缓存数据清理]]></title>
    <url>%2F2019%2F05%2F20%2FZabbix-%E7%BC%93%E5%AD%98%E6%95%B0%E6%8D%AE%E6%B8%85%E7%90%86%2F</url>
    <content type="text"><![CDATA[zabbix监控运行一段时间以后，会留下大量的历史监控数据，zabbix数据库一直在增大；可能会造成系统性能下降，查看历史数据室查询速度缓慢。zabbix里面最大的表就是history和history_uint两个表，而且zabbix里面的时间是使用的时间戳方式记录，所以可以根据时间戳来删除历史数据一、关闭zabbix、http服务pkill -9 zabbix service httpd stop 二、清理zabbix历史数据1、查看数据库目录文件[root@zabbix-server zabbix]# cd /var/lib/mysql/zabbix/ [root@zabbix-server zabbix]# ls -lh | grep G total 177G -rw-r----- 1 mysql mysql 1.7G Dec 24 13:49 events.ibd -rw-r----- 1 mysql mysql 60G Dec 24 13:49 history.ibd -rw-r----- 1 mysql mysql 2.4G Dec 24 13:49 history_str.ibd -rw-r----- 1 mysql mysql 99G Dec 24 13:49 history_uint.ibd -rw-r----- 1 mysql mysql 4.6G Dec 24 13:02 trends.ibd -rw-r----- 1 mysql mysql 9.5G Dec 24 13:49 trends_uint.ibd [root@zabbix-server zabbix]# 生成Unix时间戳。时间定为2018年2月1日（暂定是保存18年2月以后的监控数据）[root@zabbix-server zabbix]# date +%s -d &quot;Feb 1, 2018 00:00:00&quot; #执行此命令以后会生成一个ID 1517414400 #这是生成的ID 2、数据备份[root@zabbix-server zabbix]#mysql -uroot -p zabbix &gt; /root/mysqlback/zabbix.sql #需要创建mysqlback目录 3、 登录数据库[root@zabbix-server zabbix]# mysql -uroot -p Enter password: Welcome to the MariaDB monitor. Commands end with ; or \g. Your MariaDB connection id is 7 Server version: 5.5.60-MariaDB MariaDB Server Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others. Type &apos;help;&apos; or &apos;\h&apos; for help. Type &apos;\c&apos; to clear the current input statement. MariaDB [(none)]&gt; use zabbix; #选择zabbix数据库 执行sql查看指定日期之前的数据大小：SELECT table_schema as `Database`,table_name AS `Table`,round(((data_length + index_length) / 1024 / 1024 / 1024), 2) `Size in MB`FROM information_schema.TABLES where CREATE_TIME &lt; &apos;2018-02-01 00:00:00&apos; and table_name=&apos;history.ibd&apos;; 根据需要修改日期和查询的表名称(如果查询出来的结果是0.0，需要将sql中的三个1024删除一个，以G为单位显示)4、 执行以下命令，清理指定时间之前的数据、对zabbix数据库执行以下sqldelete from history where clock &lt; 1517414400; optimize table history; delete from history_uint where clock &lt; 1517414400; optimize table history_uint; delete from trends where clock &lt; 1517414400; optimize table trends; delete from trends_uint where clock &lt; 1517414400; optimize table trends_uint; 注意：sql中的ID是生成Unix时间戳的ID号,需要改为自己生成的ID号三、启动服务/usr/sbin/zabbix_server -c /etc/zabbix/zabbix_server.conf #zabbix server /usr/sbin/zabbix_agentd -c /etc/zabbix/zabbix_agentd.conf #zabbix agent service httpd start ===============================分===========隔==========符===================================1、使用truncate命令清空zabbix 所有监控数据------------------------------------------------------- truncate table history; optimize table history; ------------------------------------------------------- truncate table history_str; optimize table history_str; ------------------------------------------------------- truncate table history_uint; optimize table history_uint; ------------------------------------------------------- truncate table trends; optimize table trends; ------------------------------------------------------- truncate table trends_uint; optimize table trends_uint; ------------------------------------------------------- truncate table events; optimize table events; ------------------------------------------------------- 注意：这些命令会把zabbix所有的监控数据清空，操作前注意备份数据库truncate是删除了表，然后根据表结构重新建立，delete删除的是记录的数据没有修改表truncate执行删除比较快，但是在事务处理安全性方面不如delete,如果我们执行truncat的表正在处理事务，这个命令退出并会产生错误信息]]></content>
      <categories>
        <category>Linux</category>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis 故障恢复]]></title>
    <url>%2F2019%2F05%2F10%2FRedis-%E6%95%85%E9%9A%9C%E6%81%A2%E5%A4%8D%2F</url>
    <content type="text"><![CDATA[案例一、ResponseError: MISCONF Redis is configured to save RDB snapshots, but is currently not able to persist on disk.Commands that may modify the data set are disabled. Please check Redis logs for details about the error.Redis被配置为保存数据库快照，但它目前不能持久化到硬盘。用来修改集合数据的命令不能用。请查看Redis日志的详细错误信息。原因：强制关闭redis快照导致不能持久化解决方案：将：stop-writes-on-bgsave-error 设置为 no]]></content>
      <categories>
        <category>Linux</category>
        <category>redis</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Python统计nginx日志前十个IP的访问量，并以柱状图显示]]></title>
    <url>%2F2018%2F12%2F28%2F%E4%BD%BF%E7%94%A8Python%E7%BB%9F%E8%AE%A1nginx%E6%97%A5%E5%BF%97%E5%89%8D%E5%8D%81%E4%B8%AAIP%E7%9A%84%E8%AE%BF%E9%97%AE%E9%87%8F%EF%BC%8C%E5%B9%B6%E4%BB%A5%E6%9F%B1%E7%8A%B6%E5%9B%BE%E6%98%BE%E7%A4%BA%2F</url>
    <content type="text"><![CDATA[1、脚本代码可参考本人博客园文章import matplotlib.pyplot as plt nginx_file = &apos;&apos; --填写nginx日志文件名，需在同一目录 ip = {} #筛选nginx日志文件中的IP with open(nginx_file) as f: for i in f.readlines(): s = i.strip().split()[0] lengh = len(ip.keys()) #统计每个IP的访问以字典存储 if s in ip.keys(): ip[s] = ip[s] + 1 else: ip[s] = 1 #以IP出现的次数排序返回对象为list ip = sorted(ip.items(), key=lambda e:e[1], reverse=True) #取列表前十 newip = ip[0:20:1] tu = dict(newip) x = [] y = [] for k in tu: x.append(k) y.append(tu[k]) plt.title(&apos;ip access&apos;) plt.xlabel(&apos;ip address&apos;) plt.ylabel(&apos;pv&apos;) #X 轴项的翻转角度 plt.xticks(rotation=70) #显示每个柱状图的值 for a,b in zip(x,y): plt.text(a, b, &apos;%.0f&apos; % b, ha=&apos;center&apos;, va= &apos;bottom&apos;,fontsize=7) plt.bar(x,y) plt.legend() plt.show() 2、效果图:]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PTES渗透测试执行标准]]></title>
    <url>%2F2018%2F09%2F17%2FPTES%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E6%89%A7%E8%A1%8C%E6%A0%87%E5%87%86%2F</url>
    <content type="text"><![CDATA[渗透测试注意事项：1、不要进行恶意攻击2、不要做傻事3、在没有获得书面授权时，不要攻击任何目标4、考虑清楚攻击将会带来的后果4、如果干了非法的事情，记得天网恢恢疏而不漏参考官方对于渗透测试执行标准描述（PTES）一：前期交互阶段在前期交互阶段，渗透测试团队与客户组织进行交互讨论，最重要的是确定渗透测试的范围、目标、限制条件以及合同细节该阶段通常涉及收集客户需求，准备测试计划、定义测试范围与边界、定义业务目标、项目管理与规划等活动二：情报收集阶段在目标范围确定之后，将进入情报搜集（Information Gathering）阶段，渗透团队可以利用各种信息来源与搜集技术方法，尝试更多关于组织网络拓扑、系统配置与安全防御措施的信息。渗透测试者可以使用情报搜集方法包括公开来源信息查询、google Hacking 、社会工程学、网络踩点、扫描探测、被动监听、服务查点等。而对目标系统的情报探查能力是渗透者一项非常重要的技能，情报搜集是否充分在很大程度上决定了渗透测的成败，因为如果你遗漏关键的情报信息，你将可能在后面的阶段一无所获。三：威胁建模阶段在搜集到充分的情报信息之后，渗透测试团队的成员们停下敲击键盘，大家聚到一起针对获取的信息进行威胁建模（Threat Modeling）与攻击规划。这是渗透测试过程中非常重要，但很容易被忽视的一个关键点。通过团队共同的缜密情报分析与攻击思路头脑风暴，可以从大量的信息情报中理清头绪，确定出最可行的攻击通道。四：漏洞分析阶段在确定出最可行的攻击通道之后，接下来需要考虑该如何取得目标系统的访问控制权，即漏洞分析（Vulnerability Analysis）阶段。在该阶段，渗透测试者需要综合分析前几个阶段获取并汇总的情报信息，特别是安全漏洞扫描结果、服务查点信息等，通过搜索可获取的渗透代码资源，找出可以实施渗透攻击的攻击点，并在实验环境中进行验证。在该阶段，高水平的渗透测试团队还会针对攻击通道上的一些关键系统与服务进行安全漏洞探测与挖掘，期望找出可被利用的未知安全漏洞，并开发出渗透代码，从而打开攻击通道上的关键路径。五：渗透攻击阶段渗透攻击（Exploitation）是渗透测试过程中最具有魅力的环节。在此环节中，渗透测试团队需要利用他们所找出的目标系统安全漏洞，来真正入侵系统当中，获得访问控制权。渗透攻击可以利用公开渠道可获取的渗透代码，但一般在实际应用场景中，渗透测试者还需要充分地考虑目标系统特性来定制渗透攻击，并需要挫败目标网络与系统中实施的安全防御措施，才能成功达成渗透目的。在黑盒测试中，渗透测试者还需要考虑对目标系统检测机制的逃逸，从而避免造成目标组织安全响应团队的警觉和发现六：后渗透攻击阶段后渗透攻击（Post Exploitation）是整个渗透测试过程中最能够体现渗透测试团队创造力与技术能力的环节。前面的环节可以说都是在按部就班地完成非常普遍的目标，而在这个环节中，需要渗透测试团队根据目标组织的业务经营模式、保护资产形式与安全防御计划的不同特点，自主设计出攻击目标，识别关键基础设施，并寻找客户组织最具价值和尝试安全保护的信息和资产，最终达成能够对客户组织造成最重要业务影响的攻击途径。在不同的渗透测试场景中，这些攻击目标与途径可能是千变万化的，而设置是否准确并且可行，也取决于团队自身的创新意识、知识范畴、实际经验和技术能力。七：报告阶段渗透测试过程最终向客户组织提交，取得认可并成功获得合同付款的就是一份渗透测试报告（Reporting）。这份报告凝聚了之前所有阶段之中渗透测试团队所获取的关键情报信息、探测和发掘出的系统安全漏洞、成功渗透攻击的过程，以及造成业务影响后果的攻击途径，同时还要站在防御者的角度上，帮助他们分析安全防御体系中的薄弱环节、存在的问题，以及修补与升级技术方案。八：渗透术语：渗透攻击（Exploit）攻击者利用安全漏洞，所进行的攻击行为，常见的渗透攻击技术包括缓冲区溢出、web应用程序漏洞攻击（SQL注入）、利用配置错误等攻击载荷（Payload）目标系统在被渗透攻击之后执行的代码Shellcode在渗透攻击时作为攻击载荷运行的一组机器指令，通常用汇编语言编写模块（Module）一段软件代码组件监听器（Listener）用来等待连入网络链接的组件]]></content>
      <categories>
        <category>信息安全</category>
        <category>渗透测试</category>
      </categories>
      <tags>
        <tag>信息安全</tag>
        <tag>渗透测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[(二)、Ansible在使用过程中出现的错误解决方法]]></title>
    <url>%2F2018%2F09%2F02%2F%E4%BA%8C-%E3%80%81Ansible%E5%9C%A8%E4%BD%BF%E7%94%A8%E8%BF%87%E7%A8%8B%E4%B8%AD%E5%87%BA%E7%8E%B0%E7%9A%84%E9%94%99%E8%AF%AF%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[1.安装完成后允许命令出错Traceback (most recent call last): File &quot;/usr/bin/ansible&quot;, line 197, in &lt;module&gt; (runner, results) = cli.run(options, args) File &quot;/usr/bin/ansible&quot;, line 163, in run extra_vars=extra_vars, File &quot;/usr/lib/python2.6/site-packages/ansible/runner/__init__.py&quot;, line 233, in __init__ cmd = subprocess.Popen([&apos;ssh&apos;,&apos;-o&apos;,&apos;ControlPersist&apos;], stdout=subprocess.PIPE, stderr=subprocess.PIPE) File &quot;/usr/lib64/python2.6/subprocess.py&quot;, line 639, in __init__ errread, errwrite) File &quot;/usr/lib64/python2.6/subprocess.py&quot;, line 1228, in _execute_child raise child_exception OSError: [Errno 2] No such file or directory 解决办法yum -y install openssh-clients2.出现Error: ansible requires a json module, none found!SSH password: 10.0.1.110 | FAILED &gt;&gt; { &quot;failed&quot;: true, &quot;msg&quot;: &quot;Error: ansible requires a json module, nonefound!&quot;, &quot;parsed&quot;: false } 解决办法python版本过低，可以升级python或者python-simplejson3.安装完成后链接客户端报错（配图为我在使用ansible推送文件到客户端的时候遇到的，这个客户端是第一次推送）FAILED =&gt; Using a SSH password insteadof a key is not possible because Host Key checking is enabled and sshpass doesnot support this. Please add this host&apos;sfingerprint to your known_hosts file to manage this host. 解决办法：在ansible 服务器上使用ssh 登陆下/etc/ansible/hosts 里面配置的服务器。然后再次使用ansible 去管理就不会报上面的错误了！但这样大批量登陆就麻烦来。因为默认ansible是使用key验证的，如果使用密码登陆的服务器，使用ansible的话，要不修改ansible.cfg配置文件的ask_pass = True给取消注释，要不就在运行命令时候加上-k，这个意思是-k, –ask-pass ask for SSH password。再修改：host_key_checking= False即可4.如果客户端不在know_hosts里将会报错paramiko: The authenticity of host &apos;192.168.24.15&apos;can&apos;t be established. The ssh-rsa key fingerprint is397c139fd4b0d763fcffaee346a4bf6b. Are you sure you want to continueconnecting (yes/no)? 解决办法需要修改ansible.cfg的#host_key_checking= False取消注释5.出现FAILED =&gt; FAILED: not a valid DSA private key file解决办法：需要你在最后命令内添加参数-k6.openssh升级后无法登录报错PAM unable todlopen(/lib64/security/pam_stack.so): /lib64/security/pam_stack.so: cannot openshared object file: No such file or directory 解决方法：sshrpm 升级后会修改/etc/pam.d/sshd 文件。需要升级前备份此文件最后还原即可登录。7.第一次系统初始化运行生成本机ansible用户key时报错failed: [127.0.0.1] =&gt;{&quot;checksum&quot;: &quot;f5f2f20fc0774be961fffb951a50023e31abe920&quot;,&quot;failed&quot;: true} msg: Aborting, target uses selinux but pythonbindings (libselinux-python) aren&apos;t installed! FATAL: all hosts have already failed –aborting 解决办法yum -y install libselinux-python参考: http://blog.csdn.net/longxibendi/article/details/46989735]]></content>
      <categories>
        <category>自动化</category>
      </categories>
      <tags>
        <tag>自动化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible]]></title>
    <url>%2F2018%2F09%2F01%2FAnsible%2F</url>
    <content type="text"><![CDATA[1、ansible介绍：Ansible是一款基于Python开发的自动化运维工具，主要是实现批量系统配置、批量程序部署、批量运行命令、批量执行任务等等诸多功能。Ansible是一款灵活的开源工具，能够很大程度简化运维中的配置管理与流程控制方式，它利用推送方式对客户系统加以配置，这样所有工作都可在主服务器端完成。Asible是基于模块工作的，其本身没有批量部署的能力，Ansible~一款运维自动化的软件！1.1特性(1)、no agents：不需要在被管控主机上安装任何客户端；(2)、no server：无服务器端，使用时直接运行命令即可；(3)、modules in any languages：基于模块工作，可使用任意语言开发模块；(4)、yaml，not code：使用yaml语言定制剧本playbook；(5)、ssh by default：基于SSH工作；(6)、strong multi-tier solution：可实现多级指挥。1.1 优点(1)、轻量级，无需在客户端安装agent，更新时，只需在操作机上进行一次更新即可；(2)、批量任务执行可以写成脚本，而且不用分发到远程就可以执行；(3)、使用python编写，维护更简单，ruby语法过于复杂；(4)、支持sudo。2、ansible安装安装epel 源：rpm -ivh https://dl.fedoraproject.org/pub/epel/epel-release-latest-6.noarch.rpm安装ansible ：yum install ansible -yssh-keygen 生成秘钥文件,如果不想输入密码可以一直回车ssh-keygen -t rsacd /root/.ssh/ &amp;&amp; ll ./*配置ansible 的hosts 文件：vim /etc/ansible/hosts]]></content>
      <categories>
        <category>自动化</category>
      </categories>
      <tags>
        <tag>自动化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 系统安全检查（shell）]]></title>
    <url>%2F2018%2F04%2F22%2FLinux%20%E7%B3%BB%E7%BB%9F%E5%AE%89%E5%85%A8%E6%A3%80%E6%9F%A5%EF%BC%88shell%EF%BC%89%2F</url>
    <content type="text"><![CDATA[脚本内容:#!/bin/bash echo &quot; (__)&quot; echo &quot; (oo)&quot; echo &quot; /------\/ &quot; echo &quot; / | || &quot; echo &quot; * /\---/\ &quot; echo &quot; ~~ ~~ &quot; echo &quot;Are You Ready?&quot; read key echo &quot;警告：本脚本只作为日常巡检使用，不会对服务器做任何修改，管理员可以根据此报告进行相应的设置。&quot; echo ------------------------------------------------------------------------ echo &quot;查看系统时间&quot; DATE=`date` echo &quot;Date is $DATE&quot; echo ------------------------------------------------------------------------ echo &quot;进行系统时间同步&quot; ntpdate time.nist.gov echo ------------------------开始进行检查---------------------- echo &quot;检查时间为&quot; DATE=`date` echo &quot;Date is $DATE&quot; echo ------------------------主机基本信息检查----------------------- echo &quot;系统版本（Centos或Rehead）&quot; cat /etc/redhat-release echo -------------------------------------------------------------------------- echo &quot;系统位数（32位或64位）&quot; getconf LONG_BIT echo -------------------------检查IP信息----------------------------------------- echo &quot;本机的ip地址是：&quot; ifconfig | grep --color &quot;\([0-9]\{1,3\}\.\)\{3\}[0-9]\{1,3\}&quot; echo -------------------------检查系统用户信息--------------------------------------- awk -F&quot;:&quot; &apos;{if($2!~/^!|^*/){print &quot;(&quot;$1&quot;)&quot; &quot; 是一个未被锁定的账户，请管理员检查是否需要锁定它或者删除它。&quot;}}&apos; /etc/shadow echo -------------------------------------------------------------------------- more /etc/login.defs | grep -E &quot;PASS_MAX_DAYS&quot; | grep -v &quot;#&quot; |awk -F&apos; &apos; &apos;{if($2!=90){print &quot;/etc/login.defs里面的&quot;$1 &quot;设置的是&quot;$2&quot;天，请管理员改成90天。&quot;}}&apos; echo -------------------------------------------------------------------------- more /etc/login.defs | grep -E &quot;PASS_MIN_LEN&quot; | grep -v &quot;#&quot; |awk -F&apos; &apos; &apos;{if($2!=6){print &quot;/etc/login.defs里面的&quot;$1 &quot;设置的是&quot;$2&quot;个字符，请管理员改成6个字符。&quot;}}&apos; echo -------------------------------------------------------------------------- more /etc/login.defs | grep -E &quot;PASS_WARN_AGE&quot; | grep -v &quot;#&quot; |awk -F&apos; &apos; &apos;{if($2!=10){print &quot;/etc/login.defs里面的&quot;$1 &quot;设置的是&quot;$2&quot;天，请管理员将口令到期警告天数改成10天。&quot;}}&apos; echo -------------------------------------------------------------------------- grep TMOUT /etc/profile /etc/bashrc &gt; /dev/null|| echo &quot;未设置登录超时限制，请设置之，设置方法：在/etc/profile或者/etc/bashrc里面添加TMOUT=600参数&quot; echo ------------------------检查服务运行情况----------------------------------- if ps -elf |grep xinet |grep -v &quot;grep xinet&quot;;then echo &quot;xinetd 服务正在运行，请检查是否可以把xinnetd服务关闭&quot; else echo &quot;xinetd 服务未开启&quot; fi echo -------------------------------------------------------------------------- echo &quot;查看系统密码文件修改时间&quot; ls -ltr /etc/passwd echo -------------------------------------------------------------------------- echo &quot;查看是否开启了ssh服务&quot; if service sshd status | grep -E &quot;listening on|active \(running\)&quot;; then echo &quot;SSH服务已开启&quot; else echo &quot;SSH服务未开启&quot; fi echo -------------------------------------------------------------------------- echo &quot;查看是否开启了TELNET服务&quot; if more /etc/xinetd.d/telnetd 2&gt;&amp;1|grep -E &quot;disable=no&quot;; then echo &quot;TELNET服务已开启 &quot; else echo &quot;TELNET服务未开启 &quot; fi echo -------------------------------------------------------------------------- echo &quot;查看系统SSH远程访问设置策略(host.deny拒绝列表)&quot; if more /etc/hosts.deny | grep -E &quot;sshd: &quot;;more /etc/hosts.deny | grep -E &quot;sshd&quot;; then echo &quot;远程访问策略已设置 &quot; else echo &quot;远程访问策略未设置 &quot; fi echo -------------------------------------------------------------------------- echo &quot;查看系统SSH远程访问设置策略(hosts.allow允许列表)&quot; if more /etc/hosts.allow | grep -E &quot;sshd: &quot;;more /etc/hosts.allow | grep -E &quot;sshd&quot;; then echo &quot;远程访问策略已设置 &quot; else echo &quot;远程访问策略未设置 &quot; fi echo &quot;当hosts.allow和 host.deny相冲突时，以hosts.allow设置为准。&quot; echo ------------------------------------------------------------------------- echo &quot;查看shell是否设置超时锁定策略&quot; if more /etc/profile | grep -E &quot;TIMEOUT= &quot;; then echo &quot;系统设置了超时锁定策略 &quot; else echo &quot;未设置超时锁定策略 &quot; fi echo ------------------------------------------------------------------------- echo &quot;查看syslog日志审计服务是否开启&quot; if service syslog status | egrep &quot; active \(running&quot;;then echo &quot;syslog服务已开启&quot; else echo &quot;syslog服务未开启，建议通过service syslog start开启日志审计功能&quot; fi echo ------------------------------------------------------------------------- echo &quot;查看syslog日志是否开启外发&quot; if more /etc/rsyslog.conf | egrep &quot;@...\.|@..\.|@.\.|\*.\* @...\.|\*\.\* @..\.|\*\.\* @.\.&quot;;then echo &quot;客户端syslog日志已开启外发&quot; else echo &quot;客户端syslog日志未开启外发&quot; fi echo ------------------------------------------------------------------------- echo &quot;查看passwd文件中有哪些特权用户&quot; awk -F: &apos;$3==0 {print $1}&apos; /etc/passwd echo ------------------------------------------------------------------------ echo &quot;查看系统中是否存在空口令账户&quot; awk -F: &apos;($2==&quot;!!&quot;) {print $1}&apos; /etc/shadow echo &quot;该结果不适用于Ubuntu系统&quot; echo ------------------------------------------------------------------------ echo &quot;查看系统中root用户外连情况&quot; lsof -u root |egrep &quot;ESTABLISHED|SYN_SENT|LISTENING&quot; echo ----------------------------状态解释------------------------------ echo &quot;ESTABLISHED的意思是建立连接。表示两台机器正在通信。&quot; echo &quot;LISTENING的&quot; echo &quot;SYN_SENT状态表示请求连接&quot; echo ------------------------------------------------------------------------ echo &quot;查看系统中root用户TCP连接情况&quot; lsof -u root |egrep &quot;TCP&quot; echo ------------------------------------------------------------------------ echo &quot;查看系统中存在哪些非系统默认用户&quot; echo &quot;root:x:“该值大于500为新创建用户，小于或等于500为系统初始用户”&quot; more /etc/passwd |awk -F &quot;:&quot; &apos;{if($3&gt;500){print &quot;/etc/passwd里面的&quot;$1 &quot;的值为&quot;$3&quot;，请管理员确认该账户是否正常。&quot;}}&apos; echo ------------------------------------------------------------------------ echo &quot;检查系统守护进程&quot; more /etc/xinetd.d/rsync | grep -v &quot;^#&quot; echo ------------------------------------------------------------------------ echo &quot;检查系统是否存在入侵行为&quot; more /var/log/secure |grep refused echo ------------------------------------------------------------------------ echo &quot;-----------------------检查系统是否存在PHP脚本后门---------------------&quot; if find / -type f -name *.php | xargs egrep -l &quot;mysql_query\($query, $dbconn\)|专用网马|udf.dll|class PHPzip\{|ZIP压缩程序 荒野无灯修改版|$writabledb|AnonymousUserName|eval\(|Root_CSS\(\)|黑狼PHP木马|eval\(gzuncompress\(base64_decode|if\(empty\($_SESSION|$shellname|$work_dir |PHP木马|Array\(&quot;$filename&quot;| eval\($_POST\[|class packdir|disk_total_space|wscript.shell|cmd.exe|shell.application|documents and settings|system32|serv-u|提权|phpspy|后门&quot; |sort -n|uniq -c |sort -rn 1&gt;/dev/null 2&gt;&amp;1;then echo &quot;检测到PHP脚本后门&quot; find / -type f -name *.php | xargs egrep -l &quot;mysql_query\($query, $dbconn\)|专用网马|udf.dll|class PHPzip\{|ZIP压缩程序 荒野无灯修改版|$writabledb|AnonymousUserName|eval\(|Root_CSS\(\)|黑狼PHP木马|eval\(gzuncompress\(base64_decode|if\(empty\($_SESSION|$shellname|$work_dir |PHP木马|Array\(&quot;$filename&quot;| eval\($_POST\[|class packdir|disk_total_space|wscript.shell|cmd.exe|shell.application|documents and settings|system32|serv-u|提权|phpspy|后门&quot; |sort -n|uniq -c |sort -rn find / -type f -name *.php | xargs egrep -l &quot;mysql_query\($query, $dbconn\)|专用网马|udf.dll|class PHPzip\{|ZIP压缩程序 荒野无灯修改版|$writabledb|AnonymousUserName|eval\(|Root_CSS\(\)|黑狼PHP木马|eval\(gzuncompress\(base64_decode|if\(empty\($_SESSION|$shellname|$work_dir |PHP木马|Array\(&quot;$filename&quot;| eval\($_POST\[|class packdir|disk_total_space|wscript.shell|cmd.exe|shell.application|documents and settings|system32|serv-u|提权|phpspy|后门&quot; |sort -n|uniq -c |sort -rn |awk &apos;{print $2}&apos; | xargs -I{} cp {} /tmp/ echo &quot;后门样本已拷贝到/tmp/目录&quot; else echo &quot;未检测到PHP脚本后门&quot; fi echo ------------------------------------------------------------------------ echo &quot;-----------------------检查系统是否存在JSP脚本后门---------------------&quot; find / -type f -name *.jsp | xargs egrep -l &quot;InputStreamReader\(this.is\)|W_SESSION_ATTRIBUTE|strFileManag|getHostAddress|wscript.shell|gethostbyname|cmd.exe|documents and settings|system32|serv-u|提权|jspspy|后门&quot; |sort -n|uniq -c |sort -rn 2&gt;&amp;1 find / -type f -name *.jsp | xargs egrep -l &quot;InputStreamReader\(this.is\)|W_SESSION_ATTRIBUTE|strFileManag|getHostAddress|wscript.shell|gethostbyname|cmd.exe|documents and settings|system32|serv-u|提权|jspspy|后门&quot; |sort -n|uniq -c |sort -rn| awk &apos;{print $2}&apos; | xargs -I{} cp {} /tmp/ 2&gt;&amp;1 echo ------------------------------------------------------------------------ echo &quot;----------------------检查系统是否存在HTML恶意代码---------------------&quot; if find / -type f -name *.html | xargs egrep -l &quot;WriteData|svchost.exe|DropPath|wsh.Run|WindowBomb|a1.createInstance|CurrentVersion|myEncString|DropFileName|a = prototype;|204.351.440.495.232.315.444.550.64.330&quot; 1&gt;/dev/null 2&gt;&amp;1;then echo &quot;发现HTML恶意代码&quot; find / -type f -name *.html | xargs egrep -l &quot;WriteData|svchost.exe|DropPath|wsh.Run|WindowBomb|a1.createInstance|CurrentVersion|myEncString|DropFileName|a = prototype;|204.351.440.495.232.315.444.550.64.330&quot; |sort -n|uniq -c |sort -rn find / -type f -name *.html | xargs egrep -l &quot;WriteData|svchost.exe|DropPath|wsh.Run|WindowBomb|a1.createInstance|CurrentVersion|myEncString|DropFileName|a = prototype;|204.351.440.495.232.315.444.550.64.330&quot; |sort -n|uniq -c |sort -rn| awk &apos;{print $2}&apos; | xargs -I{} cp {} /tmp/ echo &quot;后门样本已拷贝到/tmp/目录&quot; else echo &quot;未检测到HTML恶意代码&quot; fi echo &quot;----------------------检查系统是否存在perl恶意程序----------------------&quot; if find / -type f -name *.pl | xargs egrep -l &quot;SHELLPASSWORD|shcmd|backdoor|setsockopt|IO::Socket::INET;&quot; 1&gt;/dev/null 2&gt;&amp;1;then echo &quot;发现perl恶意程序&quot; find / -type f -name *.pl | xargs egrep -l &quot;SHELLPASSWORD|shcmd|backdoor|setsockopt|IO::Socket::INET;&quot;|sort -n|uniq -c |sort -rn find / -type f -name *.pl | xargs egrep -l &quot;SHELLPASSWORD|shcmd|backdoor|setsockopt|IO::Socket::INET;&quot;|sort -n|uniq -c |sort -rn| awk &apos;{print $2}&apos; | xargs -I{} cp {} /tmp/ echo &quot;可疑样本已拷贝到/tmp/目录&quot; else echo &quot;未检测到perl恶意程序&quot; fi echo &quot;----------------------检查系统是否存在Python恶意程序----------------------&quot; find / -type f -name *.py | xargs egrep -l &quot;execCmd|cat /etc/issue|getAppProc|exploitdb&quot; |sort -n|uniq -c |sort -rn find / -type f -name *.py | xargs egrep -l &quot;execCmd|cat /etc/issue|getAppProc|exploitdb&quot; |sort -n|uniq -c |sort -rn| awk &apos;{print $2}&apos; | xargs -I{} cp {} /tmp/ echo ------------------------------------------------------------------------ echo &quot;-----------------------检查系统是否存在恶意程序---------------------&quot; find / -type f -perm -111 |xargs egrep &quot;UpdateProcessER12CUpdateGatesE6C|CmdMsg\.cpp|MiniHttpHelper.cpp|y4&apos;r3 1uCky k1d\!|execve@@GLIBC_2.0|initfini.c|ptmalloc_unlock_all2|_IO_wide_data_2|system@@GLIBC_2.0|socket@@GLIBC_2.0|gettimeofday@@GLIBC_2.0|execl@@GLIBC_2.2.5|WwW.SoQoR.NeT|2.6.17-2.6.24.1.c|Local Root Exploit|close@@GLIBC_2.0|syscall\(\__NR\_vmsplice,|Linux vmsplice Local Root Exploit|It looks like the exploit failed|getting root shell&quot; 2&gt;/dev/null echo ------------------------------------------------------------------------ echo &quot;检查网络连接和监听端口&quot; netstat -an echo &quot;--------------------------路由表、网络连接、接口信息--------------&quot; netstat -rn echo &quot;------------------------查看网卡详细信息--------------------------&quot; ifconfig -a echo ------------------------------------------------------------------------ echo &quot;查看正常情况下登录到本机的所有用户的历史记录&quot; last echo ------------------------------------------------------------------------ echo &quot;检查系统中core文件是否开启&quot; ulimit -c echo &quot;core是unix系统的内核。当你的程序出现内存越界的时候,操作系统会中止你的进程,并将当前内存状态倒出到core文件中,以便进一步分析，如果返回结果为0，则是关闭了此功能，系统不会生成core文件&quot; echo ------------------------------------------------------------------------ echo &quot;检查系统中关键文件修改时间&quot; ls -ltr /bin/ls /bin/login /etc/passwd /bin/ps /usr/bin/top /etc/shadow|awk &apos;{print &quot;文件名：&quot;$8&quot; &quot;&quot;最后修改时间：&quot;$6&quot; &quot;$7}&apos; echo &quot;ls文件：是存储ls命令的功能函数，被删除以后，就无法执行ls命令，黑客可利用篡改ls文件来执行后门或其他程序。 login文件：login是控制用户登录的文件，一旦被篡改或删除，系统将无法切换用户或登陆用户 user/bin/passwd是一个命令，可以为用户添加、更改密码，但是，用户的密码并不保存在/etc/passwd当中，而是保存在了/etc/shadow当中 etc/passwd是一个文件，主要是保存用户信息。 sbin/portmap是文件转换服务，缺少该文件后，无法使用磁盘挂载、转换类型等功能。 bin/ps 进程查看命令功能支持文件，文件损坏或被更改后，无法正常使用ps命令。 usr/bin/top top命令支持文件，是Linux下常用的性能分析工具,能够实时显示系统中各个进程的资源占用状况。 etc/shadow shadow 是 /etc/passwd 的影子文件，密码存放在该文件当中，并且只有root用户可读。&quot; echo -------------------------------------------------------------------------- echo &quot;-------------------查看系统日志文件是否存在--------------------&quot; log=/var/log/syslog log2=/var/log/messages if [ -e &quot;$log&quot; ]; then echo &quot;syslog日志文件存在！ &quot; else echo &quot;/var/log/syslog日志文件不存在！ &quot; fi if [ -e &quot;$log2&quot; ]; then echo &quot;/var/log/messages日志文件存在！ &quot; else echo &quot;/var/log/messages日志文件不存在！ &quot; fi echo -------------------------------------------------------------------------- echo &quot;检查系统文件完整性2(MD5检查)&quot; echo &quot;该项会获取部分关键文件的MD5值并入库，默认保存在/etc/md5db中&quot; echo &quot;如果第一次执行，则会提示md5sum: /sbin/portmap: 没有那个文件或目录&quot; echo &quot;第二次重复检查时，则会对MD5DB中的MD5值进行匹配，来判断文件是否被更改过&quot; file=&quot;/etc/md5db&quot; if [ -e &quot;$file&quot; ]; then md5sum -c /etc/md5db 2&gt;&amp;1; else md5sum /etc/passwd &gt;&gt;/etc/md5db md5sum /etc/shadow &gt;&gt;/etc/md5db md5sum /etc/group &gt;&gt;/etc/md5db md5sum /usr/bin/passwd &gt;&gt;/etc/md5db md5sum /sbin/portmap&gt;&gt;/etc/md5db md5sum /bin/login &gt;&gt;/etc/md5db md5sum /bin/ls &gt;&gt;/etc/md5db md5sum /bin/ps &gt;&gt;/etc/md5db md5sum /usr/bin/top &gt;&gt;/etc/md5db; fi echo ---------------------------------------------------------------------- echo &quot;------------------------主机性能检查--------------------------------&quot; echo &quot;CPU检查&quot; dmesg | grep -i cpu echo ----------------------------------------------------------------------- more /proc/cpuinfo echo ----------------------------------------------------------------------- echo &quot;内存状态检查&quot; vmstat 2 5 echo ----------------------------------------------------------------------- more /proc/meminfo echo ----------------------------------------------------------------------- free -m echo ----------------------------------------------------------------------- echo &quot;文件系统使用情况&quot; df -h echo ----------------------------------------------------------------------- echo &quot;网卡使用情况&quot; lspci -tv echo ---------------------------------------------------------------------- echo &quot;查看僵尸进程&quot; ps -ef | grep zombie echo ---------------------------------------------------------------------- echo &quot;耗CPU最多的进程&quot; ps auxf |sort -nr -k 3 |head -5 echo ---------------------------------------------------------------------- echo &quot;耗内存最多的进程&quot; ps auxf |sort -nr -k 4 |head -5 echo ---------------------------------------------------------------------- echo --------------------------------------------------------------------- echo &quot;COPY RIGHT &quot; echo &quot;QQ：&quot; echo ----------------------结束时间为------------------------------------- DATE=`date` echo &quot;Date is $DATE&quot; echo ----------------------------------------------------------------------]]></content>
      <categories>
        <category>Linux</category>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[memcache服务器搭建]]></title>
    <url>%2F2018%2F02%2F19%2Fmemcache%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[一、memcache简介Memcache是什么Memcache是danga.com的一个项目，最早是为 LiveJournal 服务的，目前全世界不少人使用这个缓存项目来构建自己大负载的网站，来分担数据库的压力。它可以应对任意多个连接，使用非阻塞的网络IO。由于它的工作机制是在内存中开辟一块空间，然后建立一个HashTable，Memcached自管理这些HashTable。Memcache官方网站,更多详细的信息可以来这里了解为什么会有Memcache和memcached两种名称？其实Memcache是这个项目的名称，而memcached是它服务器端的主程序文件名。一个是项目名称，一个是主程序文件名，不要混用了。二、Memcache的安装安装分为两个过程：memcache服务器端的安装和memcached客户端的安装。所谓服务器端的安装就是在服务器（一般都是linux系统）上安装Memcache实现数据的存储所谓客户端的安装就是指php（或者其他程序，Memcache还有其他不错的api接口提供）去使用服务器端的Memcache提供的函数，需要php添加扩展。2.1、memcache服务器的安装这里安装memcache需要指定libevent，查看系统是否已经安装libeventrpm -qa | grep libevent 如果已经有，先进行升级yum -y install libevent 测试libevent是否已经安装成功ll /usr/share/doc/ | grep libevent 可以看到有已经安装类包进行安装memchache （到官网下载自己需要的软件版本）解压文件并将文件移动到 /usr/local/ 目录下进入memcache目录进行安装可能会有一个报错因为libevent这个包是系统默认安装的，没有安装相应的开发所用的头文件，所以需要使用以下命令进行安装再次编译即可通过，编译通过后执行 make &amp;&amp; make install命令进行安装启动memcache/usr/local/memcached/bin/memcached -d -m 128 -l 172.31.8.50 -p 11211 -u root 进行连接测试telnet 172.31.8.50 11211 #出现以下内容即为安装成功 输出数据的格式如下：set foo 0 0 3 bar 如果保存成功，控制台会输出STORED获取数据的命令格式如下get foo 在控制台的输出信息如下链接到memcache后输入stats可以获得包括资源利用率在内的个种信息此外输入”stats items”可以获得关于缓存记录的信息，推出程序输入“quit”这些参数的具体含义可以参考下面的列表]]></content>
      <categories>
        <category>Linux</category>
        <category>memcache</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>memcache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis集群构建（伪集群）]]></title>
    <url>%2F2018%2F02%2F13%2Fredis%E9%9B%86%E7%BE%A4%E6%9E%84%E5%BB%BA%EF%BC%88%E4%BC%AA%E9%9B%86%E7%BE%A4%EF%BC%89%2F</url>
    <content type="text"><![CDATA[简介：用两个虚拟机模拟6个redis节点，一台机器三个节点，创建3个master、3个salve节点。redis采用3.2.4两台机器都是centos6.8，分别为172.31.8.102、172.31.8.24一、安装过程1、下载并解压[root@localhost ~]# mkdir /software [root@localhost software]#wget http://download.redis.io/releases/redis-3.2.4.tar.gz [root@localhost software]# tar -zxvf redis-3.2.4.tar.gz 2、编译安装[root@localhost software]# cd redis-3.2.4 [root@localhost redis-3.2.4]# make &amp;&amp; make install 3、将redis-trib.rb 复制到/usr/local/bin/[root@localhost redis-3.2.4]# ll src/redis-trib.rb -rwxrwxr-x. 1 root root 60852 9月 26 2016 src/redis-trib.rb [root@localhost redis-3.2.4]# cp src/redis-trib.rb /usr/local/bin/ 4、创建redis节点首先在172.31.8.102节点上/software/redis-3.2.4目录下创建redis_cluster目录[root@localhost redis-3.2.4]# mkdir redis_cluster 在redis_cluster目录下创建7000、7001、7002目录，并把redis.conf文件copy到这三个目录中[root@localhost redis_cluster]# mkdir 7000 7001 7002 [root@localhost redis-3.2.4]# cp redis.conf redis_cluster/7000/ [root@localhost redis-3.2.4]# cp redis.conf redis_cluster/7001/ [root@localhost redis-3.2.4]# cp redis.conf redis_cluster/7002/ 分别修改三个文件port 7000 //端口7000,7002,7003 bind 本机ip //默认ip为127.0.0.1 需要改为其他节点机器可访问的ip 否则创建集群时无法访问对应的端口，无法创建集群 daemonize yes //redis后台运行 pidfile /var/run/redis_7000.pid //pidfile文件对应7000,7001,7002 cluster-enabled yes //开启集群 把注释#去掉 cluster-config-file nodes_7000.conf //集群的配置 配置文件首次启动自动生成 7000,7001,7002 cluster-node-timeout 15000 //请求超时 默认15秒，可自行设置 appendonly yes //aof日志开启 有需要就开启，它会每次写操作都记录一条日志 接着在另一台机器上（172.31.8.24）重复操作以上四步，只是把目录改为7003、7004、7005，对应的配置文件也按照相应的规则修改即可5、启动各个节点在第一台机器上操作[root@localhost redis-3.2.4]# redis-server redis_cluster/7000/redis.conf [root@localhost redis-3.2.4]# redis-server redis_cluster/7001/redis.conf [root@localhost redis-3.2.4]# redis-server redis_cluster/7002/redis.conf 在第二台机器上操作[root@localhost redis-3.2.4]# redis-server redis_cluster/7003/redis.conf [root@localhost redis-3.2.4]# redis-server redis_cluster/7004/redis.conf [root@localhost redis-3.2.4]# redis-server redis_cluster/7005/redis.conf 6、检查redis启动情况第一台机器第二台机器7、创建集群redis官方提供了redis-trib.rb工具，就在已解压的src目录中，第三步已经将它拷贝到了/usr/local/bin/目录中，可以在命令行中使用了，使用以下命令创建集群：使用这个工具需要ruby，使用yum安装即可：yum -y install ruby ruby-devel rubygems rpm-build [root@localhost redis-3.2.4]# redis-trib.rb create --replicas 1 172.31.8.102:7000 172.31.8.102:7001 172.31.8.102:7002 172.31.8.24:7003 172.31.8.24:7004 172.31.8.24:7005 前三个IP:port为第一个节点，后面三个为第二个节点可能会出现的报错：这是因为ruby版本较低。yum安装的版本是1.8.7，但是redis需要的是1.9.3或者更高[root@localhost bin]# gem sources -a https://ruby.taobao.org/ [root@localhost bin]# gem install redis --version 3.0.0 之后再运行redis-trib.rb，会出现如下提示：输入“yes”回车即可，然后出现如下内容，说明安装成功二、集群验证在第一台机器上连接集群的7002端口的节点，在另外一台连接7005节点，连接方式为 redis-cli -h 172.31.8.102 -c -p 7002,加参数 -c 可连接到集群，因为上面 redis.conf 将 bind 改为了ip地址，所以 -h 参数不可以省略。在7005节点执行命令：然后在另外一台7002端口,查看key为hello的内容,get hello,执行结果如下：说明集群运作正常三、原理简介：redis cluster在设计的时候，就考虑到了去中心化,去中间件,也就是说,集群中的每个节点都是平等的关系,都是对等的,每个节点都保存各自的数据和整个集群的状态,每个节点都和其他所有节点连接而且这些连接保持活跃这样就保证了我们只需要连接集群中的任意一个节点,就可以获取到其他节点的数据.Redis 集群没有并使用传统的一致性哈希来分配数据，而是采用另外一种叫做哈希槽(hash slot)方式来分配的。rediscluster默认分配了16384个slot,当我们set一个key时,会用CRC16算法来取模得到所属的slot,然后将这个key 分到哈希槽区间的节点上,具体算法就是：CRC16(key) % 16384,所以我们在测试的时候看到set 和 get 的时候，直接跳转到了7000端口的节点.Redis集群会把数据存在一个master节点,然后在这个master和其对应的salve之间进行数据同步.当读取数据时,也根据一致性哈希算法到对应的master节点获取数据,只有当一个master 挂掉之后，才会启动一个对应的salve节点,充当 master.需要注意的是：必须要3个或以上的主节点，否则在创建集群时会失败，并且当存活的主节点数小于总节点数的一半时，整个集群就无法提供服务了。]]></content>
      <categories>
        <category>Linux</category>
        <category>redis</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[批量ping存活主机]]></title>
    <url>%2F2017%2F11%2F17%2F%E6%89%B9%E9%87%8Fping%E5%AD%98%E6%B4%BB%E4%B8%BB%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[创建一个ip.txt文件，把需要测试IP地址写入文档创建一个ping.sh 的shell 脚本，并修改ip.txt 文件路径#!/bin/bash for ips in `cat /root/manager/script/ip.txt` do result=`ping -w 2 -c 3 ${ips} | grep packet | awk -F&quot; &quot; &apos;{print $6}&apos;| awk -F&quot;%&quot; &apos;{print $1}&apos;| awk -F&apos; &apos; &apos;{print $1}&apos;` if [ $result -eq 0 ]; then echo &quot;&quot;${ips}&quot; is ok !&quot; else echo &quot;&quot;${ips}&quot; is not connected .....&quot; fi done 给脚本执行权限 chmod +x ping.sh执行脚本[root@k8s-node1 script]# ./ping.sh 172.31.8.101 is ok ! 172.31.8.192 is ok ! 172.31.8.42 is ok ! 172.31.8.176 is ok ! 172.31.8.45 is ok ! [root@k8s-node1 script]#]]></content>
      <categories>
        <category>Linux</category>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[查看MySQL运行状况]]></title>
    <url>%2F2017%2F08%2F06%2F%E6%9F%A5%E7%9C%8BMySQL%E8%BF%90%E8%A1%8C%E7%8A%B6%E5%86%B5%2F</url>
    <content type="text"><![CDATA[直接在命令行下登陆MySQL运行SHOW STATUS;查询语句，详细如下图SHOW STATUS SHOW VARIABLES SHOW VARIABLES --- 是查看MySQL的配置参数，还可以使用类似SHOW VARIABLES LIKE ‘Key%’ SHOW PROCESSLIST SHOW PROCESSLIST --- 是查看当前正在进行的进程，对于有锁表等情况的排查很有用处。一般情况下，打开MySQL的慢查询记录同样有利于排查。 SHOW OPEN TABLES SHOW OPEN TABLES --- 是显示当前已经被打开的表列表。 mysqladmin status 使用MySQL自带的mysqladmin 工具查看status，使用以下命令mysqladmin -uroot –password=’password’ status 显示的结果如下：Uptime: 87117 Threads: 1 Questions: 5481626 Slow queries: 16 Opens: 2211 Flush tables: 1 Open tables: 512 Queries per second avg: 62.923 另外可以添加 -i 5 参数，让其每五秒自动刷新之。mysqladmin -uroot –password=’password’ status -i 5 mysqladmin extended-status 同样的可以使用以下命令来查看更多的MySQL运行信息，这种方式和第一种查看的信息基本一样。mysqladmin -uroot –password=’password’ extended-status]]></content>
  </entry>
  <entry>
    <title><![CDATA[MySQL数据库备份命令]]></title>
    <url>%2F2017%2F08%2F06%2F%E5%A4%87%E4%BB%BDMySQL%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[备份MySQL数据库的命令mysqldump -hhostname -uusername -ppassword databasename &gt; backupfile.sql 备份MySQL数据库为带删除表的格式，能够让该备份覆盖已有数据库而不需要手动删除原有数据库。mysqldump -–dd-drop-table -uusername -ppassword databasename &gt; backupfile.sql 直接将MySQL数据库压缩备份mysqldump -hhostname -uusername -ppassword databasename | gzip &gt; backupfile.sql.gz 备份MySQL数据库某个（些）表mysqldump -hhostname -uusername -ppassword databasename specific_table specific_table2 &gt; backupfile.sql 同时备份多个MySQL数据库mysqldump -hhostname -uusername -ppassword -databases databasename databasename2 databasename3 &gt; multibackupfile.sql 仅仅备份数据库结构mysqldump –no-data – databases databasename databasename2 databasename3 &gt; structurebackupfile.sql 备份服务器上所有数据库mysqldump –all-databases &gt; allbackupfile.sql 还原MySQL数据库的命令mysql -hhostname -uusername -ppassword databasename &lt; backupfile.sql 还原压缩的MySQL数据库gunzip &lt; backupfile.sql.gz | mysql -uusername -ppassword databasename 将数据库转移到新服务器mysqldump -uusername -ppassword databasename | mysql –host=*.*.*.* -C databasename]]></content>
      <categories>
        <category>Linux</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 挂载新磁盘]]></title>
    <url>%2F2017%2F07%2F23%2FLinux-%E6%8C%82%E8%BD%BD%E6%96%B0%E7%A3%81%E7%9B%98%2F</url>
    <content type="text"><![CDATA[需求：新增加一块硬盘sdb，只分一个区，格式化挂载到/date1、查看现在已有的分区状态df -h图中显示没有看到sdb硬盘2、查看服务器安装的硬盘状态（包括格式化和未格式化的）fdisk -l图中显示，有sdb硬盘，但是没有分区3、添加新分区fdisk /dev/sdb按照以下红框输入：N 回车 P 回车 1 回车 两次回车 W 回车用以下命令查看分区fdisk -l图中红框显示已经多出了一个分区，但是没有格式化4、格式化分区mkfs -t ext4 -c /dev/sdb1-t 指定要把磁盘格式化成什么类型-c 在建立文件系统之前检查坏道，可能会很费时间，新硬盘一般不需要5、挂载新硬盘在根目录下建一个文件夹，待会将分区挂载在这个文件夹上，以后要往新硬盘存东西，就放在这个新建的文件夹里就可以mkdir /data挂载硬盘mount /dev/sdb1 /data6、让系统开机自动挂载这块硬盘echo “/dev/sdb1 /data ext4 defaults 0 0”&gt; /etc/fstab]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zimbra 邮箱系统安装配置]]></title>
    <url>%2F2017%2F06%2F21%2Fzimbra%20%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[1、Zimbra介绍Zimbra与众不同的特点是其“Zimlet”网络服务提供了更多的电子邮件功能。例如，人们可以简单地用鼠标点击电子邮件程序中的航班信息以检查航班的状况。用户还可以在电子邮件中跟踪FedEx公司的投递情况并且获得地图、股票和其它信息。Zimbra的核心产品是Zimbra协作套件（Zimbra Collaboration Suite，简称ZCS）。除了它的核心功能是电子邮件和日程安排服务器，当然还包括许多其它的功能，就象是下一代的微软Exchange。在电子邮件和日程安排之外，它还提供文档存储和编辑、即时消息以及一个利用获奖技术开发的全功能的管理控制台。ZCS同时也提供移动设备的支持，以及与部署于Windows、Linux或apple操作系统中的桌面程序的同步功能。(来自百度百科)注:Zimbra安装时，须在linux系统上，系统内存至少一个GB，5G磁盘空间；否则安装过程会很长，且会因为内存和磁盘空间不够而导致安装失败2、安装配置DNS1、安装配置DNS配置vim /etc/named.conf #修改一下内容配置 vim /etc/named.rfc1912.zones #添加以下内容配置正向解析文件解析文件cd /var/namedcp named.localhost tzh.com.zonevim tzh.com.zone配置反向解析文件 #添加以下内容vim 10.90.10.zone启动bindservice named start解析nslookup www.tzh.comnslookup mail.tzh.com3、安装zimbra3.1、停止系统默认邮件服务Chkconfig postfix off &amp;&amp; /etc/init.d/postfix stop3.2、关闭iptables和selinuxsetenforce 0 &amp;&amp; service iptables stop &amp;&amp; chkconfig iptables off3.3、设置hosts文件 #添加以下内容3.4、 安装点击显/隐内容[root@tzh zcs-8.6.0_GA_1153.RHEL6_64.20141215151155]# ./install.shOperations logged to /tmp/install.log.29747Checking for existing installation…zimbra-ldap…NOT FOUNDzimbra-logger…NOT FOUNDzimbra-mta…NOT FOUNDzimbra-dnscache…NOT FOUNDzimbra-snmp…NOT FOUNDzimbra-store…NOT FOUNDzimbra-apache…NOT FOUNDzimbra-spell…NOT FOUNDzimbra-convertd…NOT FOUNDzimbra-memcached…NOT FOUNDzimbra-proxy…NOT FOUNDzimbra-archiving…NOT FOUNDzimbra-core…NOT FOUNDPLEASE READ THIS AGREEMENT CAREFULLY BEFORE USING THE SOFTWARE.ZIMBRA, INC. (“ZIMBRA”) WILL ONLY LICENSE THIS SOFTWARE TO YOU IF YOUFIRST ACCEPT THE TERMS OF THIS AGREEMENT. BY DOWNLOADING OR INSTALLINGTHE SOFTWARE, OR USING THE PRODUCT, YOU ARE CONSENTING TO BE BOUND BYTHIS AGREEMENT. IF YOU DO NOT AGREE TO ALL OF THE TERMS OF THISAGREEMENT, THEN DO NOT DOWNLOAD, INSTALL OR USE THE PRODUCT.License Terms for the Zimbra Collaboration Suite:http://www.zimbra.com/license/zimbra-public-eula-2-5.htmlDo you agree with the terms of the software license agreement? [N] yChecking for prerequisites…FOUND: NPTLFOUND: nc-1.84-24FOUND: sudo-1.8.6p3-19FOUND: libidn-1.18-2FOUND: gmp-4.3.1-7FOUND: libaio-0.3.107-10FOUND: libstdc++-4.4.7-16FOUND: unzip-6.0-2Checking for suggested prerequisites…FOUND: perl-5.10.1FOUND: sysstatFOUND: sqlitePrerequisite check complete.Checking for installable packagesFound zimbra-coreFound zimbra-ldapFound zimbra-loggerFound zimbra-mtaFound zimbra-dnscacheFound zimbra-snmpFound zimbra-storeFound zimbra-apacheFound zimbra-spellFound zimbra-memcachedFound zimbra-proxySelect the packages to installInstall zimbra-ldap [Y] yInstall zimbra-logger [Y] yInstall zimbra-mta [Y] yInstall zimbra-dnscache [Y] yInstall zimbra-snmp [Y] yInstall zimbra-store [Y] yInstall zimbra-apache [Y]Install zimbra-spell [Y] yInstall zimbra-memcached [Y] yInstall zimbra-proxy [Y] yChecking required space for zimbra-coreChecking space for zimbra-storeChecking required packages for zimbra-storezimbra-store package check complete.Installing:zimbra-corezimbra-ldapzimbra-loggerzimbra-mtazimbra-dnscachezimbra-snmpzimbra-storezimbra-apachezimbra-spellzimbra-memcachedzimbra-proxyThe system will be modified. Continue? [N] yRemoving /opt/zimbraRemoving zimbra crontab entry…done.Cleaning up zimbra init scripts…done.Cleaning up /etc/ld.so.conf…done.Cleaning up /etc/prelink.conf…done.Cleaning up /etc/security/limits.conf…done.Finished removing Zimbra Collaboration Server.Installing packageszimbra-core……zimbra-core-8.6.0_GA_1153.RHEL6_64-20141215151155.x86_64.rpm…zimbra-ldap……zimbra-ldap-8.6.0_GA_1153.RHEL6_64-20141215151155.x86_64.rpm…donezimbra-logger……zimbra-logger-8.6.0_GA_1153.RHEL6_64-20141215151155.x86_64.rpm…donezimbra-mta……zimbra-mta-8.6.0_GA_1153.RHEL6_64-20141215151155.x86_64.rpm…donezimbra-dnscache……zimbra-dnscache-8.6.0_GA_1153.RHEL6_64-20141215151155.x86_64.rpm…donezimbra-snmp……zimbra-snmp-8.6.0_GA_1153.RHEL6_64-20141215151155.x86_64.rpm…donezimbra-store……zimbra-store-8.6.0_GA_1153.RHEL6_64-20141215151155.x86_64.rpm…donezimbra-apache……zimbra-apache-8.6.0_GA_1153.RHEL6_64-20141215151155.x86_64.rpm…donezimbra-spell……zimbra-spell-8.6.0_GA_1153.RHEL6_64-20141215151155.x86_64.rpm…donezimbra-memcached……zimbra-memcached-8.6.0_GA_1153.RHEL6_64-20141215151155.x86_64.rpm…donezimbra-proxy……zimbra-proxy-8.6.0_GA_1153.RHEL6_64-20141215151155.x86_64.rpm…doneOperations logged to /tmp/zmsetup06292016-184521.logInstalling LDAP configuration database…done.Setting defaults… MX: mail.user-mail.net (54.227.254.216)MX: mail.user-mail.net (54.225.221.198)Interface: 10.90.10.190Interface: 127.0.0.1Interface: ::154.225.221.19854.227.254.21654.227.254.21654.225.221.19854.225.221.19854.227.254.216DNS ERROR - none of the MX records for mail.tzh.comresolve to this hostChange domain name? [Yes] ndone.Checking for port conflictsMain menu1) Common Configuration:2) zimbra-ldap: Enabled3) zimbra-logger: Enabled4) zimbra-mta: Enabled5) zimbra-dnscache: Enabled6) zimbra-snmp: Enabled7) zimbra-store: Enabled+Create Admin User: yes+Admin user to create: admin@mail.tzh.com*** +Admin Password UNSET+Anti-virus quarantine user: virus-quarantine.iv8_lcko@mail.tzh.com+Enable automated spam training: yes+Spam training user: spam.f8aglxrf@mail.tzh.com+Non-spam(Ham) training user: ham.ugur2xpeby@mail.tzh.com+SMTP host: mail.tzh.com+Web server HTTP port: 8080+Web server HTTPS port: 8443+Web server mode: https+IMAP server port: 7143+IMAP server SSL port: 7993+POP server port: 7110+POP server SSL port: 7995+Use spell check server: yes+Spell server URL: http://mail.tzh.com:7780/aspell.php+Enable version update checks: TRUE+Enable version update notifications: TRUE+Version update notification email: admin@mail.tzh.com+Version update source email: admin@mail.tzh.com+Install mailstore (service webapp): yes+Install UI (zimbra,zimbraAdmin webapps): yes8) zimbra-spell: Enabled9) zimbra-proxy: Enabled10) Default Class of Service Configuration:s) Save config to filex) Expand menuq) QuitAddress unconfigured () items (? - help) 7Store configuration1) Status: Enabled2) Create Admin User: yes3) Admin user to create: admin@mail.tzh.com 4) Admin Password UNSET5) Anti-virus quarantine user: virus-quarantine.iv8_lcko@mail.tzh.com6) Enable automated spam training: yes7) Spam training user: spam.f8aglxrf@mail.tzh.com8) Non-spam(Ham) training user: ham.ugur2xpeby@mail.tzh.com9) SMTP host: mail.tzh.com10) Web server HTTP port: 808011) Web server HTTPS port: 844312) Web server mode: https13) IMAP server port: 714314) IMAP server SSL port: 799315) POP server port: 711016) POP server SSL port: 799517) Use spell check server: yes18) Spell server URL: http://mail.tzh.com:7780/aspell.php19) Enable version update checks: TRUE20) Enable version update notifications: TRUE21) Version update notification email: admin@mail.tzh.com22) Version update source email: admin@mail.tzh.com23) Install mailstore (service webapp): yes24) Install UI (zimbra,zimbraAdmin webapps): yesSelect, or ‘r’ for previous menu [r] 4Password for admin@mail.tzh.com (min 6 characters): [1mrCHrfp] 558842Store configuration1) Status: Enabled2) Create Admin User: yes3) Admin user to create: admin@mail.tzh.com4) Admin Password set5) Anti-virus quarantine user: virus-quarantine.iv8_lcko@mail.tzh.com6) Enable automated spam training: yes7) Spam training user: spam.f8aglxrf@mail.tzh.com8) Non-spam(Ham) training user: ham.ugur2xpeby@mail.tzh.com9) SMTP host: mail.tzh.com10) Web server HTTP port: 808011) Web server HTTPS port: 844312) Web server mode: https13) IMAP server port: 714314) IMAP server SSL port: 799315) POP server port: 711016) POP server SSL port: 799517) Use spell check server: yes18) Spell server URL: http://mail.tzh.com:7780/aspell.php19) Enable version update checks: TRUE20) Enable version update notifications: TRUE21) Version update notification email: admin@mail.tzh.com22) Version update source email: admin@mail.tzh.com23) Install mailstore (service webapp): yes24) Install UI (zimbra,zimbraAdmin webapps): yesSelect, or ‘r’ for previous menu [r] rMain menu1) Common Configuration:2) zimbra-ldap: Enabled3) zimbra-logger: Disabled4) zimbra-mta: Enabled5) zimbra-dnscache: Enabled6) zimbra-snmp: Enabled7) zimbra-store: Enabled8) zimbra-spell: Enabled9) zimbra-proxy: Enabled10) Default Class of Service Configuration:s) Save config to filex) Expand menuq) QuitSelect from menu, or press ‘a’ to apply config (? - help) aSave configuration data to a file? [Yes] ySave config in file: [/opt/zimbra/config.39633]Saving config in /opt/zimbra/config.39633…done.The system will be modified - continue? [No] yOperations logged to /tmp/zmsetup06292016-184521.logSetting local config values…done.Initializing core config…Setting up CA…done.Deploying CA to /opt/zimbra/conf/ca …done.Creating SSL zimbra-store certificate…done.Creating new zimbra-ldap SSL certificate…done.Creating new zimbra-mta SSL certificate…done.Creating new zimbra-proxy SSL certificate…done.Installing mailboxd SSL certificates…done.Installing MTA SSL certificates…done.Installing LDAP SSL certificate…done.Installing Proxy SSL certificate…done.Initializing ldap…done.Setting replication password…done.Setting Postfix password…done.Setting amavis password…done.Setting nginx password…done.Setting BES searcher password…done.Creating server entry for mail.tzh.com…done.Setting Zimbra IP Mode…done.Saving CA in ldap …done.Saving SSL Certificate in ldap …done.Setting spell check URL…done.Setting service ports on mail.tzh.com…done.Setting zimbraFeatureTasksEnabled=TRUE…done.Setting zimbraFeatureBriefcasesEnabled=TRUE…done.Setting Master DNS IP address(es)…done.Setting DNS cache tcp lookup preference…done.Setting DNS cache udp lookup preference…done.Setting DNS tcp upstream preference…done.Setting TimeZone Preference…done.Initializing mta config…done.Setting services on mail.tzh.com…done.Adding mail.tzh.com to zimbraMailHostPool in default COS…done.Creating domain mail.tzh.com…done.Setting default domain name…done.Creating domain mail.tzh.com…already exists.Creating admin account admin@mail.tzh.com…done.Creating root alias…done.Creating postmaster alias…done.Creating user spam.f8aglxrf@mail.tzh.com…done.Creating user ham.ugur2xpeby@mail.tzh.com…done.Creating user virus-quarantine.iv8_lcko@mail.tzh.com…done.Setting spam training and Anti-virus quarantine accounts…done.Initializing store sql database…done.Setting zimbraSmtpHostname for mail.tzh.com…done.Configuring SNMP…done.Setting up syslog.conf…done.Starting servers…Installing common zimlets…com_zimbra_ymemoticons…done.com_zimbra_clientuploader…done.com_zimbra_webex…done.com_zimbra_proxy_config…done.com_zimbra_srchhighlighter…done.com_zimbra_bulkprovision…done.com_zimbra_viewmail…done.com_zimbra_date…done.com_zimbra_attachcontacts…done.com_zimbra_mailarchive…done.com_zimbra_cert_manager…done.com_zimbra_url…done.com_zimbra_adminversioncheck…done.com_zimbra_attachmail…done.com_zimbra_tooltip…done.com_zimbra_email…done.com_zimbra_phone…done.Finished installing common zimlets.Restarting mailboxd…done.Creating galsync account for default domain…done.You have the option of notifying Zimbra of your installation.This helps us to track the uptake of the Zimbra Collaboration Server.The only information that will be transmitted is:The VERSION of zcs installed (8.6.0_GA_1153_RHEL6_64)The ADMIN EMAIL ADDRESS created (admin@mail.tzh.com)Notify Zimbra of your installation? [Yes] yesNotifying Zimbra of installation via http://www.zimbra.com/cgi-bin/notify.cgi?VER=8.6.0_GA_1153_RHEL6_64&amp;MAIL=admin@mail.tzh.comNotification completeSetting up zimbra crontab…done.Moving /tmp/zmsetup06292016-184521.log to /opt/zimbra/logConfiguration complete - press return to exit3.5、重启zimbra点击显/隐内容[root@tzh zcs-8.6.0_GA_1153.RHEL6_64.20141215151155]# /etc/init.d/zimbra restartHost mail.tzh.comStopping vmware-ha…skipped./opt/zimbra/bin/zmhactl missing or not executable.Stopping zmconfigd…Done.Stopping zimlet webapp…Done.Stopping zimbraAdmin webapp…Done.Stopping zimbra webapp…Done.Stopping service webapp…Done.Stopping stats…Done.Stopping mta…Done.Stopping spell…Done.Stopping snmp…Done.Stopping cbpolicyd…Done.Stopping archiving…Done.Stopping opendkim…Done.Stopping amavis…Done.Stopping antivirus…Done.Stopping antispam…Done.Stopping proxy…Done.Stopping memcached…Done.Stopping mailbox…Done.Stopping logger…Done.Stopping dnscache…Done.Stopping ldap…Done.Host mail.tzh.comStarting ldap…Done.略~~~4、服务发件测试4.1 登陆测试创建一个账户，进行邮件发送测试账户创建登陆网页客户端进行邮件发送测试注：上图时间为周三（6月29）下午17：29是因为我在本地搭建的虚拟机，时间没有同步因为域名问题，以及DNS在内网的虚拟机上，收取邮件是无法收取的，需要做公网解析，所以暂不进行邮件收取测试]]></content>
      <categories>
        <category>Linux</category>
        <category>zimbra</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>zimbra</tag>
      </tags>
  </entry>
</search>
