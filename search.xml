<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Zabbix 缓存数据清理]]></title>
    <url>%2F2019%2F05%2F17%2FZabbix-%E7%BC%93%E5%AD%98%E6%95%B0%E6%8D%AE%E6%B8%85%E7%90%86%2F</url>
    <content type="text"><![CDATA[zabbix监控运行一段时间以后，会留下大量的历史监控数据，zabbix数据库一直在增大；可能会造成系统性能下降，查看历史数据室查询速度缓慢。 zabbix里面最大的表就是history和history_uint两个表，而且zabbix里面的时间是使用的时间戳方式记录，所以可以根据时间戳来删除历史数据一、关闭zabbix、http服务 pkill -9 zabbix service httpd stop 二、清理zabbix历史数据 1、查看数据库目录文件 [root@zabbix-server zabbix]# cd /var/lib/mysql/zabbix/ [root@zabbix-server zabbix]# ls -lh | grep G total 177G -rw-r----- 1 mysql mysql 1.7G Dec 24 13:49 events.ibd -rw-r----- 1 mysql mysql 60G Dec 24 13:49 history.ibd -rw-r----- 1 mysql mysql 2.4G Dec 24 13:49 history_str.ibd -rw-r----- 1 mysql mysql 99G Dec 24 13:49 history_uint.ibd -rw-r----- 1 mysql mysql 4.6G Dec 24 13:02 trends.ibd -rw-r----- 1 mysql mysql 9.5G Dec 24 13:49 trends_uint.ibd [root@zabbix-server zabbix]# 生成Unix时间戳。时间定为2018年2月1日（暂定是保存18年2月以后的监控数据） [root@zabbix-server zabbix]# date +%s -d &quot;Feb 1, 2018 00:00:00&quot; #执行此命令以后会生成一个ID 1517414400 #这是生成的ID 2、数据备份 [root@zabbix-server zabbix]#mysql -uroot -p zabbix &gt; /root/mysqlback/zabbix.sql #需要创建mysqlback目录 3、 登录数据库 [root@zabbix-server zabbix]# mysql -uroot -p Enter password: Welcome to the MariaDB monitor. Commands end with ; or \g. Your MariaDB connection id is 7 Server version: 5.5.60-MariaDB MariaDB Server Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others. Type &apos;help;&apos; or &apos;\h&apos; for help. Type &apos;\c&apos; to clear the current input statement. MariaDB [(none)]&gt; use zabbix; #选择zabbix数据库 执行sql查看指定日期之前的数据大小： SELECT table_schema as `Database`,table_name AS `Table`,round(((data_length + index_length) / 1024 / 1024 / 1024), 2) `Size in MB`FROM information_schema.TABLES where CREATE_TIME &lt; &apos;2018-02-01 00:00:00&apos; and table_name=&apos;history.ibd&apos;; 根据需要修改日期和查询的表名称(如果查询出来的结果是0.0，需要将sql中的三个1024删除一个，以G为单位显示) 4、 执行以下命令，清理指定时间之前的数据、对zabbix数据库执行以下sql delete from history where clock &lt; 1517414400; optimize table history; delete from history_uint where clock &lt; 1517414400; optimize table history_uint; delete from trends where clock &lt; 1517414400; optimize table trends; delete from trends_uint where clock &lt; 1517414400; optimize table trends_uint; 注意：sql中的ID是生成Unix时间戳的ID号,需要改为自己生成的ID号三、启动服务 /usr/sbin/zabbix_server -c /etc/zabbix/zabbix_server.conf #zabbix server /usr/sbin/zabbix_agentd -c /etc/zabbix/zabbix_agentd.conf #zabbix agent service httpd start ===============================分===========隔==========符=================================== 1、使用truncate命令清空zabbix 所有监控数据 ------------------------------------------------------- truncate table history; optimize table history; ------------------------------------------------------- truncate table history_str; optimize table history_str; ------------------------------------------------------- truncate table history_uint; optimize table history_uint; ------------------------------------------------------- truncate table trends; optimize table trends; ------------------------------------------------------- truncate table trends_uint; optimize table trends_uint; ------------------------------------------------------- truncate table events; optimize table events; ------------------------------------------------------- 注意：这些命令会把zabbix所有的监控数据清空，操作前注意备份数据库 truncate是删除了表，然后根据表结构重新建立，delete删除的是记录的数据没有修改表 truncate执行删除比较快，但是在事务处理安全性方面不如delete,如果我们执行truncat的表正在处理事务，这个命令退出并会产生错误信息]]></content>
      <categories>
        <category>Linux</category>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis 故障恢复]]></title>
    <url>%2F2019%2F05%2F17%2FRedis-%E6%95%85%E9%9A%9C%E6%81%A2%E5%A4%8D%2F</url>
    <content type="text"><![CDATA[案例一、ResponseError: MISCONF Redis is configured to save RDB snapshots, but is currently not able to persist on disk.Commands that may modify the data set are disabled. Please check Redis logs for details about the error.Redis被配置为保存数据库快照，但它目前不能持久化到硬盘。用来修改集合数据的命令不能用。请查看Redis日志的详细错误信息。原因：强制关闭redis快照导致不能持久化 解决方案：将：stop-writes-on-bgsave-error 设置为 no]]></content>
      <categories>
        <category>Linux</category>
        <category>redis</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[批量ping存活主机]]></title>
    <url>%2F2019%2F05%2F17%2F%E6%89%B9%E9%87%8Fping%E5%AD%98%E6%B4%BB%E4%B8%BB%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[创建一个ip.txt文件，把需要测试IP地址写入文档 创建一个ping.sh 的shell 脚本，并修改ip.txt 文件路径 #!/bin/bash for ips in `cat /root/manager/script/ip.txt` do result=`ping -w 2 -c 3 ${ips} | grep packet | awk -F&quot; &quot; &apos;{print $6}&apos;| awk -F&quot;%&quot; &apos;{print $1}&apos;| awk -F&apos; &apos; &apos;{print $1}&apos;` if [ $result -eq 0 ]; then echo &quot;&quot;${ips}&quot; is ok !&quot; else echo &quot;&quot;${ips}&quot; is not connected .....&quot; fi done 给脚本执行权限 chmod +x ping.sh 执行脚本 [root@k8s-node1 script]# ./ping.sh 172.31.8.101 is ok ! 172.31.8.192 is ok ! 172.31.8.42 is ok ! 172.31.8.176 is ok ! 172.31.8.45 is ok ! [root@k8s-node1 script]#]]></content>
      <categories>
        <category>Linux</category>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PTES渗透测试执行标准]]></title>
    <url>%2F2019%2F05%2F17%2FPTES%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E6%89%A7%E8%A1%8C%E6%A0%87%E5%87%86%2F</url>
    <content type="text"><![CDATA[渗透测试注意事项：1、不要进行恶意攻击 2、不要做傻事 3、在没有获得书面授权时，不要攻击任何目标 4、考虑清楚攻击将会带来的后果 4、如果干了非法的事情，记得天网恢恢疏而不漏 参考官方对于渗透测试执行标准描述（PTES） 一：前期交互阶段在前期交互阶段，渗透测试团队与客户组织进行交互讨论，最重要的是确定渗透测试的范围、目标、限制条件以及合同细节 该阶段通常涉及收集客户需求，准备测试计划、定义测试范围与边界、定义业务目标、项目管理与规划等活动 二：情报收集阶段在目标范围确定之后，将进入情报搜集（Information Gathering）阶段，渗透团队可以利用各种信息来源与搜集技术方法，尝试更多关于组织网络拓扑、系统配置与安全防御措施的信息。 渗透测试者可以使用情报搜集方法包括公开来源信息查询、google Hacking 、社会工程学、网络踩点、扫描探测、被动监听、服务查点等。而对目标系统的情报探查能力是渗透者一项非常重要的技能，情报搜集是否充分在很大程度上决定了渗透测的成败，因为如果你遗漏关键的情报信息，你将可能在后面的阶段一无所获。 三：威胁建模阶段在搜集到充分的情报信息之后，渗透测试团队的成员们停下敲击键盘，大家聚到一起针对获取的信息进行威胁建模（Threat Modeling）与攻击规划。这是渗透测试过程中非常重要，但很容易被忽视的一个关键点。通过团队共同的缜密情报分析与攻击思路头脑风暴，可以从大量的信息情报中理清头绪，确定出最可行的攻击通道。四：漏洞分析阶段在确定出最可行的攻击通道之后，接下来需要考虑该如何取得目标系统的访问控制权，即漏洞分析（Vulnerability Analysis）阶段。在该阶段，渗透测试者需要综合分析前几个阶段获取并汇总的情报信息，特别是安全漏洞扫描结果、服务查点信息等，通过搜索可获取的渗透代码资源，找出可以实施渗透攻击的攻击点，并在实验环境中进行验证。在该阶段，高水平的渗透测试团队还会针对攻击通道上的一些关键系统与服务进行安全漏洞探测与挖掘，期望找出可被利用的未知安全漏洞，并开发出渗透代码，从而打开攻击通道上的关键路径。 五：渗透攻击阶段渗透攻击（Exploitation）是渗透测试过程中最具有魅力的环节。在此环节中，渗透测试团队需要利用他们所找出的目标系统安全漏洞，来真正入侵系统当中，获得访问控制权。渗透攻击可以利用公开渠道可获取的渗透代码，但一般在实际应用场景中，渗透测试者还需要充分地考虑目标系统特性来定制渗透攻击，并需要挫败目标网络与系统中实施的安全防御措施，才能成功达成渗透目的。在黑盒测试中，渗透测试者还需要考虑对目标系统检测机制的逃逸，从而避免造成目标组织安全响应团队的警觉和发现 六：后渗透攻击阶段后渗透攻击（Post Exploitation）是整个渗透测试过程中最能够体现渗透测试团队创造力与技术能力的环节。前面的环节可以说都是在按部就班地完成非常普遍的目标，而在这个环节中，需要渗透测试团队根据目标组织的业务经营模式、保护资产形式与安全防御计划的不同特点，自主设计出攻击目标，识别关键基础设施，并寻找客户组织最具价值和尝试安全保护的信息和资产，最终达成能够对客户组织造成最重要业务影响的攻击途径。在不同的渗透测试场景中，这些攻击目标与途径可能是千变万化的，而设置是否准确并且可行，也取决于团队自身的创新意识、知识范畴、实际经验和技术能力。 七：报告阶段渗透测试过程最终向客户组织提交，取得认可并成功获得合同付款的就是一份渗透测试报告（Reporting）。这份报告凝聚了之前所有阶段之中渗透测试团队所获取的关键情报信息、探测和发掘出的系统安全漏洞、成功渗透攻击的过程，以及造成业务影响后果的攻击途径，同时还要站在防御者的角度上，帮助他们分析安全防御体系中的薄弱环节、存在的问题，以及修补与升级技术方案。 渗透术语：渗透攻击（Exploit） 攻击者利用安全漏洞，所进行的攻击行为，常见的渗透攻击技术包括缓冲区溢出、web应用程序漏洞攻击（SQL注入）、利用配置错误等 攻击载荷（Payload） 目标系统在被渗透攻击之后执行的代码 Shellcode 在渗透攻击时作为攻击载荷运行的一组机器指令，通常用汇编语言编写 模块（Module） 一段软件代码组件 监听器（Listener） 用来等待连入网络链接的组件]]></content>
      <categories>
        <category>信息安全</category>
        <category>渗透测试</category>
      </categories>
      <tags>
        <tag>信息安全</tag>
        <tag>渗透测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[(二)、Ansible在使用过程中出现的错误解决方法]]></title>
    <url>%2F2018%2F09%2F02%2F%E4%BA%8C-%E3%80%81Ansible%E5%9C%A8%E4%BD%BF%E7%94%A8%E8%BF%87%E7%A8%8B%E4%B8%AD%E5%87%BA%E7%8E%B0%E7%9A%84%E9%94%99%E8%AF%AF%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[1.安装完成后允许命令出错Traceback (most recent call last): File &quot;/usr/bin/ansible&quot;, line 197, in &lt;module&gt; (runner, results) = cli.run(options, args) File &quot;/usr/bin/ansible&quot;, line 163, in run extra_vars=extra_vars, File &quot;/usr/lib/python2.6/site-packages/ansible/runner/__init__.py&quot;, line 233, in __init__ cmd = subprocess.Popen([&apos;ssh&apos;,&apos;-o&apos;,&apos;ControlPersist&apos;], stdout=subprocess.PIPE, stderr=subprocess.PIPE) File &quot;/usr/lib64/python2.6/subprocess.py&quot;, line 639, in __init__ errread, errwrite) File &quot;/usr/lib64/python2.6/subprocess.py&quot;, line 1228, in _execute_child raise child_exception OSError: [Errno 2] No such file or directory 解决办法yum -y install openssh-clients 2.出现Error: ansible requires a json module, none found!SSH password: 10.0.1.110 | FAILED &gt;&gt; { &quot;failed&quot;: true, &quot;msg&quot;: &quot;Error: ansible requires a json module, nonefound!&quot;, &quot;parsed&quot;: false } 解决办法python版本过低，可以升级python或者python-simplejson 3.安装完成后链接客户端报错（配图为我在使用ansible推送文件到客户端的时候遇到的，这个客户端是第一次推送）FAILED =&gt; Using a SSH password insteadof a key is not possible because Host Key checking is enabled and sshpass doesnot support this. Please add this host&apos;sfingerprint to your known_hosts file to manage this host. 解决办法：在ansible 服务器上使用ssh 登陆下/etc/ansible/hosts 里面配置的服务器。然后再次使用ansible 去管理就不会报上面的错误了！但这样大批量登陆就麻烦来。因为默认ansible是使用key验证的，如果使用密码登陆的服务器，使用ansible的话，要不修改ansible.cfg配置文件的ask_pass = True给取消注释，要不就在运行命令时候加上-k，这个意思是-k, –ask-pass ask for SSH password。再修改： host_key_checking= False即可 4.如果客户端不在know_hosts里将会报错paramiko: The authenticity of host &apos;192.168.24.15&apos;can&apos;t be established. The ssh-rsa key fingerprint is397c139fd4b0d763fcffaee346a4bf6b. Are you sure you want to continueconnecting (yes/no)? 解决办法需要修改ansible.cfg的#host_key_checking= False取消注释 5.出现FAILED =&gt; FAILED: not a valid DSA private key file解决办法：需要你在最后命令内添加参数-k 6.openssh升级后无法登录报错PAM unable todlopen(/lib64/security/pam_stack.so): /lib64/security/pam_stack.so: cannot openshared object file: No such file or directory 解决方法：sshrpm 升级后会修改/etc/pam.d/sshd 文件。需要升级前备份此文件最后还原即可登录。 7.第一次系统初始化运行生成本机ansible用户key时报错failed: [127.0.0.1] =&gt;{&quot;checksum&quot;: &quot;f5f2f20fc0774be961fffb951a50023e31abe920&quot;,&quot;failed&quot;: true} msg: Aborting, target uses selinux but pythonbindings (libselinux-python) aren&apos;t installed! FATAL: all hosts have already failed –aborting 解决办法yum -y install libselinux-python 参考: http://blog.csdn.net/longxibendi/article/details/46989735]]></content>
      <categories>
        <category>自动化</category>
      </categories>
      <tags>
        <tag>自动化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible]]></title>
    <url>%2F2018%2F09%2F01%2FAnsible%2F</url>
    <content type="text"><![CDATA[1、ansible介绍： Ansible是一款基于Python开发的自动化运维工具，主要是实现批量系统配置、批量程序部署、批量运行命令、批量执行任务等等诸多功能。 Ansible是一款灵活的开源工具，能够很大程度简化运维中的配置管理与流程控制方式，它利用推送方式对客户系统加以配置，这样所有工作都可在主服务器端完成。Asible是基于模块工作的，其本身没有批量部署的能力，Ansible~一款运维自动化的软件！1.1特性 (1)、no agents：不需要在被管控主机上安装任何客户端； (2)、no server：无服务器端，使用时直接运行命令即可； (3)、modules in any languages：基于模块工作，可使用任意语言开发模块； (4)、yaml，not code：使用yaml语言定制剧本playbook； (5)、ssh by default：基于SSH工作； (6)、strong multi-tier solution：可实现多级指挥。 1.1 优点 (1)、轻量级，无需在客户端安装agent，更新时，只需在操作机上进行一次更新即可； (2)、批量任务执行可以写成脚本，而且不用分发到远程就可以执行； (3)、使用python编写，维护更简单，ruby语法过于复杂； (4)、支持sudo。 2、ansible安装 安装epel 源：rpm -ivh https://dl.fedoraproject.org/pub/epel/epel-release-latest-6.noarch.rpm 安装ansible ：yum install ansible -y ssh-keygen 生成秘钥文件,如果不想输入密码可以一直回车 ssh-keygen -t rsa cd /root/.ssh/ &amp;&amp; ll ./* 配置ansible 的hosts 文件： vim /etc/ansible/hosts]]></content>
      <categories>
        <category>自动化</category>
      </categories>
      <tags>
        <tag>自动化</tag>
      </tags>
  </entry>
</search>
